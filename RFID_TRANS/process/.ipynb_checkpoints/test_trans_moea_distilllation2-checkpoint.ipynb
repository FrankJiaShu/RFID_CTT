{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识蒸馏-RFID Transformer teacher->GRU student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geatpy as ea\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.calculate_param as cp\n",
    "from dataset import data_read\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 硬件设备准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 50)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = data_read.load_data('train')\n",
    "X_test, y_test = data_read.load_data('test')\n",
    "\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2000, 50])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device) # [len * feature]\n",
    "y_train = torch.from_numpy(y_train).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device) # [len * feature]\n",
    "y_test = torch.from_numpy(y_test).float().to(device)\n",
    "\n",
    "X_train.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=100, shuffle=False)\n",
    "test_data_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=100, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义教师模型-transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 位置编码类\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.pe[:x.size(0), :]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TeacherTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherTransformer, self).__init__()\n",
    "        self.d_model = 128  # 词向量维度\n",
    "        self.embedding_enc = nn.Linear(50, self.d_model)\n",
    "        self.embedding_dec = nn.Linear(2, self.d_model)\n",
    "        self.pos_encoding = PositionalEncoding(self.d_model)\n",
    "        self.Transformer_layer = nn.Transformer(d_model=128, num_encoder_layers=3, num_decoder_layers=3, batch_first=True)\n",
    "        self.FC_layer = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 使用线性层代替embedding\n",
    "        src = self.embedding_enc(src).unsqueeze(0)\n",
    "        tgt = self.embedding_dec(tgt).unsqueeze(0)\n",
    "        src = self.pos_encoding(src)\n",
    "        out = self.Transformer_layer(src, tgt)\n",
    "        out = self.FC_layer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = TeacherTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "TeacherTransformer                                                     --\n",
      "├─Linear: 1-1                                                          6,528\n",
      "├─Linear: 1-2                                                          384\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "├─Transformer: 1-4                                                     --\n",
      "│    └─TransformerEncoder: 2-1                                         --\n",
      "│    │    └─ModuleList: 3-1                                            1,779,072\n",
      "│    │    └─LayerNorm: 3-2                                             256\n",
      "│    └─TransformerDecoder: 2-2                                         --\n",
      "│    │    └─ModuleList: 3-3                                            1,977,984\n",
      "│    │    └─LayerNorm: 3-4                                             256\n",
      "├─Linear: 1-5                                                          258\n",
      "===============================================================================================\n",
      "Total params: 3,764,738\n",
      "Trainable params: 3,764,738\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出教师模型的参数信息-300w参数\n",
    "cp.get_summary(model, input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 125.783032\n",
      "Epoch: 0002 loss = 45.761256\n",
      "Epoch: 0003 loss = 45.505695\n",
      "Epoch: 0004 loss = 42.353956\n",
      "Epoch: 0005 loss = 35.948355\n",
      "Epoch: 0006 loss = 32.446449\n",
      "Epoch: 0007 loss = 21.893260\n",
      "Epoch: 0008 loss = 14.406091\n",
      "Epoch: 0009 loss = 12.699065\n",
      "Epoch: 0010 loss = 9.974565\n",
      "Epoch: 0011 loss = 6.017965\n",
      "Epoch: 0012 loss = 4.791051\n",
      "Epoch: 0013 loss = 4.368068\n",
      "Epoch: 0014 loss = 3.540432\n",
      "Epoch: 0015 loss = 2.970758\n",
      "Epoch: 0016 loss = 2.604799\n",
      "Epoch: 0017 loss = 2.098221\n",
      "Epoch: 0018 loss = 1.981578\n",
      "Epoch: 0019 loss = 2.042423\n",
      "Epoch: 0020 loss = 1.545588\n",
      "Epoch: 0021 loss = 1.418187\n",
      "Epoch: 0022 loss = 1.515038\n",
      "Epoch: 0023 loss = 1.320891\n",
      "Epoch: 0024 loss = 1.271869\n",
      "Epoch: 0025 loss = 1.422441\n",
      "Epoch: 0026 loss = 1.062351\n",
      "Epoch: 0027 loss = 0.999672\n",
      "Epoch: 0028 loss = 1.039854\n",
      "Epoch: 0029 loss = 0.856481\n",
      "Epoch: 0030 loss = 0.880436\n",
      "Epoch: 0031 loss = 1.036889\n",
      "Epoch: 0032 loss = 0.868655\n",
      "Epoch: 0033 loss = 0.766982\n",
      "Epoch: 0034 loss = 0.810581\n",
      "Epoch: 0035 loss = 0.705722\n",
      "Epoch: 0036 loss = 0.654709\n",
      "Epoch: 0037 loss = 0.659048\n",
      "Epoch: 0038 loss = 0.610421\n",
      "Epoch: 0039 loss = 0.622286\n",
      "Epoch: 0040 loss = 0.656394\n",
      "Epoch: 0041 loss = 0.576831\n",
      "Epoch: 0042 loss = 0.628729\n",
      "Epoch: 0043 loss = 0.596955\n",
      "Epoch: 0044 loss = 0.610608\n",
      "Epoch: 0045 loss = 0.604649\n",
      "Epoch: 0046 loss = 0.551109\n",
      "Epoch: 0047 loss = 0.508280\n",
      "Epoch: 0048 loss = 0.474341\n",
      "Epoch: 0049 loss = 0.477734\n",
      "Epoch: 0050 loss = 0.548591\n",
      "Epoch: 0051 loss = 0.512083\n",
      "Epoch: 0052 loss = 0.500707\n",
      "Epoch: 0053 loss = 0.472647\n",
      "Epoch: 0054 loss = 0.476252\n",
      "Epoch: 0055 loss = 0.545302\n",
      "Epoch: 0056 loss = 0.522652\n",
      "Epoch: 0057 loss = 0.498959\n",
      "Epoch: 0058 loss = 0.482182\n",
      "Epoch: 0059 loss = 0.506116\n",
      "Epoch: 0060 loss = 0.483219\n",
      "Epoch: 0061 loss = 0.512527\n",
      "Epoch: 0062 loss = 0.490967\n",
      "Epoch: 0063 loss = 0.550481\n",
      "Epoch: 0064 loss = 0.391608\n",
      "Epoch: 0065 loss = 0.377062\n",
      "Epoch: 0066 loss = 0.370361\n",
      "Epoch: 0067 loss = 0.368790\n",
      "Epoch: 0068 loss = 0.376447\n",
      "Epoch: 0069 loss = 0.400941\n",
      "Epoch: 0070 loss = 0.410186\n",
      "Epoch: 0071 loss = 0.470278\n",
      "Epoch: 0072 loss = 0.394468\n",
      "Epoch: 0073 loss = 0.330150\n",
      "Epoch: 0074 loss = 0.380820\n",
      "Epoch: 0075 loss = 0.403693\n",
      "Epoch: 0076 loss = 0.383286\n",
      "Epoch: 0077 loss = 0.422628\n",
      "Epoch: 0078 loss = 0.407120\n",
      "Epoch: 0079 loss = 0.316187\n",
      "Epoch: 0080 loss = 0.313550\n",
      "Epoch: 0081 loss = 0.298045\n",
      "Epoch: 0082 loss = 0.337241\n",
      "Epoch: 0083 loss = 0.368175\n",
      "Epoch: 0084 loss = 0.438501\n",
      "Epoch: 0085 loss = 0.432201\n",
      "Epoch: 0086 loss = 0.366642\n",
      "Epoch: 0087 loss = 0.301437\n",
      "Epoch: 0088 loss = 0.293482\n",
      "Epoch: 0089 loss = 0.294455\n",
      "Epoch: 0090 loss = 0.319507\n",
      "Epoch: 0091 loss = 0.341648\n",
      "Epoch: 0092 loss = 0.304955\n",
      "Epoch: 0093 loss = 0.277894\n",
      "Epoch: 0094 loss = 0.332150\n",
      "Epoch: 0095 loss = 0.377949\n",
      "Epoch: 0096 loss = 0.419868\n",
      "Epoch: 0097 loss = 0.356641\n",
      "Epoch: 0098 loss = 0.282545\n",
      "Epoch: 0099 loss = 0.295701\n",
      "Epoch: 0100 loss = 0.369238\n",
      "best_loss::| 0.27789394464343786 ---best_epoch::| 92\n",
      "CPU times: user 4min 11s, sys: 48 s, total: 4min 59s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:  # enc_inputs : [len * feature]->[2000 * 50]\n",
    "        # print(X.shape)  # [100 * 50]\n",
    "        # print(y.shape)  # [100 * 50]\n",
    "        outputs = model(X, y)\n",
    "        outputs = outputs.squeeze()  # [100 * 2]\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss_num = loss.item()\n",
    "        epoch_loss += loss_num\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/teacher_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 教师模型评估"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.13243303, 'mse': 0.025263175, 'rmse': 0.15894393781553615, 'evs': 0.9964690506458282, 'r2': 0.9878422883621918, 'mmax': 0.29382825, 'mmin': 0.016830608}\n"
     ]
    }
   ],
   "source": [
    "model = TeacherTransformer().to(device)\n",
    "# 暂存教师模型为teacher_model\n",
    "teacher_model = model\n",
    "model.load_state_dict(torch.load('./result/teacher_weight.pth'))\n",
    "model.eval()\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 教师模型定位效果可视化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       X     y        PX        Py\n0   0.21  3.47  0.241251  3.687650\n1   1.13  1.96  1.226814  2.030297\n2   3.38  2.58  3.537199  2.668814\n3   4.07  2.72  4.335702  2.836458\n4   1.58  2.47  1.701975  2.534136\n5   3.43  1.61  3.593117  1.675727\n6   1.22  0.74  1.302344  0.762687\n7   2.33  1.97  2.442400  2.056887\n8   0.33  3.56  0.359159  3.795717\n9   3.53  4.28  3.826211  4.540102\n10  4.42  3.69  4.766800  3.884391\n11  3.67  0.34  3.932131  0.335423\n12  2.57  0.37  2.717470  0.385501\n13  3.14  3.22  3.318558  3.337761\n14  4.76  3.34  5.035338  3.453727\n15  1.70  3.71  1.839692  3.895073\n16  3.50  1.20  3.715562  1.242010\n17  0.68  4.65  0.767599  4.859977\n18  1.09  4.59  1.192177  4.844568\n19  0.25  3.70  0.286411  3.938812",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n      <th>PX</th>\n      <th>Py</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.21</td>\n      <td>3.47</td>\n      <td>0.241251</td>\n      <td>3.687650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.13</td>\n      <td>1.96</td>\n      <td>1.226814</td>\n      <td>2.030297</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.38</td>\n      <td>2.58</td>\n      <td>3.537199</td>\n      <td>2.668814</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.07</td>\n      <td>2.72</td>\n      <td>4.335702</td>\n      <td>2.836458</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.58</td>\n      <td>2.47</td>\n      <td>1.701975</td>\n      <td>2.534136</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.43</td>\n      <td>1.61</td>\n      <td>3.593117</td>\n      <td>1.675727</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.22</td>\n      <td>0.74</td>\n      <td>1.302344</td>\n      <td>0.762687</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.33</td>\n      <td>1.97</td>\n      <td>2.442400</td>\n      <td>2.056887</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.33</td>\n      <td>3.56</td>\n      <td>0.359159</td>\n      <td>3.795717</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.53</td>\n      <td>4.28</td>\n      <td>3.826211</td>\n      <td>4.540102</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4.42</td>\n      <td>3.69</td>\n      <td>4.766800</td>\n      <td>3.884391</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3.67</td>\n      <td>0.34</td>\n      <td>3.932131</td>\n      <td>0.335423</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2.57</td>\n      <td>0.37</td>\n      <td>2.717470</td>\n      <td>0.385501</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3.14</td>\n      <td>3.22</td>\n      <td>3.318558</td>\n      <td>3.337761</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4.76</td>\n      <td>3.34</td>\n      <td>5.035338</td>\n      <td>3.453727</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.70</td>\n      <td>3.71</td>\n      <td>1.839692</td>\n      <td>3.895073</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.50</td>\n      <td>1.20</td>\n      <td>3.715562</td>\n      <td>1.242010</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.68</td>\n      <td>4.65</td>\n      <td>0.767599</td>\n      <td>4.859977</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.09</td>\n      <td>4.59</td>\n      <td>1.192177</td>\n      <td>4.844568</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.25</td>\n      <td>3.70</td>\n      <td>0.286411</td>\n      <td>3.938812</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teacher = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_teacher)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_teacher.csv')\n",
    "coor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_teacher[:, 0], y_teacher[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with Transformer')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_teacher.jpg', dpi=750, bbox_inches = 'tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义学生模型-小变压器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class StudentTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentTransformer, self).__init__()\n",
    "        self.d_model = 8  # 词向量维度\n",
    "        self.embedding_enc = nn.Linear(50, self.d_model)\n",
    "        self.embedding_dec = nn.Linear(2, self.d_model)\n",
    "        self.Transformer_layer = nn.Transformer(d_model=8, num_encoder_layers=1, num_decoder_layers=1, batch_first=True)\n",
    "        self.FC_layer = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 使用线性层代替embedding\n",
    "        src = self.embedding_enc(src).unsqueeze(0)\n",
    "        tgt = self.embedding_dec(tgt).unsqueeze(0)\n",
    "        out = self.Transformer_layer(src, tgt)\n",
    "        out = self.FC_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 从头先训练一下学生模型\n",
    "model = StudentTransformer().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "StudentTransformer                                                     --\n",
      "├─Linear: 1-1                                                          408\n",
      "├─Linear: 1-2                                                          24\n",
      "├─Transformer: 1-3                                                     --\n",
      "│    └─TransformerEncoder: 2-1                                         --\n",
      "│    │    └─ModuleList: 3-1                                            35,144\n",
      "│    │    └─LayerNorm: 3-2                                             16\n",
      "│    └─TransformerDecoder: 2-2                                         --\n",
      "│    │    └─ModuleList: 3-3                                            35,448\n",
      "│    │    └─LayerNorm: 3-4                                             16\n",
      "├─Linear: 1-4                                                          18\n",
      "===============================================================================================\n",
      "Total params: 71,074\n",
      "Trainable params: 71,074\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出学生模型的参数信息-1w参数\n",
    "cp.get_summary(model, input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 0.448841\n",
      "Epoch: 0002 loss = 0.315990\n",
      "Epoch: 0003 loss = 0.379252\n",
      "Epoch: 0004 loss = 0.506168\n",
      "Epoch: 0005 loss = 0.338425\n",
      "Epoch: 0006 loss = 0.314701\n",
      "Epoch: 0007 loss = 0.390483\n",
      "Epoch: 0008 loss = 0.427704\n",
      "Epoch: 0009 loss = 0.290983\n",
      "Epoch: 0010 loss = 0.390513\n",
      "Epoch: 0011 loss = 0.432219\n",
      "Epoch: 0012 loss = 0.331589\n",
      "Epoch: 0013 loss = 0.326747\n",
      "Epoch: 0014 loss = 0.364772\n",
      "Epoch: 0015 loss = 0.383584\n",
      "Epoch: 0016 loss = 0.283193\n",
      "Epoch: 0017 loss = 0.293466\n",
      "Epoch: 0018 loss = 0.417398\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-17-8c8cefb44712>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src, tgt)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0msrc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_enc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mtgt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_dec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtgt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTransformer_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFC_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m         \u001B[0mmemory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001B[0m\u001B[1;32m    147\u001B[0m                               \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m                               memory_key_padding_mask=memory_key_padding_mask)\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmod\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 291\u001B[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001B[0m\u001B[1;32m    292\u001B[0m                          \u001B[0mmemory_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmemory_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m                          \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    576\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sa_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mha_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 578\u001B[0;31m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ff_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    579\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/normalization.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    188\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 189\u001B[0;31m         return F.layer_norm(\n\u001B[0m\u001B[1;32m    190\u001B[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001B[1;32m    191\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlayer_norm\u001B[0;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[1;32m   2501\u001B[0m             \u001B[0mlayer_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalized_shape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2502\u001B[0m         )\n\u001B[0;32m-> 2503\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer_norm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalized_shape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackends\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcudnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menabled\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2504\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2505\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:  # enc_inputs : [len * feature]->[2000 * 50]\n",
    "        outputs = model(X, y)\n",
    "        outputs = outputs.squeeze()  # [100 * 2]\n",
    "        loss = criterion(outputs, y)\n",
    "        loss_num = loss.item()\n",
    "        epoch_loss += loss_num\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/student_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|', best_loss, '---best_epoch::|', best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 学生模型评估"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.15204194, 'mse': 0.035176195, 'rmse': 0.18755317966981516, 'evs': 0.9912069439888, 'r2': 0.9829413458638048, 'mmax': 0.3146553, 'mmin': 0.008249178}\n"
     ]
    }
   ],
   "source": [
    "model = StudentTransformer().to(device)\n",
    "# 暂存教师模型为teacher_model\n",
    "student_model = model\n",
    "model.load_state_dict(torch.load('./result/student_weight.pth'))\n",
    "model.eval()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 学生模型定位效果可视化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "       X     y        PX        Py\n0   0.21  3.47  0.162144  3.669692\n1   1.13  1.96  1.105486  2.036714\n2   3.38  2.58  3.631137  2.750383\n3   4.07  2.72  4.408797  2.920367\n4   1.58  2.47  1.607036  2.612742\n5   3.43  1.61  3.698950  1.650250\n6   1.22  0.74  1.199389  0.682068\n7   2.33  1.97  2.439924  2.067953\n8   0.33  3.56  0.276683  3.781685\n9   3.53  4.28  3.763663  4.609232\n10  4.42  3.69  4.719604  3.972551\n11  3.67  0.34  3.931938  0.266225\n12  2.57  0.37  2.721863  0.283552\n13  3.14  3.22  3.366997  3.472075\n14  4.76  3.34  5.027439  3.550685\n15  1.70  3.71  1.741418  4.032957\n16  3.50  1.20  3.784999  1.181881\n17  0.68  4.65  0.691874  4.806493\n18  1.09  4.59  1.094549  4.841394\n19  0.25  3.70  0.212121  3.904635",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n      <th>PX</th>\n      <th>Py</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.21</td>\n      <td>3.47</td>\n      <td>0.162144</td>\n      <td>3.669692</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.13</td>\n      <td>1.96</td>\n      <td>1.105486</td>\n      <td>2.036714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.38</td>\n      <td>2.58</td>\n      <td>3.631137</td>\n      <td>2.750383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.07</td>\n      <td>2.72</td>\n      <td>4.408797</td>\n      <td>2.920367</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.58</td>\n      <td>2.47</td>\n      <td>1.607036</td>\n      <td>2.612742</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.43</td>\n      <td>1.61</td>\n      <td>3.698950</td>\n      <td>1.650250</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.22</td>\n      <td>0.74</td>\n      <td>1.199389</td>\n      <td>0.682068</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.33</td>\n      <td>1.97</td>\n      <td>2.439924</td>\n      <td>2.067953</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.33</td>\n      <td>3.56</td>\n      <td>0.276683</td>\n      <td>3.781685</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.53</td>\n      <td>4.28</td>\n      <td>3.763663</td>\n      <td>4.609232</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4.42</td>\n      <td>3.69</td>\n      <td>4.719604</td>\n      <td>3.972551</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3.67</td>\n      <td>0.34</td>\n      <td>3.931938</td>\n      <td>0.266225</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2.57</td>\n      <td>0.37</td>\n      <td>2.721863</td>\n      <td>0.283552</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3.14</td>\n      <td>3.22</td>\n      <td>3.366997</td>\n      <td>3.472075</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4.76</td>\n      <td>3.34</td>\n      <td>5.027439</td>\n      <td>3.550685</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.70</td>\n      <td>3.71</td>\n      <td>1.741418</td>\n      <td>4.032957</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.50</td>\n      <td>1.20</td>\n      <td>3.784999</td>\n      <td>1.181881</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.68</td>\n      <td>4.65</td>\n      <td>0.691874</td>\n      <td>4.806493</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.09</td>\n      <td>4.59</td>\n      <td>1.094549</td>\n      <td>4.841394</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.25</td>\n      <td>3.70</td>\n      <td>0.212121</td>\n      <td>3.904635</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_student = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_student)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_student.csv')\n",
    "coor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_student[:, 0], y_student[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with GRU')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_student.jpg', dpi=750, bbox_inches = 'tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识蒸馏准备与设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 准备预训练好的教师模型\n",
    "teacher_model.eval()\n",
    "\n",
    "# 准备新的学生模型\n",
    "model = StudentTransformer().to(device)\n",
    "\n",
    "# 蒸馏温度\n",
    "T = 9\n",
    "\n",
    "# 蒸馏参数设置\n",
    "# hard_loss\n",
    "hard_loss = nn.MSELoss()\n",
    "# hard_loss权重\n",
    "alpha = 0.3\n",
    "# soft_loss kl散度\n",
    "soft_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识蒸馏训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frank/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([100, 2])) that is different to the input size (torch.Size([1, 100, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = -10411.670044\n",
      "Epoch: 0002 loss = -10418.210693\n",
      "Epoch: 0003 loss = -10421.324890\n",
      "Epoch: 0004 loss = -10423.941284\n",
      "Epoch: 0005 loss = -10426.218933\n",
      "Epoch: 0006 loss = -10428.354126\n",
      "Epoch: 0007 loss = -10430.313354\n",
      "Epoch: 0008 loss = -10431.782532\n",
      "Epoch: 0009 loss = -10432.940125\n",
      "Epoch: 0010 loss = -10433.869324\n",
      "Epoch: 0011 loss = -10434.597595\n",
      "Epoch: 0012 loss = -10435.117432\n",
      "Epoch: 0013 loss = -10435.506226\n",
      "Epoch: 0014 loss = -10435.813904\n",
      "Epoch: 0015 loss = -10436.074402\n",
      "Epoch: 0016 loss = -10436.317200\n",
      "Epoch: 0017 loss = -10436.344788\n",
      "Epoch: 0018 loss = -10436.564209\n",
      "Epoch: 0019 loss = -10436.755188\n",
      "Epoch: 0020 loss = -10436.831909\n",
      "Epoch: 0021 loss = -10436.896179\n",
      "Epoch: 0022 loss = -10437.046326\n",
      "Epoch: 0023 loss = -10436.998596\n",
      "Epoch: 0024 loss = -10437.144775\n",
      "Epoch: 0025 loss = -10437.139221\n",
      "Epoch: 0026 loss = -10437.155823\n",
      "Epoch: 0027 loss = -10437.171570\n",
      "Epoch: 0028 loss = -10437.223450\n",
      "Epoch: 0029 loss = -10437.242004\n",
      "Epoch: 0030 loss = -10437.252441\n",
      "Epoch: 0031 loss = -10437.253479\n",
      "Epoch: 0032 loss = -10437.311096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-17-8c8cefb44712>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src, tgt)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0msrc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_enc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mtgt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_dec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtgt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTransformer_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFC_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m         \u001B[0mmemory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001B[0m\u001B[1;32m    147\u001B[0m                               \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m                               memory_key_padding_mask=memory_key_padding_mask)\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmod\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 291\u001B[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001B[0m\u001B[1;32m    292\u001B[0m                          \u001B[0mmemory_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmemory_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m                          \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    576\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sa_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mha_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 578\u001B[0;31m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ff_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    579\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36m_ff_block\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[0;31m# feed forward block\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    601\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_ff_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 602\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactivation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    603\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 教师模型预测\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(X, y)\n",
    "        # 学生模型预测\n",
    "        student_outputs = model(X, y)\n",
    "        student_loss = hard_loss(student_outputs, y)\n",
    "        # 计算蒸馏后的预测结果及soft_loss\n",
    "        distillation_loss = soft_loss(\n",
    "            F.softmax(student_outputs/T, dim=1),\n",
    "            F.softmax(teacher_outputs/T, dim=1)\n",
    "        )\n",
    "        # 将 hard_loss 和 soft_loss 加权求和\n",
    "        loss = alpha * student_loss + (1-alpha) * distillation_loss * T **2\n",
    "        # 反向传播,优化权重\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/distillation_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 蒸馏模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.1518006, 'mse': 0.03801897, 'rmse': 0.19498454216064115, 'evs': 0.9847988784313202, 'r2': 0.9816030012417469, 'mmax': 0.71145415, 'mmin': 0.016973555}\n"
     ]
    }
   ],
   "source": [
    "model = StudentTransformer().to(device)\n",
    "model.load_state_dict(torch.load('./result/distillation_weight.pth'))\n",
    "model.eval()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 蒸馏模型定位效果可视化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "       X     y        PX        Py\n0   0.21  3.47  0.284969  3.602425\n1   1.13  1.96  1.164377  2.080438\n2   3.38  2.58  3.682233  2.803676\n3   4.07  2.72  4.393359  2.952392\n4   1.58  2.47  1.603147  2.571705\n5   3.43  1.61  3.892507  1.795763\n6   1.22  0.74  1.254863  0.782649\n7   2.33  1.97  2.426601  2.106437\n8   0.33  3.56  0.382243  3.688406\n9   3.53  4.28  3.531628  4.341705\n10  4.42  3.69  4.347397  3.730716\n11  3.67  0.34  3.900538  0.575031\n12  2.57  0.37  2.908475  0.409832\n13  3.14  3.22  3.340399  3.486715\n14  4.76  3.34  4.560523  3.342371\n15  1.70  3.71  1.664338  3.887244\n16  3.50  1.20  3.975747  1.356169\n17  0.68  4.65  0.806122  4.337845\n18  1.09  4.59  1.108630  4.413423\n19  0.25  3.70  0.346374  3.777927",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n      <th>PX</th>\n      <th>Py</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.21</td>\n      <td>3.47</td>\n      <td>0.284969</td>\n      <td>3.602425</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.13</td>\n      <td>1.96</td>\n      <td>1.164377</td>\n      <td>2.080438</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.38</td>\n      <td>2.58</td>\n      <td>3.682233</td>\n      <td>2.803676</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.07</td>\n      <td>2.72</td>\n      <td>4.393359</td>\n      <td>2.952392</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.58</td>\n      <td>2.47</td>\n      <td>1.603147</td>\n      <td>2.571705</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.43</td>\n      <td>1.61</td>\n      <td>3.892507</td>\n      <td>1.795763</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.22</td>\n      <td>0.74</td>\n      <td>1.254863</td>\n      <td>0.782649</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.33</td>\n      <td>1.97</td>\n      <td>2.426601</td>\n      <td>2.106437</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.33</td>\n      <td>3.56</td>\n      <td>0.382243</td>\n      <td>3.688406</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.53</td>\n      <td>4.28</td>\n      <td>3.531628</td>\n      <td>4.341705</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4.42</td>\n      <td>3.69</td>\n      <td>4.347397</td>\n      <td>3.730716</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3.67</td>\n      <td>0.34</td>\n      <td>3.900538</td>\n      <td>0.575031</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2.57</td>\n      <td>0.37</td>\n      <td>2.908475</td>\n      <td>0.409832</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3.14</td>\n      <td>3.22</td>\n      <td>3.340399</td>\n      <td>3.486715</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4.76</td>\n      <td>3.34</td>\n      <td>4.560523</td>\n      <td>3.342371</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.70</td>\n      <td>3.71</td>\n      <td>1.664338</td>\n      <td>3.887244</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.50</td>\n      <td>1.20</td>\n      <td>3.975747</td>\n      <td>1.356169</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.68</td>\n      <td>4.65</td>\n      <td>0.806122</td>\n      <td>4.337845</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.09</td>\n      <td>4.59</td>\n      <td>1.108630</td>\n      <td>4.413423</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.25</td>\n      <td>3.70</td>\n      <td>0.346374</td>\n      <td>3.777927</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_distill = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_distill)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_distill.csv')\n",
    "coor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAJOCAYAAABvHKlnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA79UlEQVR4nO3deXycZb3///enixZoIQrFIiBtI7QU2qaLUqDQ1gVRewCBHvbloHAKovnG5QjniI4MRznCzxh+VjiIBGSTytZ80YPIErsAB2gJLdAWEIMEppTFlBYsQzOf7x/3TDpJsydXZns9H495ZO6Ze+77M3OH5s11XXNd5u4CAADAwBuS6wIAAACKFUELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0AAAAAiFoARgwZuZm9sn0/WvM7JJc11To+ByBwmbMowUUFzM7VdK3JE2UtFlSg6T/dPflg3Bul7S/u784gMccK+mvkoa7+7Y+HuNDkv5d0mmSPi7pDUkPSbrU3RsHplIA2BEtWkARMbNvSfq5pB9L+pikT0j6paRjB/g8wwbyeIPgDknHSDpV0m6SpkpaKemzuSyqO2Y2NNc1AOgfghZQJMxsN0mXSvq6u9/l7u+6+wfu/n/d/bvpfT5sZj83s9fSt5+b2YezjnGumb1oZm+bWZ2ZfTzrOTezr5vZC5JeSD/2XTNLpI91Trt6bjCzy9L355pZk5l928w2pl/zL1n7ftnMnjKzd8zsFTOLZR1qafpns5ltMbND0685x8zWmtnfzeyPZrZfJ5/L5yR9XtKx7v6Eu29z903uvsjdf53e5+Pp9/t2+v2fm/X6mJn9zsxuNrPNZrbGzA4ws4vT7+UVMzsqa/96M/uJmT1uZpvMbImZfTTr+d+Z2Yb0c0vN7KB2n9nVZvYHM3tX0rx2n+MeZnavmTWna11mZkPSzx2YPnezmT1rZse0O+4iM/t9+j38r5mVd/R5ARhYBC2geBwqaYSku7vY5z8kzZJUoahV59OSvi9JZvYZST+R9M+S9pL0sqTftnv9cZIOkTTJzI6W9B1FIWZ/SZ/rpr4xilqT9pb0VUmLzOwj6efelXSmpDJJX5Z0vpkdl37uyPTPMncf6e6Ppp/7d0nHSxotaZmk2zo57+ckPe7ur3RR222SmhR1K54o6cdmlt3a9U+SbpL0EUlPSfqjon8/91YUbv+73fHOlHRO+njbJF2V9dz/KPq89pS0StIt7V57qqT/lDRKUvvu3m+n6xytqMXy3yW5mQ2X9H8l3Z8+7jck3WJmE7Jee4qkH6Xfw4vpcwAIjKAFFI/dJb3ZzTim0xSNS9ro7m8o+sN7RtZz17v7Knd/X9LFkg5Nj5HK+Im7v+3u/1AUyGrd/Rl3f1dSrJv6Pkif+wN3/4OkLZImSJK717v7GndPuftqRcFnThfH+td0LWvT7/fHkio6adXaXVKiswOZ2b6SZkv6nrtvdfcGSddp++ciScvc/Y/pc/1OUdC53N0/UBRGx5pZWdb+N2V9LpdI+udMN6C7X+/um9OfcUzS1HRrZMYSd1+R/iy2tiv3A0UheL/057jMo4G2sySNTNeUdPeHJN2rKFxl3OXuj6ffwy2KwjaAwAhaQPF4S9Ie3Yyf+riilqqMl9OP7fCcu29JH3PvrP2zW4U+3m47+7gd1tcuBL6nKBzIzA4xs4fN7A0z2yRpoaQ9ujjWfpJq0t1kzZLelmTtam09r6Jw0pmPS3rb3Te3ey/Zx3o96/4/FAXalqxtZd5LWvvPZbiiazPUzC43s7+Y2TuSGtP77NHJa9u7QlFr1P1m9pKZXZT1Hl5x91QX72FD1v3Wzx5AWAQtoHg8Kmmrou69zrymKKRkfCL92A7PmdkuilqDXs3aP/tryglJ+7Y7Vl/dKqlO0r7uvpukaxQFp/bnzHhF0r+6e1nWbSd3f6SDfR+Q9Gkz26eTc78m6aNmNirrsU+o7fvurfafyweS3lTULXisou7M3SSNTe9jWft3+lXwdEvYt919vKLuzG+luzhfk7RvZrzWAL0HAAOAoAUUCXffJOkHisY+HWdmO5vZcDP7opn9NL3bbZK+b2ajzWyP9P43p5+7VdK/mFmFRQPkfyzpf7uY/mCxpLPNbJKZ7Szph/0of5SiVqWtZvZpRYEk4w1JKUnjsx67RtLFmYHkZrabmS3o6MDu/oCkP0m628xmmNkwMxtlZgvN7Jz02K1HJP3EzEaY2RRFY8jaj53qjdOzPpdLJd2RbgEbJel9Ra1sOyv6jHvMzOab2SfNzCS9I6klfftfRePc/i19zecqCmLtx9gBGGQELaCIuPvPFM2h9X1FAeUVSRdKuie9y2WSnpS0WtIaRYOxL0u/9kFF44nuVNRaVS7p5C7O9T+KppJ4SFF31kP9KP0CSZea2WZF4W9x1nneUzRwe0W6q3CWu98t6b8k/TbdBfeMpC92cfwTJf1B0u2SNqX3n6motUuKxjKNVdQydLekH7r7n/rxfm6SdIOi7roRkr6Zfvw3irr0XpX0nKTHennc/dM1b1HUgvnL9Pi2pKLpK76oqOXsl5LOdPd1/XgPAAYAE5YCwAAys3pJN7v7dbmuBUDu0aIFAAAQSNDZnc2sUdESIC2Strn7zJDnAwAAyCdBuw7TQWumu78Z7CQAAAB5iq5DAACAQEK3aP1V0t8VzQvz3+5+bQf7nCfpPEkaMWLEjE98oj9T8SBXUqmUhgwhtxcqrl/h4toVNq5fYXv++effdPfRXe0TOmh93N1fM7M9Fc1j8w13X9rZ/hMmTPD169cHqwfh1NfXa+7cubkuA33E9StcXLvCxvUrbGa2srvx50FjtLu/lv65UdHcNJ8OeT4AAIB8EixomdkumSUt0kt5HKVokkAAAICSEHJ6h48pWvIic55b3f2+gOcDAADIK8GClru/JGlqqOMDAErXBx98oKamJm3dujXXpfTLbrvtprVr1+a6DHRjxIgR2meffTR8+PBevzbohKUAAITQ1NSkUaNGaezYsUr3nBSkzZs3a9SoUbkuA11wd7311ltqamrSuHHjev16vlMKACg4W7du1e67717QIQuFwcy0++6797n1lKAFAChIhCwMlv78rhG0AAAAAiFoAQCQA2PHjtVbb70V5Nh1dXW6/PLLJUn33HOPnnvuudbnfvCDH+iBBx4Ict6MU045RVOmTFF1dXWbx2OxmPbee29VVFRo0qRJuu2221qfO/vsszVu3DhVVFSooqJCV111laToc3rzzWjJ5KFDh6qiokIHHXSQpk6dqp/97GdKpVI7nL+xsVG33nprwHfYcwyGBwCgH9xd7p5XS+kcc8wxOuaYYyRFQWv+/PmaNGmSJOnSSy8Neu4NGzbokUce0csvv9zh81VVVfrOd76jF154QTNmzNCJJ57Y+m2+K664QieeeGKnx95pp53U0NAgSdq4caNOPfVUbdq0ST/60Y/a7JcJWqeeeurAvKl+yJ/fCgAAAkokEiovL9eGDRv6fazGxkYdeOCBuuCCCzR9+nS98soruuKKK/SpT31KU6ZM0Q9/+MPWfY877jjNmDFDBx10kK69doclf3cwcuRIffvb39b06dP12c9+Vm+88YYkqaGhQbNmzdKUKVP0la98RX//+98lSVdddZUmTZqkKVOm6OSTT5Yk3XDDDbrwwgv1yCOPqK6uTt/97ndVUVGhv/zlLzr77LN1xx13SJIefPBBTZs2TZMnT9Y555yj999/X1LUivTDH/5Q06dP1+TJk7Vu3bod6ty6dav+5V/+RZMnT9a0adP08MMPS5KOOuoobdy4URUVFVq2bFmn73P//ffXzjvv3Po+emvPPffUtddeq1/84hdqv5zgRRddpGXLlqmiokLV1dVqbGzUEUccoenTp2v69Ol65JFHJEVrTV5wwQU66KCDNH/+fH3pS19q/WwGCkELAFAS4vG4GhsbFY/HB+R469ev15lnnqmnnnpK69ev1wsvvKDHH39cDQ0NWrlypZYujZb2vf7667Vy5Uo9+eSTuuqqq7rtLnz33Xc1ffp0rVq1SnPmzGltrTnzzDP1X//1X1q9erUmT57c+vjll1+up556SqtXr9Y111zT5liHHXaYjjnmGF1xxRVqaGhQeXl563Nbt27V2Wefrdtvv11r1qzRtm3bdPXVV7c+v8cee2jVqlU6//zzdeWVV+5Q56JFiyRJa9as0W233aazzjpLW7duVV1dncrLy9XQ0KAjjjii0/e5atUq7b///tpzzz1bH8sEwoqKCq1Zs6bLz0mSxo8fr1QqpY0bN7Z5/PLLL9cRRxyhhoYGVVVVac8999Sf/vQnrVq1Srfffru++c1vSpLuuusuNTY2as2aNbruuuv06KOPdnvO3iJoAQCKXiKRUG1trVKplGprawekVWu//fbTrFmzJEn333+/7r//fk2bNk3Tp0/XunXr9MILL0iKWpymTp2qWbNm6ZVXXml9vDNDhgzRSSedJEk6/fTTtXz5cm3atEnNzc2aM2eOJOmss85qDXJTpkzRaaedpptvvlnDhvV8RND69es1btw4HXDAATscU5KOP/54SdKMGTPU2Ni4w+uXL1+uM844Q5I0ceJE7bfffnr++ee7PW91dbUmTJigQw45RLFYrM1zmUDY0NCgyZMn9+h9tG/N6sgHH3ygc889V5MnT9aCBQtax6wtX75cCxYs0JAhQzRmzBjNmzevR+fsDYIWAKDoxePx1kHTLS0tA9Kqtcsuu7Ted3ddfPHFrSHhxRdf1Fe/+lXV19frgQce0KOPPqqnn35a06ZN6/V8TN1NLfD73/9eX//617Vy5UrNmDFD27Zt69FxuwsoH/7whyVFA9A7OmZPAk5HqqqqtH79et1+++0688wz+zW7/0svvaShQ4e2aRXrSHV1tT72sY/p6aef1pNPPqlkMimp7++hNwhaAICilmnNyvxxTSaTA9aqlfGFL3xB119/vbZs2SJJevXVV7Vx40Zt2rRJH/nIR7Tzzjtr3bp1euyxx7o9ViqVah0ndOutt2r27Nnabbfd9JGPfKR1zNNNN92kOXPmKJVK6ZVXXtG8efP005/+VM3Nza01ZIwaNUqbN2/e4TwTJ05UY2OjXnzxxTbH7KkjjzxSt9xyiyTp+eef19/+9jdNmDChx68//vjjNXPmTN144409fk22N954QwsXLtSFF164Qxht/543bdqkvfbaS0OGDNFNN92klpYWSdLs2bN15513KpVK6fXXX1d9fX2faukK3zoEABS17NasjEyrVmacUX8dddRRWrt2rQ499FBJ0YD2m2++WUcffbSuueYaTZkyRRMmTGjtauzKLrvsomeffVYzZszQbrvtpttvv12SdOONN2rhwoV67733NH78eNXW1qqlpUWnn366Nm3aJHdXVVWVysrK2hzv5JNP1rnnnqurrrqqzUDvESNGqLa2VgsWLNC2bdv0qU99SgsXLuzxe77gggu0cOFCTZ48WcOGDdMNN9zQ2grWUz/4wQ906qmn6txzz+3R/v/4xz9UUVGhDz74QMOGDdMZZ5yhb33rWzvsN2XKFA0bNkxTp07V2WefrQsuuEAnnHCCfve732nevHmtrZEnnHCCHnzwQR188ME64IADdMghh2i33Xbr1Xvojg1Gs1lPTZgwwdevX5/rMtAH9fX1mjt3bq7LQB9x/QpXqV67tWvX6sADD+zRvvvss49effXVHR7fe++91dTUNNCl9UpHax2OHDlyh1YphLNlyxaNHDlSb731lj796U9rxYoVGjNmzA77dfQ7Z2Yr3X1mV8enRQsAUNRyHaaQ3+bPn6/m5mYlk0ldcsklHYas/iBoAQCQR2jNGlwhxmVlYzA8AABAIAQtAACAQAhaAAAAgRC0AAAAAiFoAQCQY/X19Zo/f74kqa6uTpdffnmn+zY3N+uXv/xl0HquueYa/eY3v5EULVD92muvtT73ta99rXUJm5CefPLJ1jUJ6+vrWxeCltRmYeyujBw5svX+H/7wB+2///7629/+plgspr333lsVFRXaf//9dfzxxwd7TwQtAEDxaz9n5CDNIZmZgbw3jjnmGF100UWdPj8YQWvhwoU688wzJe0YtK677jpNmjQp6PklaebMmbrqqqsk7Ri0euvBBx/UN77xDd133336xCc+ISlaCqihoUEvvPCCTjrpJH3mM5/RG2+8MSC1ZyNoAQCKWywmVVVtD1fu0Xa7BY17o7GxURMnTtRZZ52lKVOm6MQTT9R7770nSRo7dqwuvfRSzZ49W7/73e90//3369BDD9X06dO1YMGC1ukb7rvvPs2YMUOzZ8/WXXfd1XrsG264QRdeeKEk6fXXX9dXvvIVTZ06VVOnTtUjjzyiiy66SH/5y19UUVGh7373uz2u68EHH9S0adM0efJknXPOOXr//fclSRdddJEmTZqkKVOm6Dvf+U76I4vpyiuv1B133KEnn3xSp512mioqKvSPf/xDc+fO1ZNPPilJuu222zR58mQdfPDB+t73vtdax8iRI/Uf//EfrYtpv/766zt8hpMnT1Zzc7PcXbvvvntrC9oZZ5yhBx54oLWVr7GxUddcc42qq6tVUVHRugzR0qVLddhhh2n8+PFdtm4tW7ZM5557rn7/+9+rvLy8w31OOukkHXXUUbr11ls7PU5fEbQAAMXLXWpulmpqtoetqqpou7m5Xy1b69ev13nnnafVq1dr1113bdPKNGLECC1fvlyf+9zndNlll+mBBx7QqlWrNHPmTP3sZz/T1q1bde655+r222/XsmXLOl138Zvf/KbmzJmjp59+WqtWrdJBBx2kyy+/XOXl5WpoaNAVV1zRo7q2bt2qs88+W7fffrvWrFmjbdu26eqrr9bbb7+tu+++W88++6xWr16t73//+22OdeKJJ2rmzJm65ZZb1NDQoJ122qn1uddee03f+9739NBDD6mhoUFPPPGE7rnnHknSu+++q1mzZunpp5/WkUceqV/96lc71Hn44YdrxYoVevbZZzV+/PjWAPXYY4+1Wapo7NixWrhwYWsL1BFHHCEpWsNy+fLluvfeezttAXz//fd17LHH6p577tHEiRM73Cdj+vTpWrduXZf79AVBCwBQvMyk6mqpsjIKV0OGRD8rK6PH2y1G3Bv77ruvDj/8cEnS6aefruXLl7c+d9JJJ0mKQsNzzz2nww8/XBUVFbrxxhv18ssva926dRo3bpw++clPysx0+umnd3iOhx56SOeff74kaejQoT1ah6+jutavX69x48bpgAMOkCSdddZZWrp0qXbddVeNGDFCX/va13TXXXdp55137vH7f+KJJzR37lyNHj1aw4YN02mnnaalS5dKkj70oQ+1jjmbMWOGGhsbd3j9EUccoaVLl2rp0qU6//zztWbNGr366qv66Ec/2mZsVWeOO+44DRkyRJMmTeqwxUyShg8frsMOO0y//vWvuz1eqCUJCVoAgOKWCVvZ+hmyosNap9uZRYvdXZ///OfV0NCghoYGPffcc61/9Nu/fqB0VFdnIWLYsGF6/PHHdcIJJ+iee+7R0Ucf3ePzdBVMhg8f3lrH0KFDtW3bth32OfLII7Vs2TItW7asNbDdcccdrS1W3clewLqzWoYMGaLFixfriSee0I9//OMuj/fUU0/1eP3M3iBoAQCKW6a7MFv2mK0++tvf/qZHH31UUjRWafbs2TvsM2vWLK1YsUIvvviiJOm9997T888/r4kTJ+qvf/2rXnrppdbXd+Szn/2srr76aknRwPp33nlHo0aN0ubNm3tV18SJE9XY2Nhax0033aQ5c+Zoy5Yt2rRpk770pS/p5z//uRoaGnY4XmfnO+SQQ/TnP/9Zb775plpaWnTbbbdpzpw5ndbV3r777qs333xTL7zwgsaPH6/Zs2fryiuv7DBodfeeu7Lzzjvr3nvv1S233NJpy9add96p+++/X6ecckqfztEVghYAoHhlj8mqrJRSqe3diP0MWwceeKBuvPFGTZkyRW+//XZrF1+20aNH64YbbtApp5yiKVOmaNasWVq3bp1GjBiha6+9VgsWLNDs2bO13377dXiOmpoaPfzww5o8ebJmzJihZ599VrvvvrsOP/xwHXzwwTsMhu+srhEjRqi2tlYLFizQ5MmTNWTIEC1cuFCbN2/W/PnzNWXKFM2ZM0fV7Vv+FE2lsHDhwtbB8Bl77bWXfvKTn2jevHmaOnWqpk+frmOPPbZXn+EhhxzS2p15xBFH6NVXX+0wsP7TP/2T7r777jaD4Xvjox/9qO677z5ddtllWrJkiSS1Dq7ff//9dfPNN+uhhx7S6NGje33s7lioPsm+mDBhgq9fvz7XZaAP6uvrNXfu3FyXgT7i+hWuUr12a9eu7Xk3TywWDXzPdBdmwldZWZ+/edjY2Kj58+frmWee6dPrMzZv3qxRo0b16xjZBqou7Kij3zkzW+nuM7t63bCgVQEAkGuxWBSuMmOXMmO2Ao2RArLRdViAEomEysvLO/06MACgnfahqp8ha+zYsXnZapSvdZUyglYBisfjamxsVDwez3UpAJAz+TT0BcWtP79rBK0Ck0gkVFtbq1QqpdraWlq1AJSkESNG6K233iJsITh311tvvaURI0b06fWM0Sow8XhcqVRKUvRV33g8rkWLFuW4KgAYXPvss4+ampqCrE03mLZu3drnP+AYPCNGjNA+++zTp9cStApIpjUrmUxKkpLJpGpra3XJJZdozJgxOa4OAAbP8OHDNW7cuFyX0W/19fWaNm1arstAQHQdFpDs1qyMTKsWAADIPwStAlJXV9fampWRTCZbJ18DAAD5haBVQJqamuTuO9yamppyXVqPMC0FAKDUELQwaJiWAgBQaghaGBRMSwEAKEUELQyKjqalAACg2BG0EFxn01LQqgUAKHYELQTHtBQAgFJF0EJwTEsBAChVzAyP4Apl+gkAAAYaLVoAAACBELQAAAACIWgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0AAAAAiFoYXC5d70NAEARIWhh8MRiUlXV9nDlHm3HYrmsCgCAYAhaGBzuUnOzVFOzPWxVVUXbzc20bAEAitKwXBeAEmEmVVdH92tqopskVVZGj5vlrjYAAAKhRQuDJztsZRCyAABFjKCFwZPpLsyWPWYLAIAiQ9DC4Mgek1VZKaVS0c/sMVsAABQZxmhhcJhJZWVtx2RluhHLyug+BAAUJYJWKXFvG2jab4cWi7U9ZyZsEbIAdCfX/34BfUTXYanIlzms2v/DyD+UALqTL/9+AX1A0CoFzGEFoFDx7xcKHF2HpYA5rAAUKv79QoGjRatUMIcVgELFv18oYAStUsEcVgAKFf9+oYARtEoBc1gBKFT8+4UCxxitUsAcVgAKVda/X4l/+zfN/uQntWL5co2R+PcLBYGgVSqYwwpAoUr/+xX/+tfV2Nio+GWXadEvfsG/XygIdB2WEuawAlCgEhs2qLa2VqlUSrW1tdrw+uu5LgnoEYIWACDvxeNxpVIpSVJLS4vi8XiOKwJ6hqAFAMhriURCtbW1SiaTkqRkMhm1am3YkOPKgO4RtAAAeS27NSuDVi0UCoIWACCv1dXVtbZmZSSTSS1ZsiRHFQE9x7cOAQB5rampKdclAH1GixYAAEAgBC0AAIBACFoAAACBELQAAAACIWgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0AAAAAiFoAQAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABBI8KBlZkPN7Ckzuzf0uQAAAPLJYLRoVUpaOwjnAQAAyCtBg5aZ7SPpy5KuC3keAACAfGTuHu7gZndI+omkUZK+4+7zO9jnPEnnSdLo0aNnLF68OFg9CGfLli0aOXJkrstAH3H9ChfXrrBx/QrbvHnzVrr7zK72GRbq5GY2X9JGd19pZnM728/dr5V0rSRNmDDB587tdFfksfr6enHtChfXr3Bx7Qob16/4hew6PFzSMWbWKOm3kj5jZjcHPB8AAEBeCRa03P1id9/H3cdKOlnSQ+5+eqjzAQAA5Bvm0QIAAAgk2BitbO5eL6l+MM4FAACQL2jRAgAACISgBQAAEAhBCxgM7eerCzh/HQAgfxC0gNBiMamqanu4co+2Y7FcVgUAGAQELSAkd6m5Waqp2R62qqqi7eZmWrYAoMgNyrcOgZJlJlVXR/draqKbJFVWRo+b5a42AEBwtGgBoWWHrQxCFgCUBIIWEFqmuzBb9pgtAEDRImgBIWWPyaqslFKp6Gf2mC0AQNFijBYQkplUVtZ2TFamG7GsjO5DAChyBC0gtFgsarnKhKpM2CJkAUDRo+sQGAztQxUhCwBKAkELAAAgEIIWAABAIAStrrA+HQAA6AeCVmdYnw4AAPQTQasjrE8HAAAGANM7dIT16QAAwACgRaszrE8HAAD6iaDVGdanAwCUIr4INqAIWh1hfToAQCnii2ADjjFaHWF9OgBAqcn+IpgU/d3LbnTIXkoMPUbQ6gzr0yGwRCKh2bNna8WKFRozZkyuywFQ6vgiWBB0HXaF9ekQUDweV2Njo+LxeK5LAYAIXwQbcCUZtBKJhMrLy7Vhw4bevZABghggiURCtbW1SqVSqq2t7f3vIgCEwBfBBlxJBq0+tSQwQBADKB6PK5VKSZJaWlpo1QKQe734IlifGyxKUMkFrT61JDBTPAZQ5ncwmUxKkpLJJK1aAHKvsy+CVVbu8EUwhj70XMkFrT61JGT/stXUSEOGbE/89F2jl7J/BzNo1QKQF2Kxtn/XMn//snpvGPrQOyUVtPrVksAAQQyQurq61t/BjGQyqSVLluSoIgDI0s0XwRj60DslFbT61ZLAAEEMkKamJrn7DrempqZclwYAXWLoQ++VVNDqc0sCM8UDAMDQhz4oqaDV55aEXgwQBACgWDH0ofeYGb6nmCkeAFDiGOLQeyXVotWh3kxCykzxAACgF0o7aDEJKQAACKh0gxaTkAIAgMBKd4wWq5QDAIDASrdFS2ISUgAAEFRpBy0mIQUAAAGVbtDqZhLSxGuvsTI5AADol9INWt1MQhq/7DJWJgcAAP1SuoPhpU4nIU1s2KDa8eNbVya/5JJLNGbMmJyWCgAACk/ptmhldDAJKSuTAwCAgUDQaoeVyQEAwEAhaLXDyuQAAGCgELTaYWVyAAAwUEp7MHwHWJkcAPoh+wtGHW0DJYYWLQDAwIjF2k76nJmvMBbLZVVAThG0AAD95y41N7dO+txmUujmZlbcQMkqiaCVSCSY5R0AQsqe9LmmRhoyZPvKG6whixJWEkErHo8zyzsAhJYJW9kIWShxRR+0MvNiZWZ5p1ULAALJdBdmyx6zBZSgog9azPIOAIMge0xWZaWUSm3vRiRsoYQVddBilncAGCRmUllZ2zFZmTFbZWV0H6JkFfU8Wl3N8r5o0aIcVQUARSoWaztvViZsEbJQwoq6RYtZ3gFgkLUPVYQslLiibtFilncAAJBLRd2iBQAAkEsELQAAgEAIWgAAAIEQtAAAAAIhaAEAgMHTfvLaIp/MlqAFAAAGRyzWdqWAzIoCsVguqwqKoAUAAMJzl5qb2y7LlFm2qbl5QFq2EomEysvL82oFGIIWAAAIL3tZppoaaciQ7WtjDtAKAvF4XI2NjXm1rjFBCwAADI5M2Mo2QCErs75xKpXKq3WNCVoAAGBwZLoLs2WP2eqH7PWNM+sa5wOCFgAACC97TFZlpZRKbe9G7GfYyrRmZdY3TiaTedOqRdACAADhmUllZW3HZGXGbJWV9av7MLs1KyNfWrWKelFpAACQR2KxqOUqE6oyYaufY7Tq6upaW7MyksmklixZokWLFvXr2P1F0AIAAIOnfagagIHwTU1N/T5GKHQdAgAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAoUfm4AC9QbAhaAFCi8nEBXqDYELQAoATl6wK8QLEhaAFACcrXBXiBYkPQAoASk88L8ALFhqAFACUmnxfgBYoNQQsASkxXC/ACGFgsKg0AJSafF+AFig0tWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABAIQQsAACAQghYAAEAgBC0AAIBACFoAAACBELQAAAACIWgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQIIFLTMbYWaPm9nTZvasmf0o1LkAAADy0bCAx35f0mfcfYuZDZe03Mz+x90fC3hOAACAvBEsaLm7S9qS3hyevnmo8wEAAOQbi/JQoIObDZW0UtInJS1y9+91sM95ks6TpNGjR89YvHhxsHoQzpYtWzRy5Mhcl4E+4voVLq5dYeP6FbZ58+atdPeZXe0TNGi1nsSsTNLdkr7h7s90tt+ECRN8/fr1wevBwKuvr9fcuXNzXQb6iOtXuLh2ha1grp+7ZNb5dokys26D1qB869DdmyXVSzp6MM4HAAAGSCwmVVVF4UqKflZVRY+jWyG/dTg63ZIlM9tJ0uckrQt1PgAAMMDcpeZmqaZme9iqqoq2m5u3hy90KuS3DveSdGN6nNYQSYvd/d6A5wMAAAPJTKquju7X1EQ3SaqsjB6n+7BbIb91uFrStFDHBwAAgyATtjIhSyJk9QIzwwMAgM5luguzZY/ZQpcIWgAAoGPZY7IqK6VUKvqZPWYLXQo5RgsAABQyM6msrO2YrMyYrbIyug97gKAFAAA6F4u1nTcrE7YIWT1C1yEAAOha+1BFyOoxghYAAEAgBC0AAIBACFoAAACBELQAAAACIWgBAAAEQtACAAAIhKAFACgN7WcxZ1ZzDAKCFgCg+MVibZeMySwtE4vlsiqUAIIWAKC4uUvNzW3X58us39fcTMsWgmIJHgBAccten6+mJrpJbdfvAwKhRQsAUPyyw1YGIQuDgKAFACh+me7CbNljtoBACFoAgOKWPSarslJKpaKf2WO2gEAYowUAKG5mUllZ2zFZmW7EsjK6DxEUQQsAUPxisajlKhOqMmGLkIXAuuw6tMi+g1UMAADBtA9VhCwMgi6Dlru7pHsGpxQAAJCRSCRUXl6uDRs25LoU9ENPBsM/ZmafCl4JAABoFY/H1djYqHg8nutS0A89CVrzFIWtv5jZajNbY2arQxcGAECpSiQSqq2tVSqVUm1tLa1aBawng+G/GLwKAADQKh6PK5VKSZJaWloUj8e1aNGiHFeFvui2RcvdX5a0r6TPpO+/15PXAQCA3su0ZiWTSUlSMpmkVauAdRuYzOyHkr4n6eL0Q8Ml3RyyKAAASlV2a1ZGplULhacnLVNfkXSMpHclyd1fkzQqZFEAAJSqurq61tasjGQyqSVLluSoIvRHT8ZoJd3dzcwlycx2CVwTAAAlq6mpKdclYAD1pEVrsZn9t6QyMztX0gOSfhW2LAAAgMLXbYuWu19pZp+X9I6kCZJ+4O5/Cl4ZAABAgevRWofpYEW4AgAA6IVOg5aZbZbknT3v7rsGqQgAAKBIdBq03H2UJJnZpZI2SLpJkkk6TXzrEAAAoFs9GQz/BXf/pbtvdvd33P1qSSeELgwAAKDQ9SRotZjZaWY21MyGmNlpklpCFwYAAFDoehK0TpX0z5JeT98WpB8DkM29622ghCUSCZWXl7OMDEpOT9Y6bHT3Y919D3cf7e7HuXvjINQGFI5YTKqq2h6u3KPtWCyXVQF5Ix6Pq7GxkWVkUHJ6stbhCDP7upn90syuz9wGozigILhLzc1STc32sFVVFW03N9OyhZKXWSQ5lUqxODJKTk+6Dm+SNEbSFyT9WdI+kjaHLAooKGZSdbVUWRmFqyFDop+VldHjZrmuEMip7EWSWRwZpaYnQeuT7n6JpHfd/UZJX5Y0OWxZQIHJhK1shCygtTUrs0hyMpmkVQslpSdB64P0z2YzO1jSbpLGBqsIKESZ7sJs2WO2gBKV3ZqVQasWSklPgta1ZvYRSZdIqpP0nKSfBq0KKCTZY7IqK6VUans3ImELJa6urq61NSsjmUxqyZIlOaoIGFw9WVT6uvTdP0saH7YcoACZSWVlbcdkZboRy8roPkRJa2pqynUJQE51G7TM7GOSfizp4+7+RTObJOlQd/918OqAQhGLRS1XmVCVCVuELAAoaT3pOrxB0h8lfTy9/byk/xOoHqBwtQ9VhCwAKHk9CVp7uPtiSSlJcvdtYgkeAACAbvUkaL1rZrtLckkys1mSNgWtCgAAoAj0JGh9S9G3DcvNbIWk30j6RtCqgALDOm4AgI50GbTMbKikOenbYZL+VdJB7r56EGoDCgbruAEAOtJl0HL3FknHuvs2d3/W3Z9x9w+6eg1QaljHDQDQmZ50Ha4ws1+Y2RFmNj1zC14ZUCBYxw0A0JmeBK3DJB0k6VJJ/1/6dmXIooBCwTpuAICu9GRm+HmDUQhQiLpax23RokU5qgoAkC960qIFoBOs4wYA6Eq3LVoAOsc6bgCArtCiBQAAEEiXLVrpGeFPlTQx/dBaSbe5+1uhCwMAACh0nbZomdmBkp6RNEPRQtIvSPqUpDVmNrGz1wEAACDSVYtWXFJlekHpVmZ2gqT/lHRCyMIAAAAKXVdjtCa3D1mS5O53Sjo4XEkAAADFoaug9W4fnwMAAIC67jrc08y+1cHjJml0oHoAAACKRldB61eSRnXy3HUBagEAACgqnQYtd//RYBYCAABQbDoNWmZ2VVcvdPdvDnw5AAAAxaOrrsOVg1YFAABAEeoqaN3i7tsGrRIAAIAi09X0Do9n7pjZ/z8ItQAAABSVroKWZd0/PHQhAAAAxaaroOWDVgUAAEAR6mqM1kQzW62oZas8fV/pbXf3KcGrAwAAKGBdBa0DB60KAACAItTVhKUvd/S4mQ2VdLKkDp8HAABApNMxWma2q5ldbGa/MLOjLPINSS9J+ufBKxEAAKAwddV1eJOkv0t6VNLXJH1X0ockHevuDeFLAwAAKGxdBa3x7j5ZkszsOklvSvqEu28elMoAAAAKXFfTO3yQuePuLZL+SsgCAADoua5atKaa2Tvp+yZpp/R2ZnqHXYNXBwAAUMC6+tbh0MEsBAAAoNh01XUIAACAfiBoAQAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAAgEAIWgAKk3vX2wCQBwhaAApPLCZVVW0PV+7RdiyWy6oAYAcELQCFxV1qbpZqaraHraqqaLu5mZYtAHmlq7UOgcHlLpl1vg1I0e9EdXV0v6YmuklSZWX0OL8zAPIILVrID3QFoTeyw1YGIQtAHiJoIffoCkJvZX5HsmUHdQDIEwQt5F6mdaKyMgpXQ4ZEP+kKQkeyg3hlpZRKbf/dIWwByDMELeQHuoLQU2ZSWVnbIJ4J6mVl/M4AyCsMhkd+6KwriLCFjsRibb8skQlb/K4AyDO0aCH36ApCX7QPVYQsAHmIFi3kXmddQRJdQQCAgkbQQn6gKwgAUISCdR2a2b5m9rCZrTWzZ82sMtS5UCToCgIAFJmQLVrbJH3b3VeZ2ShJK83sT+7+XMBzAgAA5I1gLVrunnD3Ven7myWtlbR3qPMBAADkG/NB+EaXmY2VtFTSwe7+TrvnzpN0niSNHj16xuLFi4PXg4G3ZcsWjRw5MtdloI+4foWLa1fYuH6Fbd68eSvdfWZX+wQPWmY2UtKfJf2nu9/V1b4TJkzw9evXB60HYdTX12vu3Lm5LgN9lG/XL5FIaPbs2VqxYoXGjBmT63LyWr5dO/QO16+wmVm3QSvoPFpmNlzSnZJu6S5koTQlEgmVl5drw4YNuS4FeSQej6uxsVHxeDzXpQBAv4T81qFJ+rWkte7+s1DnQWHjDyraSyQSqq2tVSqVUm1tLSEcQEEL2aJ1uKQzJH3GzBrSty8FPB8KDH9Q0ZF4PK5UKiVJamlpIYQDKGghv3W43N3N3ae4e0X69odQ50Ph4Q8q2suE72QyKUlKJpOEcAAFjbUOkRP8QUVHssN3BiEcQCEjaCEn+IOKjtTV1bWG74xkMqklS5bkqCIA6B+CFnKCP6joSFNTk9x9h1tTU1OuSwOAPmFRaeQEfzgBAKWAFi0AAIBACFoAAACBELQAAAACIWgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAD0l3vX2yhZBC0AAPojFpOqqraHK/doOxbLZVXIEwQtAAD6yl1qbpZqaraHraqqaLu5mZYtsKg0AAB9ZiZVV0f3a2qimyRVVkaPm+WuNuQFWrQAAOiP7LCVQchCGkELAID+yHQXZsses4WSRtACAKCvssdkVVZKqVT0M3vMFkoaY7QAAOgrM6msrO2YrEw3YlkZ3YcgaAEA0C+xWNRylQlVmbBFyILoOgQAoP/ahypCFtIIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABAIQQsAACAQghYAAEAgBC0AAIBACFoAAACBELQAAAACIWgBAAAEQtACAOREIpFQeXm5NmzYkOtSgGAIWgCAnIjH42psbFQ8Hs91KUAwBC0AwKBLJBKqra1VKpVSbW0trVooWgQtAMCgi8fjSqVSkqSWlhZatVC0CFoAgEGVac1KJpOSpGQySasWihZBCwAwqLJbszJo1UKxImgBAAZVXV1da2tWRjKZ1JIlS3JUERDOsFwXAAAoLU1NTbkuARg0tGgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0AAAAAiFoAQAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAwGBw73obRYmgBQBAaLGYVFW1PVy5R9uJRE7LQngELQAAQnKXmpulmprtYauqKtreto2WrSI3LNcFAABQ1Myk6urofk1NdJOkykpp332j51G0aNECACC07LCV0X4bRYmgBQBAaJnuwmztt1GUCFoAAISUPSarslJKpaKfNTXSK68wRqvIMUYLAICQzKSysihcVVe37UYcNowxWkWOoAUAQGixWNRylQlVmbD15z/ntCyER9chAACDoX3LFS1ZJYGgBQAAEAhBCwAAIBCCFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAyEuJRELl5eXasGFDrksB+oygBQDIS/F4XI2NjYrH47kuBegzghYAIO8kEgnV1tYqlUqptraWVi0ULIIWACDvxONxpVIpSVJLSwutWihYBC0AQF7JtGYlk0lJUjKZpFULBYugBQDIK9mtWRm0aqFQEbQAAHmlrq6utTUrI5lMasmSJTmqCOi7YbkuAACAbE1NTbkuARgwtGgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0AAAAAiFoAQAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAAgECCBS0zu97MNprZM6HOAQAAkM9CtmjdIOnogMcHAADIa8GClrsvlfR2qOMDAADkO3P3cAc3GyvpXnc/uIt9zpN0niSNHj16xuLFi4PVg3C2bNmikSNH5roM9BHXr3Bx7Qob16+wzZs3b6W7z+xqn5wHrWwTJkzw9evXB6sH4dTX12vu3Lm5LgN9xPUrXFy7wsb1K2xm1m3Q4luHAAAAgRC0AAAAAgk5vcNtkh6VNMHMmszsq6HOBQAAkI+GhTqwu58S6tgAAACFgK5DAACAQAhaAAAAgRC0AAAAAiFoAQAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABAIQQuFx73rbQAA8gRBC4UlFpOqqraHK/doOxbLZVUAAHSIoIXC4S41N0s1NdvDVlVVtN3cTMsWACDvDMt1AUCPmUnV1dH9mproJkmVldHjZrmrDQCADtCihcKSHbYyCFkAgDxF0EJBSCQSKi8v14ZEIuouzJY9ZgsAgDxC0EJBiMfjavzrX/Xc0UdHXYaVlVIqFf3MHrMFAEAeYYwW8l4ikVBtba1S7nr0ued0yNe+pl0y3YWZbsSyMroPAQB5h6CFvBePx5VKpSRJlw4ZoteGD9eiTKjKhC1CFgAgD9F1iLyWac1KJpOSpGQyqdobbtCGDRu270TIAgDkKYIW8lp2a1ZGS0uL4vF4jioCAKDnCFrIa3V1da2tWRnJZFJLlizJUUUAAPQcY7SQ15qamnJdAgAAfUaLFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABAIQQsAACAQghYAAEAgBC0AAAaCe9fbKEkELQAA+isWk6qqtocr92g7FstlVcgDBC0AAPrDXWpulmpqtoetqqpou7mZlq0Sx6LSAAD0h5lUXR3dr6mJbpJUWRk9bpa72pBztGgBANBf2WErg5AFEbQAAOi/THdhtuwxWyhZBC0AAPoje0xWZaWUSkU/s8dsoWQxRgsAgP4wk8rK2o7JynQjlpXRfVjiCFoAAPRXLBa1XGVCVSZsEbJKHl2HAAAMhPahipAFEbQAAACCIWgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0ACCftF8Xj3XygIJG0AKAfBGLtV2EOLNYcSyWy6oA9ANBCwDygbvU3CzV1GwPW1VV0XZzMy1bQIFiUWkAyAeZRYilKFzV1ET3KytZnBgoYLRoAUC+yA5bGYQsoKARtAAgX2S6C7Nlj9kCUHAIWgBKViKRUHl5uTZs2JDrUtqOyaqslFKp6Gf2mC0ABYegBaBkxeNxNTY2Kh6P57qUqHuwrKztmKzq6mi7rIzuQ6BAMRgeQElKJBKqra1VKpVSbW2tLrnkEo0ZMya3RcViUctVJlRlwhYhCyhYtGgBKEnxeFypVEqS1NLSkh+tWtKOoYqQNSDyqpsYJYWgBaDkZFqzksmkJCmZTKq2tpY/wkUsr7qJUVIIWgBKTnZrVkZetWphQLXvJiZQYzARtACUnLq6utbWrIxkMqklS5bkqCKElLfdxCgJBC0AJaepqUnuvsOtqakp16VhgNFNjFwjaAEAihbdxMg1ghYAoGjRTYxcYx4tAEDRojsYuUaLFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABAIQQsAACAQghYAAEAgBC0AAIBACFoAAACBELQAAAACIWgBAAAEQtACAAAIhKAFAAAQCEELAAAgEIIWAABAIAQtAACAQAhaAAAAgRC0AAAAAiFoAQAABELQAgAACISgBQAAEAhBCwAAIBCCFgAAQCAELQAAgEAIWgAAAIEQtAAAAAIhaAEAAAQSNGiZ2dFmtt7MXjSzi0KeCwAAIN8EC1pmNlTSIklflDRJ0ilmNinU+QAAAPJNyBatT0t60d1fcvekpN9KOjbg+QAAAPLKsIDH3lvSK1nbTZIOab+TmZ0n6bz05vtm9kzAmhDOHpLezHUR6DOuX+Hi2hU2rl9hm9DdDiGDlnXwmO/wgPu1kq6VJDN70t1nBqwJgXDtChvXr3Bx7Qob16+wmdmT3e0TsuuwSdK+Wdv7SHot4PkAAADySsig9YSk/c1snJl9SNLJkuoCng8AACCvBOs6dPdtZnahpD9KGirpend/tpuXXRuqHgTHtStsXL/CxbUrbFy/wtbt9TP3HYZNAQAAYAAwMzwAAEAgBC0AAIBA8iJosVRP4TKz681sI/OfFR4z29fMHjaztWb2rJlV5rom9JyZjTCzx83s6fT1+1Gua0LvmNlQM3vKzO7NdS3oHTNrNLM1ZtbQ3RQPOR+jlV6q53lJn1c0JcQTkk5x9+dyWhh6xMyOlLRF0m/c/eBc14OeM7O9JO3l7qvMbJSklZKO47+9wmBmJmkXd99iZsMlLZdU6e6P5bg09JCZfUvSTEm7uvv8XNeDnjOzRkkz3b3byWbzoUWLpXoKmLsvlfR2rutA77l7wt1Xpe9vlrRW0YoOKAAe2ZLeHJ6+8e2mAmFm+0j6sqTrcl0LwsqHoNXRUj38Yw8MIjMbK2mapP/NcSnohXTXU4OkjZL+5O5cv8Lxc0n/JimV4zrQNy7pfjNbmV5KsFP5ELR6tFQPgDDMbKSkOyX9H3d/J9f1oOfcvcXdKxStvPFpM6P7vgCY2XxJG919Za5rQZ8d7u7TJX1R0tfTw2g6lA9Bi6V6gBxJj+25U9It7n5XrutB37h7s6R6SUfnthL00OGSjkmP8/mtpM+Y2c25LQm94e6vpX9ulHS3omFQHcqHoMVSPUAOpAdT/1rSWnf/Wa7rQe+Y2WgzK0vf30nS5ySty2lR6BF3v9jd93H3sYr+5j3k7qfnuCz0kJntkv4CkcxsF0lHSer0m/c5D1ruvk1SZqmetZIW92CpHuQJM7tN0qOSJphZk5l9Ndc1occOl3SGov+bbkjfvpTrotBje0l62MxWK/of1j+5O9MEAOF9TNJyM3ta0uOSfu/u93W2c86ndwAAAChWOW/RAgAAKFYELQAAgEAIWgAAAIEQtAAAAAIhaAEAAARC0AIAAAiEoAUAABDI/wOLBeHNanFsfgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_distill[:, 0], y_distill[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with KD')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_distill.jpg', dpi=750, bbox_inches = 'tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义问题类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MOEA(ea.Problem):\n",
    "    def __init__(self, train_data_loader, test_data_loader):\n",
    "        name = 'MOEA'\n",
    "        M = 1 # 初始化M（目标维数）\n",
    "        maxormins = [-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标）\n",
    "        Dim = 2 # 初始化Dim（决策变量维数）\n",
    "        varTypes = np.array([0] * Dim) # 初始化varTypes 0-连续\n",
    "        lb = [5, 0.1] # 决策变量下界\n",
    "        ub = [10, 0.9] # 决策变量上界\n",
    "        lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含）\n",
    "        ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含）\n",
    "        # 调用父类构造方法完成实例化\n",
    "        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)\n",
    "        # 数据设置\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.test_data_loader = test_data_loader\n",
    "\n",
    "\n",
    "    # 目标函数，采用多线程加速计算\n",
    "    def aimFunc(self, pop):\n",
    "        Vars = pop.Phen # 得到决策变量矩阵\n",
    "        # print(Vars)\n",
    "        pop.ObjV = np.zeros((pop.sizes, 1)) # 初始化种群个体目标函数值列向量\n",
    "        def subAimFunc(i):\n",
    "            epochs, alpha = int(Vars[i, 0]), float(Vars[i, 1])\n",
    "            print(epochs, alpha)\n",
    "            final_loss = 0\n",
    "            for epoch in range(epochs):\n",
    "                for data,targets in tqdm(train_data_loader):\n",
    "                    data, targets = data.to(device), targets.to(device)\n",
    "                    # 教师模型预测\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(data)\n",
    "                    # 学生模型预测\n",
    "                    student_outputs = model(data)\n",
    "                    student_loss = hard_loss(student_outputs, targets)\n",
    "                    # 计算蒸馏后的预测结果及soft_loss\n",
    "                    distillation_loss = soft_loss(\n",
    "                        F.softmax(student_outputs/T, dim=1),\n",
    "                        F.softmax(teacher_outputs/T, dim=1)\n",
    "                    )\n",
    "                    # 将 hard_loss 和 soft_loss 加权求和\n",
    "                    loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                    final_loss = loss.item()\n",
    "                    # 反向传播,优化权重\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            pop.ObjV[i] = final_loss # 最小化最终的损失作为目标函数\n",
    "        pool = ThreadPool(processes=2) # 设置池的大小\n",
    "        pool.map(subAimFunc, list(range(pop.sizes))) # 散列种群每个个体进行加速计算\n",
    "\n",
    "\n",
    "    # 代入优化后的参数先训练再对测试集进行检验，计算指标\n",
    "    def test(self, epochs, alpha):\n",
    "        for epoch in range(epochs):\n",
    "            for data,targets in tqdm(train_data_loader):\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                # 教师模型预测\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(data)\n",
    "                # 学生模型预测\n",
    "                student_outputs = model(data)\n",
    "                student_loss = hard_loss(student_outputs, targets)\n",
    "                # 计算蒸馏后的预测结果及soft_loss\n",
    "                distillation_loss = soft_loss(\n",
    "                    F.softmax(student_outputs/T, dim=1),\n",
    "                    F.softmax(teacher_outputs/T, dim=1)\n",
    "                )\n",
    "                # 将 hard_loss 和 soft_loss 加权求和\n",
    "                loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                # 反向传播,优化权重\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 测试集上评估性能\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x,y in test_data_loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    outputs = model(x)\n",
    "                    pred = outputs.max(1).indices\n",
    "                    num_correct += (pred == y).sum()\n",
    "                    num_samples += pred.size(0)\n",
    "                acc = (num_correct/num_samples).item()\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n",
    "\n",
    "        torch.save(model.state_dict(), \"./models/moea_distillation.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参数调优"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.3189171239733696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2855765145272017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 2/938 [00:00<00:54, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8424268286675215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 3/938 [00:00<00:39, 23.75it/s]\u001B[A\u001B[A\n",
      "  0%|          | 2/938 [00:00<00:52, 17.78it/s]\u001B[A\n",
      "\n",
      "  1%|          | 6/938 [00:00<00:44, 20.86it/s]\u001B[A\u001B[A\n",
      "  0%|          | 4/938 [00:00<00:51, 18.15it/s]\u001B[A\n",
      "\n",
      " 94%|█████████▎| 878/938 [00:08<00:01, 36.62it/s]A\u001B[A\n",
      " 94%|█████████▎| 878/938 [00:08<00:00, 102.62it/s]\n",
      "\n",
      "\n",
      "  1%|          | 9/938 [00:00<00:48, 19.11it/s]]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8656420316547155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 1/938 [00:00<01:05, 14.39it/s]]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.6277091335505247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 4/938 [00:00<00:25, 37.06it/s]]\u001B[A\u001B[A\n",
      "\n",
      "  1%|          | 10/938 [00:00<00:26, 34.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  3%|▎         | 31/938 [00:00<00:23, 38.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "  4%|▍         | 38/938 [00:01<00:19, 45.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "  5%|▍         | 46/938 [00:01<00:16, 54.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "  6%|▌         | 54/938 [00:01<00:14, 61.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "  7%|▋         | 65/938 [00:01<00:11, 74.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "  8%|▊         | 76/938 [00:01<00:10, 83.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "  9%|▉         | 86/938 [00:01<00:09, 88.29it/s]\u001B[A\u001B[A\n",
      "\n",
      " 10%|█         | 96/938 [00:01<00:09, 89.71it/s]\u001B[A\u001B[A\n",
      "\n",
      " 11%|█▏        | 106/938 [00:01<00:09, 85.26it/s]\u001B[A\u001B[A\n",
      "\n",
      " 12%|█▏        | 116/938 [00:01<00:09, 87.53it/s]\u001B[A\u001B[A\n",
      "\n",
      " 13%|█▎        | 125/938 [00:02<00:09, 87.56it/s]\u001B[A\u001B[A\n",
      "\n",
      " 14%|█▍        | 134/938 [00:02<00:09, 86.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 15%|█▌        | 143/938 [00:02<00:09, 87.52it/s]\u001B[A\u001B[A\n",
      "\n",
      " 16%|█▌        | 152/938 [00:02<00:09, 86.56it/s]\u001B[A\u001B[A\n",
      "\n",
      " 17%|█▋        | 163/938 [00:02<00:08, 92.49it/s]\u001B[A\u001B[A\n",
      "\n",
      " 19%|█▊        | 174/938 [00:02<00:08, 95.28it/s]\u001B[A\u001B[A\n",
      "\n",
      " 20%|█▉        | 184/938 [00:02<00:08, 92.35it/s]\u001B[A\u001B[A\n",
      "\n",
      " 21%|██        | 194/938 [00:02<00:08, 92.09it/s]\u001B[A\u001B[A\n",
      "\n",
      " 22%|██▏       | 205/938 [00:02<00:07, 96.28it/s]\u001B[A\u001B[A\n",
      "\n",
      " 23%|██▎       | 216/938 [00:03<00:07, 99.24it/s]\u001B[A\u001B[A\n",
      "\n",
      " 24%|██▍       | 226/938 [00:03<00:07, 97.81it/s]\u001B[A\u001B[A\n",
      "\n",
      " 25%|██▌       | 237/938 [00:03<00:07, 100.07it/s]\u001B[A\u001B[A\n",
      "\n",
      " 26%|██▋       | 248/938 [00:03<00:06, 101.80it/s]\u001B[A\u001B[A\n",
      "\n",
      " 28%|██▊       | 260/938 [00:03<00:06, 104.55it/s]\u001B[A\u001B[A\n",
      "\n",
      " 29%|██▉       | 272/938 [00:03<00:06, 106.73it/s]\u001B[A\u001B[A\n",
      "\n",
      " 30%|███       | 283/938 [00:03<00:06, 105.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 31%|███▏      | 295/938 [00:03<00:05, 107.48it/s]\u001B[A\u001B[A\n",
      "\n",
      " 33%|███▎      | 306/938 [00:03<00:05, 107.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 34%|███▍      | 317/938 [00:03<00:05, 106.38it/s]\u001B[A\u001B[A\n",
      "\n",
      " 35%|███▍      | 328/938 [00:04<00:05, 105.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 36%|███▌      | 339/938 [00:04<00:05, 107.02it/s]\u001B[A\u001B[A\n",
      "\n",
      " 37%|███▋      | 351/938 [00:04<00:05, 108.31it/s]\u001B[A\u001B[A\n",
      "\n",
      " 39%|███▊      | 362/938 [00:04<00:05, 106.19it/s]\u001B[A\u001B[A\n",
      "\n",
      " 40%|███▉      | 374/938 [00:04<00:05, 107.98it/s]\u001B[A\u001B[A\n",
      "\n",
      " 41%|████      | 385/938 [00:04<00:05, 106.42it/s]\u001B[A\u001B[A\n",
      "\n",
      " 42%|████▏     | 397/938 [00:04<00:04, 108.32it/s]\u001B[A\u001B[A\n",
      "\n",
      " 44%|████▎     | 409/938 [00:04<00:04, 109.17it/s]\u001B[A\u001B[A\n",
      "\n",
      " 45%|████▍     | 421/938 [00:04<00:04, 111.22it/s]\u001B[A\u001B[A\n",
      "\n",
      " 46%|████▌     | 433/938 [00:05<00:04, 112.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 47%|████▋     | 445/938 [00:05<00:04, 111.32it/s]\u001B[A\u001B[A\n",
      "\n",
      " 49%|████▊     | 457/938 [00:05<00:04, 112.26it/s]\u001B[A\u001B[A\n",
      "\n",
      " 50%|█████     | 469/938 [00:05<00:04, 108.13it/s]\u001B[A\u001B[A\n",
      "\n",
      " 51%|█████▏    | 481/938 [00:05<00:04, 110.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 53%|█████▎    | 493/938 [00:05<00:03, 111.45it/s]\u001B[A\u001B[A\n",
      "\n",
      " 54%|█████▍    | 505/938 [00:05<00:03, 111.51it/s]\u001B[A\u001B[A\n",
      "\n",
      " 55%|█████▌    | 517/938 [00:05<00:03, 112.92it/s]\u001B[A\u001B[A\n",
      "\n",
      " 56%|█████▋    | 529/938 [00:05<00:03, 113.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 58%|█████▊    | 541/938 [00:05<00:03, 113.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 59%|█████▉    | 553/938 [00:06<00:03, 112.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 60%|██████    | 565/938 [00:06<00:03, 113.01it/s]\u001B[A\u001B[A\n",
      "\n",
      " 62%|██████▏   | 577/938 [00:06<00:03, 113.99it/s]\u001B[A\u001B[A\n",
      "\n",
      " 63%|██████▎   | 589/938 [00:06<00:03, 114.94it/s]\u001B[A\u001B[A\n",
      "\n",
      " 64%|██████▍   | 601/938 [00:06<00:02, 115.34it/s]\u001B[A\u001B[A\n",
      "\n",
      " 65%|██████▌   | 613/938 [00:06<00:02, 112.19it/s]\u001B[A\u001B[A\n",
      "\n",
      " 67%|██████▋   | 625/938 [00:06<00:02, 113.47it/s]\u001B[A\u001B[A\n",
      "\n",
      " 68%|██████▊   | 637/938 [00:06<00:02, 114.37it/s]\u001B[A\u001B[A\n",
      "\n",
      " 69%|██████▉   | 649/938 [00:06<00:02, 114.63it/s]\u001B[A\u001B[A\n",
      "\n",
      " 70%|███████   | 661/938 [00:07<00:02, 115.88it/s]\u001B[A\u001B[A\n",
      "\n",
      " 72%|███████▏  | 673/938 [00:07<00:02, 115.04it/s]\u001B[A\u001B[A\n",
      "\n",
      " 73%|███████▎  | 685/938 [00:07<00:02, 106.64it/s]\u001B[A\u001B[A\n",
      "\n",
      " 74%|███████▍  | 696/938 [00:07<00:02, 105.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 75%|███████▌  | 708/938 [00:07<00:02, 109.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 77%|███████▋  | 719/938 [00:07<00:02, 106.84it/s]\u001B[A\u001B[A\n",
      "\n",
      " 78%|███████▊  | 731/938 [00:07<00:01, 109.64it/s]\u001B[A\u001B[A\n",
      "\n",
      " 79%|███████▉  | 743/938 [00:07<00:01, 112.57it/s]\u001B[A\u001B[A\n",
      "\n",
      " 80%|████████  | 755/938 [00:07<00:01, 113.94it/s]\u001B[A\u001B[A\n",
      "\n",
      " 82%|████████▏ | 767/938 [00:08<00:01, 110.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 83%|████████▎ | 779/938 [00:08<00:01, 109.68it/s]\u001B[A\u001B[A\n",
      "\n",
      " 84%|████████▍ | 791/938 [00:08<00:01, 112.01it/s]\u001B[A\u001B[A\n",
      "\n",
      " 86%|████████▌ | 803/938 [00:08<00:01, 105.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 87%|████████▋ | 814/938 [00:08<00:01, 103.05it/s]\u001B[A\u001B[A\n",
      "\n",
      " 88%|████████▊ | 825/938 [00:08<00:01, 103.50it/s]\u001B[A\u001B[A\n",
      "\n",
      " 89%|████████▉ | 836/938 [00:08<00:00, 104.69it/s]\u001B[A\u001B[A\n",
      "\n",
      " 90%|█████████ | 848/938 [00:08<00:00, 106.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 92%|█████████▏| 859/938 [00:08<00:00, 106.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 93%|█████████▎| 871/938 [00:09<00:00, 108.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 94%|█████████▍| 882/938 [00:09<00:00, 104.92it/s]\u001B[A\u001B[A\n",
      "\n",
      " 95%|█████████▌| 893/938 [00:09<00:00, 104.17it/s]\u001B[A\u001B[A\n",
      "\n",
      " 96%|█████████▋| 904/938 [00:09<00:00, 99.99it/s] \u001B[A\u001B[A\n",
      "\n",
      " 98%|█████████▊| 915/938 [00:09<00:00, 100.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 99%|█████████▊| 926/938 [00:09<00:00, 101.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "100%|██████████| 938/938 [00:09<00:00, 96.68it/s] \u001B[A\u001B[A\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.38it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 105.10it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 112.47it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.13it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.2740337282419205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 109.97it/s]\n",
      "100%|██████████| 938/938 [00:07<00:00, 118.57it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.56it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.24it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 104.54it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.32it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 106.33it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 116.82it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-e006b3843ce3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m \u001B[0;34m[\u001B[0m\u001B[0mBestIndi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpopulation\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmyAlgorithm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 执行算法模板，得到最优个体以及最后一代种群\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m \u001B[0mBestIndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 把最优个体的信息保存到文件中\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/templates/soeas/DE/DE_rand_1_bin/soea_DE_rand_1_bin_templet.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, prophetPop)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;31m# ===========================准备进化============================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0mpopulation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minitChrom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNIND\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 初始化种群染色体矩阵\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_aimFunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpopulation\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 计算种群的目标函数值\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;31m# 插入先验知识（注意：这里不会对先知种群prophetPop的合法性进行检查，故应确保prophetPop是一个种群类且拥有合法的Chrom、ObjV、Phen等属性）\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mprophetPop\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/Algorithm.py\u001B[0m in \u001B[0;36mcall_aimFunc\u001B[0;34m(self, pop)\u001B[0m\n\u001B[1;32m    172\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproblem\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'error: problem has not been initialized. (算法模板中的问题对象未被初始化。)'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproblem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maimFunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 调用问题类的aimFunc()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m  \u001B[0;31m# 更新评价次数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0;31m# 格式检查\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-29ea1f645391>\u001B[0m in \u001B[0;36maimFunc\u001B[0;34m(self, pop)\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mObjV\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfinal_loss\u001B[0m \u001B[0;31m# 最小化最终的损失作为目标函数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mpool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mThreadPool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocesses\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 设置池的大小\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubAimFunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 散列种群每个个体进行加速计算\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m         \u001B[0;32min\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mthat\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mreturned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         '''\n\u001B[0;32m--> 364\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstarmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    769\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    770\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 771\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    772\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    773\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mworker\u001B[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0mjob\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mwrap_exception\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mfunc\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_helper_reraises_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmapstar\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mstarmapstar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-29ea1f645391>\u001B[0m in \u001B[0;36msubAimFunc\u001B[0;34m(i)\u001B[0m\n\u001B[1;32m     45\u001B[0m                     \u001B[0;31m# 反向传播,优化权重\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m                     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    394\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    395\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 396\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    397\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    398\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    171\u001B[0m     \u001B[0;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[0;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 173\u001B[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[0;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "\"\"\"===============================实例化问题对象===========================\"\"\"\n",
    "\n",
    "problem = MOEA(train_data_loader, test_data_loader) # 生成问题对象\n",
    "\n",
    "\"\"\"=================================种群设置===============================\"\"\"\n",
    "\n",
    "Encoding = 'RI'       # 编码方式\n",
    "NIND = 10             # 种群规模\n",
    "Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器\n",
    "population = ea.Population(Encoding, Field, NIND) # 实例化种群对象（此时种群还没被初始化，仅仅是完成种群对象的实例化）\n",
    "\n",
    "\"\"\"===============================算法参数设置=============================\"\"\"\n",
    "\n",
    "myAlgorithm = ea.soea_DE_rand_1_bin_templet(problem, population) # 实例化一个算法模板对象\n",
    "myAlgorithm.MAXGEN = 10 # 最大进化代数\n",
    "myAlgorithm.trappedValue = 1e-6 # “进化停滞”判断阈值\n",
    "myAlgorithm.maxTrappedCount = 10 # 进化停滞计数器最大上限值，如果连续maxTrappedCount代被判定进化陷入停滞，则终止进化\n",
    "myAlgorithm.logTras = 1  # 设置每隔多少代记录日志，若设置成0则表示不记录日志\n",
    "myAlgorithm.verbose = True  # 设置是否打印输出日志信息\n",
    "myAlgorithm.drawing = 1  # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画）\n",
    "\n",
    "\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\n",
    "\n",
    "[BestIndi, population] = myAlgorithm.run()  # 执行算法模板，得到最优个体以及最后一代种群\n",
    "BestIndi.save()  # 把最优个体的信息保存到文件中\n",
    "\n",
    "\"\"\"==================================输出结果=============================\"\"\"\n",
    "\n",
    "print('用时：%f 秒' % myAlgorithm.passTime)\n",
    "print('评价次数：%d 次' % myAlgorithm.evalsNum)\n",
    "if BestIndi.sizes != 0:\n",
    "    print('最优的目标函数值为：%s' % BestIndi.ObjV[0][0])\n",
    "    print('最优的控制变量值为：')\n",
    "    for i in range(BestIndi.Phen.shape[1]):\n",
    "        print(BestIndi.Phen[0, i])\n",
    "else:\n",
    "    print('没找到可行解。')\n",
    "\n",
    "\"\"\"=================================检验结果===============================\"\"\"\n",
    "\n",
    "problem.test(epochs= int(BestIndi.Phen[0][0]), alpha= float(BestIndi.Phen[0][1]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
