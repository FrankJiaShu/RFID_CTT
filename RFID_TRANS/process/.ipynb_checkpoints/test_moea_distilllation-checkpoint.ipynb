{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 知识蒸馏-mnist手写数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import utils.calculate_param as cp\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geatpy as ea\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 没有就下载-手写数据集\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 设备准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取设备类型\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 定义教师模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, num_classes= 10):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(784, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 1200)\n",
    "        self.fc3 = nn.Linear(1200, num_classes)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "\n",
    "    # 处理逻辑：fc1->dropout->relu->fc2->dropout->relu->fc3\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,784)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 教师模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = TeacherModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 设置使用交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4) # 使用Adam优化器，学习率为lr=1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 教师模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "TeacherModel                             [64, 10]                  --\n",
      "├─Linear: 1-1                            [64, 1200]                942,000\n",
      "├─Dropout: 1-2                           [64, 1200]                --\n",
      "├─ReLU: 1-3                              [64, 1200]                --\n",
      "├─Linear: 1-4                            [64, 1200]                1,441,200\n",
      "├─Dropout: 1-5                           [64, 1200]                --\n",
      "├─ReLU: 1-6                              [64, 1200]                --\n",
      "├─Linear: 1-7                            [64, 10]                  12,010\n",
      "==========================================================================================\n",
      "Total params: 2,395,210\n",
      "Trainable params: 2,395,210\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 153.29\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 1.23\n",
      "Params size (MB): 9.58\n",
      "Estimated Total Size (MB): 11.02\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出模型的参数信息-100w参数\n",
    "cp.get_summary(model, input_size=(64, 1, 28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 教师模型训练&评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t Accuracy:0.832200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2\t Accuracy:0.848900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3\t Accuracy:0.856800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:21<00:00, 43.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4\t Accuracy:0.863300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:21<00:00, 43.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5\t Accuracy:0.869300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6\t Accuracy:0.871100\n",
      "CPU times: user 4min 17s, sys: 13.6 s, total: 4min 30s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 6 # 训练6轮\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for data,targets in tqdm(train_dataloader):\n",
    "        # 前向预测\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 反向传播，优化权重\n",
    "        optimizer.zero_grad()  # 把梯度置为0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 测试集上评估性能 进入评估模式\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dataloader:\n",
    "            outputs = model(x)\n",
    "            predictions = outputs.max(1).indices\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        acc = (num_correct / num_samples).item()\n",
    "\n",
    "    model.train()  # 再次进入训练模式\n",
    "    print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n",
    "\n",
    "# 暂存教师模型为teacher_model\n",
    "teacher_model = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 定义学生模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 学生模型\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__( self, num_class=10):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(784, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.fc3 = nn.Linear(20, num_class)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "\n",
    "    # 处理逻辑：fc1->relu->fc2->relu->fc3\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 学生模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 从头先训练一下学生模型\n",
    "model = StudentModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 学生模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "StudentModel                             [64, 10]                  210\n",
      "├─Linear: 1-1                            [64, 20]                  15,700\n",
      "├─ReLU: 1-2                              [64, 20]                  --\n",
      "├─Linear: 1-3                            --                        420\n",
      "├─Linear: 1-6                            [64, 10]                  (recursive)\n",
      "├─Dropout: 1-5                           --                        --\n",
      "├─Linear: 1-6                            [64, 10]                  (recursive)\n",
      "==========================================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.03\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.28\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出模型的参数信息-1w参数\n",
    "cp.get_summary(model, input_size=(64, 1, 28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 学生模型训练&评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 178.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t Accuracy:0.727300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 180.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2\t Accuracy:0.774200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 180.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3\t Accuracy:0.798800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 180.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4\t Accuracy:0.807700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 170.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5\t Accuracy:0.818200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 173.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6\t Accuracy:0.824100\n",
      "CPU times: user 1min 10s, sys: 1.09 s, total: 1min 11s\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 6\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for data,targets in tqdm(train_dataloader):\n",
    "        # 前向预测\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 反向传播，优化权重\n",
    "        optimizer.zero_grad() # 把梯度置为0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in  test_dataloader:\n",
    "            outputs = model(x)\n",
    "            predictions = outputs.max(1).indices\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            acc = (num_correct / num_samples).item()\n",
    "\n",
    "    model.train()\n",
    "    print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n",
    "\n",
    "# 暂存不加蒸馏学生模型为student_model\n",
    "student_model = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 知识蒸馏准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 准备预训练好的教师模型\n",
    "teacher_model.eval()\n",
    "\n",
    "# 准备新的学生模型\n",
    "model = StudentModel().to(device)\n",
    "\n",
    "# 蒸馏温度\n",
    "T = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 蒸馏参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hard_loss\n",
    "hard_loss = nn.CrossEntropyLoss()\n",
    "# hard_loss权重\n",
    "alpha = 0.27\n",
    "# soft_loss kl散度\n",
    "soft_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 知识蒸馏训练&评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 115.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t Accuracy:0.730700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 117.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2\t Accuracy:0.781900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 120.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3\t Accuracy:0.800800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 117.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4\t Accuracy:0.809700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 120.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5\t Accuracy:0.815500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 120.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6\t Accuracy:0.821200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 112.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7\t Accuracy:0.824300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 118.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8\t Accuracy:0.827000\n",
      "CPU times: user 2min 14s, sys: 1.84 s, total: 2min 16s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "    for data,targets in tqdm(train_dataloader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        # 教师模型预测\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(data)\n",
    "        # 学生模型预测\n",
    "        student_outputs = model(data)\n",
    "        student_loss = hard_loss(student_outputs, targets)\n",
    "        # 计算蒸馏后的预测结果及soft_loss\n",
    "        distillation_loss = soft_loss(\n",
    "            F.softmax(student_outputs/T, dim=1),\n",
    "            F.softmax(teacher_outputs/T, dim=1)\n",
    "        )\n",
    "        # 将 hard_loss 和 soft_loss 加权求和\n",
    "        loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "        # 反向传播,优化权重\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 测试集上评估性能\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            pred = outputs.max(1).indices\n",
    "            num_correct += (pred == y).sum()\n",
    "            num_samples += pred.size(0)\n",
    "        acc = (num_correct/num_samples).item()\n",
    "\n",
    "    model.train()\n",
    "    print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 蒸馏模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"./models/distillation_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义问题类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MOEA(ea.Problem):\n",
    "    def __init__(self, train_dataloader, test_dataloader):\n",
    "        name = 'MOEA'\n",
    "        M = 1 # 初始化M（目标维数）\n",
    "        maxormins = [-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标）\n",
    "        Dim = 2 # 初始化Dim（决策变量维数）\n",
    "        varTypes = np.array([0] * Dim) # 初始化varTypes 0-连续\n",
    "        lb = [5, 0.1] # 决策变量下界\n",
    "        ub = [10, 0.9] # 决策变量上界\n",
    "        lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含）\n",
    "        ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含）\n",
    "        # 调用父类构造方法完成实例化\n",
    "        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)\n",
    "        # 数据设置\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "\n",
    "\n",
    "    # 目标函数，采用多线程加速计算\n",
    "    def aimFunc(self, pop):\n",
    "        Vars = pop.Phen # 得到决策变量矩阵\n",
    "        # print(Vars)\n",
    "        pop.ObjV = np.zeros((pop.sizes, 1)) # 初始化种群个体目标函数值列向量\n",
    "        def subAimFunc(i):\n",
    "            epochs, alpha = int(Vars[i, 0]), float(Vars[i, 1])\n",
    "            print(epochs, alpha)\n",
    "            final_loss = 0\n",
    "            for epoch in range(epochs):\n",
    "                for data,targets in tqdm(train_dataloader):\n",
    "                    data, targets = data.to(device), targets.to(device)\n",
    "                    # 教师模型预测\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(data)\n",
    "                    # 学生模型预测\n",
    "                    student_outputs = model(data)\n",
    "                    student_loss = hard_loss(student_outputs, targets)\n",
    "                    # 计算蒸馏后的预测结果及soft_loss\n",
    "                    distillation_loss = soft_loss(\n",
    "                        F.softmax(student_outputs/T, dim=1),\n",
    "                        F.softmax(teacher_outputs/T, dim=1)\n",
    "                    )\n",
    "                    # 将 hard_loss 和 soft_loss 加权求和\n",
    "                    loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                    final_loss = loss.item()\n",
    "                    # 反向传播,优化权重\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            pop.ObjV[i] = final_loss # 最小化最终的损失作为目标函数\n",
    "        pool = ThreadPool(processes=2) # 设置池的大小\n",
    "        pool.map(subAimFunc, list(range(pop.sizes))) # 散列种群每个个体进行加速计算\n",
    "\n",
    "\n",
    "    # 代入优化后的参数先训练再对测试集进行检验，计算指标\n",
    "    def test(self, epochs, alpha):\n",
    "        for epoch in range(epochs):\n",
    "            for data,targets in tqdm(train_dataloader):\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                # 教师模型预测\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(data)\n",
    "                # 学生模型预测\n",
    "                student_outputs = model(data)\n",
    "                student_loss = hard_loss(student_outputs, targets)\n",
    "                # 计算蒸馏后的预测结果及soft_loss\n",
    "                distillation_loss = soft_loss(\n",
    "                    F.softmax(student_outputs/T, dim=1),\n",
    "                    F.softmax(teacher_outputs/T, dim=1)\n",
    "                )\n",
    "                # 将 hard_loss 和 soft_loss 加权求和\n",
    "                loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                # 反向传播,优化权重\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 测试集上评估性能\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x,y in test_dataloader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    outputs = model(x)\n",
    "                    pred = outputs.max(1).indices\n",
    "                    num_correct += (pred == y).sum()\n",
    "                    num_samples += pred.size(0)\n",
    "                acc = (num_correct/num_samples).item()\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n",
    "\n",
    "        torch.save(model.state_dict(), \"./models/moea_distillation.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.3189171239733696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2855765145272017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 2/938 [00:00<00:54, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8424268286675215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 3/938 [00:00<00:39, 23.75it/s]\u001B[A\u001B[A\n",
      "  0%|          | 2/938 [00:00<00:52, 17.78it/s]\u001B[A\n",
      "\n",
      "  1%|          | 6/938 [00:00<00:44, 20.86it/s]\u001B[A\u001B[A\n",
      "  0%|          | 4/938 [00:00<00:51, 18.15it/s]\u001B[A\n",
      "\n",
      " 94%|█████████▎| 878/938 [00:08<00:01, 36.62it/s]A\u001B[A\n",
      " 94%|█████████▎| 878/938 [00:08<00:00, 102.62it/s]\n",
      "\n",
      "\n",
      "  1%|          | 9/938 [00:00<00:48, 19.11it/s]]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8656420316547155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 1/938 [00:00<01:05, 14.39it/s]]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.6277091335505247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 4/938 [00:00<00:25, 37.06it/s]]\u001B[A\u001B[A\n",
      "\n",
      "  1%|          | 10/938 [00:00<00:26, 34.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  3%|▎         | 31/938 [00:00<00:23, 38.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "  4%|▍         | 38/938 [00:01<00:19, 45.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "  5%|▍         | 46/938 [00:01<00:16, 54.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "  6%|▌         | 54/938 [00:01<00:14, 61.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "  7%|▋         | 65/938 [00:01<00:11, 74.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "  8%|▊         | 76/938 [00:01<00:10, 83.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "  9%|▉         | 86/938 [00:01<00:09, 88.29it/s]\u001B[A\u001B[A\n",
      "\n",
      " 10%|█         | 96/938 [00:01<00:09, 89.71it/s]\u001B[A\u001B[A\n",
      "\n",
      " 11%|█▏        | 106/938 [00:01<00:09, 85.26it/s]\u001B[A\u001B[A\n",
      "\n",
      " 12%|█▏        | 116/938 [00:01<00:09, 87.53it/s]\u001B[A\u001B[A\n",
      "\n",
      " 13%|█▎        | 125/938 [00:02<00:09, 87.56it/s]\u001B[A\u001B[A\n",
      "\n",
      " 14%|█▍        | 134/938 [00:02<00:09, 86.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 15%|█▌        | 143/938 [00:02<00:09, 87.52it/s]\u001B[A\u001B[A\n",
      "\n",
      " 16%|█▌        | 152/938 [00:02<00:09, 86.56it/s]\u001B[A\u001B[A\n",
      "\n",
      " 17%|█▋        | 163/938 [00:02<00:08, 92.49it/s]\u001B[A\u001B[A\n",
      "\n",
      " 19%|█▊        | 174/938 [00:02<00:08, 95.28it/s]\u001B[A\u001B[A\n",
      "\n",
      " 20%|█▉        | 184/938 [00:02<00:08, 92.35it/s]\u001B[A\u001B[A\n",
      "\n",
      " 21%|██        | 194/938 [00:02<00:08, 92.09it/s]\u001B[A\u001B[A\n",
      "\n",
      " 22%|██▏       | 205/938 [00:02<00:07, 96.28it/s]\u001B[A\u001B[A\n",
      "\n",
      " 23%|██▎       | 216/938 [00:03<00:07, 99.24it/s]\u001B[A\u001B[A\n",
      "\n",
      " 24%|██▍       | 226/938 [00:03<00:07, 97.81it/s]\u001B[A\u001B[A\n",
      "\n",
      " 25%|██▌       | 237/938 [00:03<00:07, 100.07it/s]\u001B[A\u001B[A\n",
      "\n",
      " 26%|██▋       | 248/938 [00:03<00:06, 101.80it/s]\u001B[A\u001B[A\n",
      "\n",
      " 28%|██▊       | 260/938 [00:03<00:06, 104.55it/s]\u001B[A\u001B[A\n",
      "\n",
      " 29%|██▉       | 272/938 [00:03<00:06, 106.73it/s]\u001B[A\u001B[A\n",
      "\n",
      " 30%|███       | 283/938 [00:03<00:06, 105.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 31%|███▏      | 295/938 [00:03<00:05, 107.48it/s]\u001B[A\u001B[A\n",
      "\n",
      " 33%|███▎      | 306/938 [00:03<00:05, 107.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 34%|███▍      | 317/938 [00:03<00:05, 106.38it/s]\u001B[A\u001B[A\n",
      "\n",
      " 35%|███▍      | 328/938 [00:04<00:05, 105.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 36%|███▌      | 339/938 [00:04<00:05, 107.02it/s]\u001B[A\u001B[A\n",
      "\n",
      " 37%|███▋      | 351/938 [00:04<00:05, 108.31it/s]\u001B[A\u001B[A\n",
      "\n",
      " 39%|███▊      | 362/938 [00:04<00:05, 106.19it/s]\u001B[A\u001B[A\n",
      "\n",
      " 40%|███▉      | 374/938 [00:04<00:05, 107.98it/s]\u001B[A\u001B[A\n",
      "\n",
      " 41%|████      | 385/938 [00:04<00:05, 106.42it/s]\u001B[A\u001B[A\n",
      "\n",
      " 42%|████▏     | 397/938 [00:04<00:04, 108.32it/s]\u001B[A\u001B[A\n",
      "\n",
      " 44%|████▎     | 409/938 [00:04<00:04, 109.17it/s]\u001B[A\u001B[A\n",
      "\n",
      " 45%|████▍     | 421/938 [00:04<00:04, 111.22it/s]\u001B[A\u001B[A\n",
      "\n",
      " 46%|████▌     | 433/938 [00:05<00:04, 112.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 47%|████▋     | 445/938 [00:05<00:04, 111.32it/s]\u001B[A\u001B[A\n",
      "\n",
      " 49%|████▊     | 457/938 [00:05<00:04, 112.26it/s]\u001B[A\u001B[A\n",
      "\n",
      " 50%|█████     | 469/938 [00:05<00:04, 108.13it/s]\u001B[A\u001B[A\n",
      "\n",
      " 51%|█████▏    | 481/938 [00:05<00:04, 110.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 53%|█████▎    | 493/938 [00:05<00:03, 111.45it/s]\u001B[A\u001B[A\n",
      "\n",
      " 54%|█████▍    | 505/938 [00:05<00:03, 111.51it/s]\u001B[A\u001B[A\n",
      "\n",
      " 55%|█████▌    | 517/938 [00:05<00:03, 112.92it/s]\u001B[A\u001B[A\n",
      "\n",
      " 56%|█████▋    | 529/938 [00:05<00:03, 113.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 58%|█████▊    | 541/938 [00:05<00:03, 113.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 59%|█████▉    | 553/938 [00:06<00:03, 112.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 60%|██████    | 565/938 [00:06<00:03, 113.01it/s]\u001B[A\u001B[A\n",
      "\n",
      " 62%|██████▏   | 577/938 [00:06<00:03, 113.99it/s]\u001B[A\u001B[A\n",
      "\n",
      " 63%|██████▎   | 589/938 [00:06<00:03, 114.94it/s]\u001B[A\u001B[A\n",
      "\n",
      " 64%|██████▍   | 601/938 [00:06<00:02, 115.34it/s]\u001B[A\u001B[A\n",
      "\n",
      " 65%|██████▌   | 613/938 [00:06<00:02, 112.19it/s]\u001B[A\u001B[A\n",
      "\n",
      " 67%|██████▋   | 625/938 [00:06<00:02, 113.47it/s]\u001B[A\u001B[A\n",
      "\n",
      " 68%|██████▊   | 637/938 [00:06<00:02, 114.37it/s]\u001B[A\u001B[A\n",
      "\n",
      " 69%|██████▉   | 649/938 [00:06<00:02, 114.63it/s]\u001B[A\u001B[A\n",
      "\n",
      " 70%|███████   | 661/938 [00:07<00:02, 115.88it/s]\u001B[A\u001B[A\n",
      "\n",
      " 72%|███████▏  | 673/938 [00:07<00:02, 115.04it/s]\u001B[A\u001B[A\n",
      "\n",
      " 73%|███████▎  | 685/938 [00:07<00:02, 106.64it/s]\u001B[A\u001B[A\n",
      "\n",
      " 74%|███████▍  | 696/938 [00:07<00:02, 105.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 75%|███████▌  | 708/938 [00:07<00:02, 109.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 77%|███████▋  | 719/938 [00:07<00:02, 106.84it/s]\u001B[A\u001B[A\n",
      "\n",
      " 78%|███████▊  | 731/938 [00:07<00:01, 109.64it/s]\u001B[A\u001B[A\n",
      "\n",
      " 79%|███████▉  | 743/938 [00:07<00:01, 112.57it/s]\u001B[A\u001B[A\n",
      "\n",
      " 80%|████████  | 755/938 [00:07<00:01, 113.94it/s]\u001B[A\u001B[A\n",
      "\n",
      " 82%|████████▏ | 767/938 [00:08<00:01, 110.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 83%|████████▎ | 779/938 [00:08<00:01, 109.68it/s]\u001B[A\u001B[A\n",
      "\n",
      " 84%|████████▍ | 791/938 [00:08<00:01, 112.01it/s]\u001B[A\u001B[A\n",
      "\n",
      " 86%|████████▌ | 803/938 [00:08<00:01, 105.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 87%|████████▋ | 814/938 [00:08<00:01, 103.05it/s]\u001B[A\u001B[A\n",
      "\n",
      " 88%|████████▊ | 825/938 [00:08<00:01, 103.50it/s]\u001B[A\u001B[A\n",
      "\n",
      " 89%|████████▉ | 836/938 [00:08<00:00, 104.69it/s]\u001B[A\u001B[A\n",
      "\n",
      " 90%|█████████ | 848/938 [00:08<00:00, 106.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 92%|█████████▏| 859/938 [00:08<00:00, 106.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 93%|█████████▎| 871/938 [00:09<00:00, 108.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 94%|█████████▍| 882/938 [00:09<00:00, 104.92it/s]\u001B[A\u001B[A\n",
      "\n",
      " 95%|█████████▌| 893/938 [00:09<00:00, 104.17it/s]\u001B[A\u001B[A\n",
      "\n",
      " 96%|█████████▋| 904/938 [00:09<00:00, 99.99it/s] \u001B[A\u001B[A\n",
      "\n",
      " 98%|█████████▊| 915/938 [00:09<00:00, 100.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 99%|█████████▊| 926/938 [00:09<00:00, 101.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "100%|██████████| 938/938 [00:09<00:00, 96.68it/s] \u001B[A\u001B[A\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.38it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 105.10it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 112.47it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.13it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.2740337282419205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 109.97it/s]\n",
      "100%|██████████| 938/938 [00:07<00:00, 118.57it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.56it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.24it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 104.54it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.32it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 106.33it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 116.82it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-e006b3843ce3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m \u001B[0;34m[\u001B[0m\u001B[0mBestIndi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpopulation\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmyAlgorithm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 执行算法模板，得到最优个体以及最后一代种群\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m \u001B[0mBestIndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 把最优个体的信息保存到文件中\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/templates/soeas/DE/DE_rand_1_bin/soea_DE_rand_1_bin_templet.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, prophetPop)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;31m# ===========================准备进化============================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0mpopulation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minitChrom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNIND\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 初始化种群染色体矩阵\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_aimFunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpopulation\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 计算种群的目标函数值\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;31m# 插入先验知识（注意：这里不会对先知种群prophetPop的合法性进行检查，故应确保prophetPop是一个种群类且拥有合法的Chrom、ObjV、Phen等属性）\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mprophetPop\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/Algorithm.py\u001B[0m in \u001B[0;36mcall_aimFunc\u001B[0;34m(self, pop)\u001B[0m\n\u001B[1;32m    172\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproblem\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'error: problem has not been initialized. (算法模板中的问题对象未被初始化。)'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproblem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maimFunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 调用问题类的aimFunc()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m  \u001B[0;31m# 更新评价次数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0;31m# 格式检查\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-29ea1f645391>\u001B[0m in \u001B[0;36maimFunc\u001B[0;34m(self, pop)\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mObjV\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfinal_loss\u001B[0m \u001B[0;31m# 最小化最终的损失作为目标函数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mpool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mThreadPool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocesses\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 设置池的大小\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubAimFunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 散列种群每个个体进行加速计算\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m         \u001B[0;32min\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mthat\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mreturned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         '''\n\u001B[0;32m--> 364\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstarmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    769\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    770\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 771\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    772\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    773\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mworker\u001B[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0mjob\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mwrap_exception\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mfunc\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_helper_reraises_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmapstar\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mstarmapstar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-29ea1f645391>\u001B[0m in \u001B[0;36msubAimFunc\u001B[0;34m(i)\u001B[0m\n\u001B[1;32m     45\u001B[0m                     \u001B[0;31m# 反向传播,优化权重\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m                     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    394\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    395\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 396\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    397\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    398\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    171\u001B[0m     \u001B[0;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[0;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 173\u001B[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[0;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "\"\"\"===============================实例化问题对象===========================\"\"\"\n",
    "\n",
    "problem = MOEA(train_dataloader, test_dataloader) # 生成问题对象\n",
    "\n",
    "\"\"\"=================================种群设置===============================\"\"\"\n",
    "\n",
    "Encoding = 'RI'       # 编码方式\n",
    "NIND = 10             # 种群规模\n",
    "Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器\n",
    "population = ea.Population(Encoding, Field, NIND) # 实例化种群对象（此时种群还没被初始化，仅仅是完成种群对象的实例化）\n",
    "\n",
    "\"\"\"===============================算法参数设置=============================\"\"\"\n",
    "\n",
    "myAlgorithm = ea.soea_DE_rand_1_bin_templet(problem, population) # 实例化一个算法模板对象\n",
    "myAlgorithm.MAXGEN = 10 # 最大进化代数\n",
    "myAlgorithm.trappedValue = 1e-6 # “进化停滞”判断阈值\n",
    "myAlgorithm.maxTrappedCount = 10 # 进化停滞计数器最大上限值，如果连续maxTrappedCount代被判定进化陷入停滞，则终止进化\n",
    "myAlgorithm.logTras = 1  # 设置每隔多少代记录日志，若设置成0则表示不记录日志\n",
    "myAlgorithm.verbose = True  # 设置是否打印输出日志信息\n",
    "myAlgorithm.drawing = 1  # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画）\n",
    "\n",
    "\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\n",
    "\n",
    "[BestIndi, population] = myAlgorithm.run()  # 执行算法模板，得到最优个体以及最后一代种群\n",
    "BestIndi.save()  # 把最优个体的信息保存到文件中\n",
    "\n",
    "\"\"\"==================================输出结果=============================\"\"\"\n",
    "\n",
    "print('用时：%f 秒' % myAlgorithm.passTime)\n",
    "print('评价次数：%d 次' % myAlgorithm.evalsNum)\n",
    "if BestIndi.sizes != 0:\n",
    "    print('最优的目标函数值为：%s' % BestIndi.ObjV[0][0])\n",
    "    print('最优的控制变量值为：')\n",
    "    for i in range(BestIndi.Phen.shape[1]):\n",
    "        print(BestIndi.Phen[0, i])\n",
    "else:\n",
    "    print('没找到可行解。')\n",
    "\n",
    "\"\"\"=================================检验结果===============================\"\"\"\n",
    "\n",
    "problem.test(epochs= int(BestIndi.Phen[0][0]), alpha= float(BestIndi.Phen[0][1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}