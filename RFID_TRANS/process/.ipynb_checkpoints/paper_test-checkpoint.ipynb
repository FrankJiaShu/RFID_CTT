{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识蒸馏-RFID Transformer teacher->GRU student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-26e33e12c0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_param\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geatpy as ea\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.calculate_param as cp\n",
    "from dataset import data_read\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 硬件设备准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_read' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0fb119f9b6c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_read\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_read\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_read' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data_read.load_data('train')\n",
    "X_test, y_test = data_read.load_data('test')\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-594710ff7c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [len * feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [len * feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device) # [len * feature]\n",
    "y_train = torch.from_numpy(y_train).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device) # [len * feature]\n",
    "y_test = torch.from_numpy(y_test).float().to(device)\n",
    "\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51b79d7808d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=100, shuffle=False)\n",
    "test_data_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义教师模型-transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 位置编码类\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.pe[:x.size(0), :]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TeacherTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherTransformer, self).__init__()\n",
    "        self.d_model = 128  # 词向量维度\n",
    "        self.embedding_enc = nn.Linear(50, self.d_model)\n",
    "        self.embedding_dec = nn.Linear(2, self.d_model)\n",
    "        self.pos_encoding = PositionalEncoding(self.d_model)\n",
    "        self.Transformer_layer = nn.Transformer(d_model=128, num_encoder_layers=3, num_decoder_layers=3, batch_first=True)\n",
    "        self.FC_layer = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 使用线性层代替embedding\n",
    "        src = self.embedding_enc(src).unsqueeze(0)\n",
    "        tgt = self.embedding_dec(tgt).unsqueeze(0)\n",
    "        src = self.pos_encoding(src)\n",
    "        out = self.Transformer_layer(src, tgt)\n",
    "        out = self.FC_layer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = TeacherTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "TeacherTransformer                                                     --\n",
      "├─Linear: 1-1                                                          6,528\n",
      "├─Linear: 1-2                                                          384\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "├─Transformer: 1-4                                                     --\n",
      "│    └─TransformerEncoder: 2-1                                         --\n",
      "│    │    └─ModuleList: 3-1                                            1,779,072\n",
      "│    │    └─LayerNorm: 3-2                                             256\n",
      "│    └─TransformerDecoder: 2-2                                         --\n",
      "│    │    └─ModuleList: 3-3                                            1,977,984\n",
      "│    │    └─LayerNorm: 3-4                                             256\n",
      "├─Linear: 1-5                                                          258\n",
      "===============================================================================================\n",
      "Total params: 3,764,738\n",
      "Trainable params: 3,764,738\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出教师模型的参数信息-300w参数\n",
    "cp.get_summary(model, input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 146.021196\n",
      "Epoch: 0002 loss = 48.642279\n",
      "Epoch: 0003 loss = 48.374830\n",
      "Epoch: 0004 loss = 40.773885\n",
      "Epoch: 0005 loss = 38.780626\n",
      "Epoch: 0006 loss = 31.814842\n",
      "Epoch: 0007 loss = 22.182482\n",
      "Epoch: 0008 loss = 15.505138\n",
      "Epoch: 0009 loss = 13.970082\n",
      "Epoch: 0010 loss = 9.494105\n",
      "Epoch: 0011 loss = 5.759591\n",
      "Epoch: 0012 loss = 5.455363\n",
      "Epoch: 0013 loss = 4.145405\n",
      "Epoch: 0014 loss = 4.251118\n",
      "Epoch: 0015 loss = 3.749619\n",
      "Epoch: 0016 loss = 2.698970\n",
      "Epoch: 0017 loss = 2.341664\n",
      "Epoch: 0018 loss = 2.750972\n",
      "Epoch: 0019 loss = 2.069706\n",
      "Epoch: 0020 loss = 2.142641\n",
      "Epoch: 0021 loss = 1.876754\n",
      "Epoch: 0022 loss = 1.554499\n",
      "Epoch: 0023 loss = 1.750292\n",
      "Epoch: 0024 loss = 1.905683\n",
      "Epoch: 0025 loss = 1.418602\n",
      "Epoch: 0026 loss = 1.549186\n",
      "Epoch: 0027 loss = 1.689632\n",
      "Epoch: 0028 loss = 1.545023\n",
      "Epoch: 0029 loss = 1.254578\n",
      "Epoch: 0030 loss = 1.295816\n",
      "Epoch: 0031 loss = 1.113830\n",
      "Epoch: 0032 loss = 1.197965\n",
      "Epoch: 0033 loss = 1.369943\n",
      "Epoch: 0034 loss = 1.013569\n",
      "Epoch: 0035 loss = 1.231339\n",
      "Epoch: 0036 loss = 1.386474\n",
      "Epoch: 0037 loss = 0.975088\n",
      "Epoch: 0038 loss = 1.162244\n",
      "Epoch: 0039 loss = 1.086151\n",
      "Epoch: 0040 loss = 0.970686\n",
      "Epoch: 0041 loss = 1.069518\n",
      "Epoch: 0042 loss = 0.718160\n",
      "Epoch: 0043 loss = 0.693110\n",
      "Epoch: 0044 loss = 0.703323\n",
      "Epoch: 0045 loss = 0.699173\n",
      "Epoch: 0046 loss = 0.809498\n",
      "Epoch: 0047 loss = 0.623248\n",
      "Epoch: 0048 loss = 0.748733\n",
      "Epoch: 0049 loss = 0.909876\n",
      "Epoch: 0050 loss = 0.733224\n",
      "Epoch: 0051 loss = 0.675324\n",
      "Epoch: 0052 loss = 0.659211\n",
      "Epoch: 0053 loss = 0.509601\n",
      "Epoch: 0054 loss = 0.505444\n",
      "Epoch: 0055 loss = 0.525242\n",
      "Epoch: 0056 loss = 0.607783\n",
      "Epoch: 0057 loss = 0.716973\n",
      "Epoch: 0058 loss = 0.638316\n",
      "Epoch: 0059 loss = 0.567311\n",
      "Epoch: 0060 loss = 0.571196\n",
      "Epoch: 0061 loss = 0.517468\n",
      "Epoch: 0062 loss = 0.468084\n",
      "Epoch: 0063 loss = 0.518527\n",
      "Epoch: 0064 loss = 0.532766\n",
      "Epoch: 0065 loss = 0.633589\n",
      "Epoch: 0066 loss = 0.542620\n",
      "Epoch: 0067 loss = 0.513787\n",
      "Epoch: 0068 loss = 0.506317\n",
      "Epoch: 0069 loss = 0.483628\n",
      "Epoch: 0070 loss = 0.507854\n",
      "Epoch: 0071 loss = 0.500861\n",
      "Epoch: 0072 loss = 0.445483\n",
      "Epoch: 0073 loss = 0.376043\n",
      "Epoch: 0074 loss = 0.395517\n",
      "Epoch: 0075 loss = 0.370844\n",
      "Epoch: 0076 loss = 0.374642\n",
      "Epoch: 0077 loss = 0.398057\n",
      "Epoch: 0078 loss = 0.416179\n",
      "Epoch: 0079 loss = 0.468224\n",
      "Epoch: 0080 loss = 0.448743\n",
      "Epoch: 0081 loss = 0.461111\n",
      "Epoch: 0082 loss = 0.446102\n",
      "Epoch: 0083 loss = 0.470443\n",
      "Epoch: 0084 loss = 0.392187\n",
      "Epoch: 0085 loss = 0.345276\n",
      "Epoch: 0086 loss = 0.331676\n",
      "Epoch: 0087 loss = 0.334069\n",
      "Epoch: 0088 loss = 0.326836\n",
      "Epoch: 0089 loss = 0.350567\n",
      "Epoch: 0090 loss = 0.377730\n",
      "Epoch: 0091 loss = 0.423912\n",
      "Epoch: 0092 loss = 0.411489\n",
      "Epoch: 0093 loss = 0.314159\n",
      "Epoch: 0094 loss = 0.325789\n",
      "Epoch: 0095 loss = 0.307691\n",
      "Epoch: 0096 loss = 0.311124\n",
      "Epoch: 0097 loss = 0.425064\n",
      "Epoch: 0098 loss = 0.371573\n",
      "Epoch: 0099 loss = 0.351531\n",
      "Epoch: 0100 loss = 0.422515\n",
      "best_loss::| 0.3076905161142349 ---best_epoch::| 94\n",
      "CPU times: user 4min 11s, sys: 47.1 s, total: 4min 58s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:  # enc_inputs : [len * feature]->[2000 * 50]\n",
    "        # print(X.shape)  # [100 * 50]\n",
    "        # print(y.shape)  # [100 * 50]\n",
    "        outputs = model(X, y)\n",
    "        outputs = outputs.squeeze()  # [100 * 2]\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss_num = loss.item()\n",
    "        epoch_loss += loss_num\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/teacher_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.084892, 'mse': 0.011776982, 'rmse': 0.10852180368617363, 'evs': 0.9972739815711975, 'r2': 0.9943189869485213, 'mmax': 0.21287823, 'mmin': 0.0052908137}\n"
     ]
    }
   ],
   "source": [
    "model = TeacherTransformer().to(device)\n",
    "# 暂存教师模型为teacher_model\n",
    "teacher_model = model\n",
    "model.load_state_dict(torch.load('./result/teacher_weight.pth'))\n",
    "model.eval()\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型定位效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>PX</th>\n",
       "      <th>Py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.179203</td>\n",
       "      <td>3.613626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.182119</td>\n",
       "      <td>2.018872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.475395</td>\n",
       "      <td>2.628522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.07</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.254373</td>\n",
       "      <td>2.789131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.662742</td>\n",
       "      <td>2.512204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.43</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.558935</td>\n",
       "      <td>1.657329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.247052</td>\n",
       "      <td>0.733851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.385608</td>\n",
       "      <td>2.029962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.297978</td>\n",
       "      <td>3.725786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.700464</td>\n",
       "      <td>4.499172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.646064</td>\n",
       "      <td>3.832847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.67</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.877194</td>\n",
       "      <td>0.297701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.57</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.662488</td>\n",
       "      <td>0.357804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.255364</td>\n",
       "      <td>3.308111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.76</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4.927291</td>\n",
       "      <td>3.414310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.70</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.767315</td>\n",
       "      <td>3.836316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.674821</td>\n",
       "      <td>1.218679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.68</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.687669</td>\n",
       "      <td>4.779669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.09</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.104179</td>\n",
       "      <td>4.770106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.25</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.215453</td>\n",
       "      <td>3.864165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X     y        PX        Py\n",
       "0   0.21  3.47  0.179203  3.613626\n",
       "1   1.13  1.96  1.182119  2.018872\n",
       "2   3.38  2.58  3.475395  2.628522\n",
       "3   4.07  2.72  4.254373  2.789131\n",
       "4   1.58  2.47  1.662742  2.512204\n",
       "5   3.43  1.61  3.558935  1.657329\n",
       "6   1.22  0.74  1.247052  0.733851\n",
       "7   2.33  1.97  2.385608  2.029962\n",
       "8   0.33  3.56  0.297978  3.725786\n",
       "9   3.53  4.28  3.700464  4.499172\n",
       "10  4.42  3.69  4.646064  3.832847\n",
       "11  3.67  0.34  3.877194  0.297701\n",
       "12  2.57  0.37  2.662488  0.357804\n",
       "13  3.14  3.22  3.255364  3.308111\n",
       "14  4.76  3.34  4.927291  3.414310\n",
       "15  1.70  3.71  1.767315  3.836316\n",
       "16  3.50  1.20  3.674821  1.218679\n",
       "17  0.68  4.65  0.687669  4.779669\n",
       "18  1.09  4.59  1.104179  4.770106\n",
       "19  0.25  3.70  0.215453  3.864165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teacher = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_teacher)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_teacher.csv')\n",
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_teacher[:, 0], y_teacher[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with Transformer')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_teacher.jpg', dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义学生模型-小变压器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class StudentTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentTransformer, self).__init__()\n",
    "        self.d_model = 8  # 词向量维度\n",
    "        self.embedding_enc = nn.Linear(50, self.d_model)\n",
    "        self.embedding_dec = nn.Linear(2, self.d_model)\n",
    "        self.Transformer_layer = nn.Transformer(d_model=8, num_encoder_layers=1, num_decoder_layers=1, batch_first=True)\n",
    "        self.FC_layer = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 使用线性层代替embedding\n",
    "        src = self.embedding_enc(src).unsqueeze(0)\n",
    "        tgt = self.embedding_dec(tgt).unsqueeze(0)\n",
    "        out = self.Transformer_layer(src, tgt)\n",
    "        out = self.FC_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 从头先训练一下学生模型\n",
    "model = StudentTransformer().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "StudentTransformer                                                     --\n",
      "├─Linear: 1-1                                                          408\n",
      "├─Linear: 1-2                                                          24\n",
      "├─Transformer: 1-3                                                     --\n",
      "│    └─TransformerEncoder: 2-1                                         --\n",
      "│    │    └─ModuleList: 3-1                                            35,144\n",
      "│    │    └─LayerNorm: 3-2                                             16\n",
      "│    └─TransformerDecoder: 2-2                                         --\n",
      "│    │    └─ModuleList: 3-3                                            35,448\n",
      "│    │    └─LayerNorm: 3-4                                             16\n",
      "├─Linear: 1-4                                                          18\n",
      "===============================================================================================\n",
      "Total params: 71,074\n",
      "Trainable params: 71,074\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出学生模型的参数信息-1w参数\n",
    "cp.get_summary(model, input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 139.130597\n",
      "Epoch: 0002 loss = 97.224904\n",
      "Epoch: 0003 loss = 61.542907\n",
      "Epoch: 0004 loss = 43.566233\n",
      "Epoch: 0005 loss = 46.203680\n",
      "Epoch: 0006 loss = 46.952348\n",
      "Epoch: 0007 loss = 41.023726\n",
      "Epoch: 0008 loss = 45.715397\n",
      "Epoch: 0009 loss = 40.270610\n",
      "Epoch: 0010 loss = 39.936496\n",
      "Epoch: 0011 loss = 37.431767\n",
      "Epoch: 0012 loss = 33.447421\n",
      "Epoch: 0013 loss = 29.424758\n",
      "Epoch: 0014 loss = 23.759452\n",
      "Epoch: 0015 loss = 25.533319\n",
      "Epoch: 0016 loss = 24.320489\n",
      "Epoch: 0017 loss = 21.061591\n",
      "Epoch: 0018 loss = 19.128983\n",
      "Epoch: 0019 loss = 14.962416\n",
      "Epoch: 0020 loss = 9.974117\n",
      "Epoch: 0021 loss = 7.762563\n",
      "Epoch: 0022 loss = 7.252261\n",
      "Epoch: 0023 loss = 6.549025\n",
      "Epoch: 0024 loss = 5.996923\n",
      "Epoch: 0025 loss = 5.540876\n",
      "Epoch: 0026 loss = 5.039779\n",
      "Epoch: 0027 loss = 4.265544\n",
      "Epoch: 0028 loss = 4.093740\n",
      "Epoch: 0029 loss = 3.506531\n",
      "Epoch: 0030 loss = 3.136931\n",
      "Epoch: 0031 loss = 2.851424\n",
      "Epoch: 0032 loss = 2.618742\n",
      "Epoch: 0033 loss = 2.439405\n",
      "Epoch: 0034 loss = 2.309009\n",
      "Epoch: 0035 loss = 2.148235\n",
      "Epoch: 0036 loss = 2.352889\n",
      "Epoch: 0037 loss = 1.867808\n",
      "Epoch: 0038 loss = 2.062507\n",
      "Epoch: 0039 loss = 1.719774\n",
      "Epoch: 0040 loss = 1.869026\n",
      "Epoch: 0041 loss = 1.590761\n",
      "Epoch: 0042 loss = 1.520358\n",
      "Epoch: 0043 loss = 1.471584\n",
      "Epoch: 0044 loss = 1.519939\n",
      "Epoch: 0045 loss = 1.352115\n",
      "Epoch: 0046 loss = 1.384212\n",
      "Epoch: 0047 loss = 1.252323\n",
      "Epoch: 0048 loss = 1.338291\n",
      "Epoch: 0049 loss = 1.230689\n",
      "Epoch: 0050 loss = 1.255565\n",
      "Epoch: 0051 loss = 1.166977\n",
      "Epoch: 0052 loss = 1.178662\n",
      "Epoch: 0053 loss = 1.096643\n",
      "Epoch: 0054 loss = 0.966547\n",
      "Epoch: 0055 loss = 0.836914\n",
      "Epoch: 0056 loss = 0.945276\n",
      "Epoch: 0057 loss = 0.827973\n",
      "Epoch: 0058 loss = 0.921610\n",
      "Epoch: 0059 loss = 0.782994\n",
      "Epoch: 0060 loss = 0.839072\n",
      "Epoch: 0061 loss = 0.719440\n",
      "Epoch: 0062 loss = 0.803847\n",
      "Epoch: 0063 loss = 0.649825\n",
      "Epoch: 0064 loss = 0.693687\n",
      "Epoch: 0065 loss = 0.626244\n",
      "Epoch: 0066 loss = 0.617384\n",
      "Epoch: 0067 loss = 0.552085\n",
      "Epoch: 0068 loss = 0.555797\n",
      "Epoch: 0069 loss = 0.524649\n",
      "Epoch: 0070 loss = 0.593270\n",
      "Epoch: 0071 loss = 0.543580\n",
      "Epoch: 0072 loss = 0.578153\n",
      "Epoch: 0073 loss = 0.506772\n",
      "Epoch: 0074 loss = 0.531487\n",
      "Epoch: 0075 loss = 0.530793\n",
      "Epoch: 0076 loss = 0.506764\n",
      "Epoch: 0077 loss = 0.518900\n",
      "Epoch: 0078 loss = 0.421687\n",
      "Epoch: 0079 loss = 0.431945\n",
      "Epoch: 0080 loss = 0.417714\n",
      "Epoch: 0081 loss = 0.417617\n",
      "Epoch: 0082 loss = 0.470894\n",
      "Epoch: 0083 loss = 0.398913\n",
      "Epoch: 0084 loss = 0.412360\n",
      "Epoch: 0085 loss = 0.434758\n",
      "Epoch: 0086 loss = 0.342018\n",
      "Epoch: 0087 loss = 0.355662\n",
      "Epoch: 0088 loss = 0.318917\n",
      "Epoch: 0089 loss = 0.322305\n",
      "Epoch: 0090 loss = 0.324324\n",
      "Epoch: 0091 loss = 0.361366\n",
      "Epoch: 0092 loss = 0.331830\n",
      "Epoch: 0093 loss = 0.287865\n",
      "Epoch: 0094 loss = 0.269841\n",
      "Epoch: 0095 loss = 0.296328\n",
      "Epoch: 0096 loss = 0.340956\n",
      "Epoch: 0097 loss = 0.256051\n",
      "Epoch: 0098 loss = 0.242094\n",
      "Epoch: 0099 loss = 0.308351\n",
      "Epoch: 0100 loss = 0.347302\n",
      "best_loss::| 0.2420944324694574 ---best_epoch::| 97\n",
      "CPU times: user 39.6 s, sys: 2.54 s, total: 42.1 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:  # enc_inputs : [len * feature]->[2000 * 50]\n",
    "        outputs = model(X, y)\n",
    "        outputs = outputs.squeeze()  # [100 * 2]\n",
    "        loss = criterion(outputs, y)\n",
    "        loss_num = loss.item()\n",
    "        epoch_loss += loss_num\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/student_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|', best_loss, '---best_epoch::|', best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.06455692, 'mse': 0.007047292, 'rmse': 0.08394814974186886, 'evs': 0.9978922605514526, 'r2': 0.9966219557245699, 'mmax': 0.15922213, 'mmin': 0.0050887465}\n"
     ]
    }
   ],
   "source": [
    "model = StudentTransformer().to(device)\n",
    "# 暂存教师模型为teacher_model\n",
    "student_model = model\n",
    "model.load_state_dict(torch.load('./result/student_weight.pth'))\n",
    "model.eval()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型定位效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>PX-MOEA</th>\n",
       "      <th>Py-MOEA</th>\n",
       "      <th>PX-NAAS</th>\n",
       "      <th>Py-NAAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.241</td>\n",
       "      <td>3.688</td>\n",
       "      <td>0.192</td>\n",
       "      <td>3.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.227</td>\n",
       "      <td>2.030</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.537</td>\n",
       "      <td>2.669</td>\n",
       "      <td>3.404</td>\n",
       "      <td>2.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.07</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.336</td>\n",
       "      <td>2.836</td>\n",
       "      <td>4.172</td>\n",
       "      <td>2.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.702</td>\n",
       "      <td>2.534</td>\n",
       "      <td>1.621</td>\n",
       "      <td>2.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.43</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.593</td>\n",
       "      <td>1.676</td>\n",
       "      <td>3.477</td>\n",
       "      <td>1.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.302</td>\n",
       "      <td>0.763</td>\n",
       "      <td>1.227</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.442</td>\n",
       "      <td>2.057</td>\n",
       "      <td>2.356</td>\n",
       "      <td>1.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.359</td>\n",
       "      <td>3.796</td>\n",
       "      <td>0.304</td>\n",
       "      <td>3.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.826</td>\n",
       "      <td>4.540</td>\n",
       "      <td>3.646</td>\n",
       "      <td>4.429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X     y  PX-MOEA  Py-MOEA  PX-NAAS  Py-NAAS\n",
       "0  0.21  3.47    0.241    3.688    0.192    3.548\n",
       "1  1.13  1.96    1.227    2.030    1.173    1.972\n",
       "2  3.38  2.58    3.537    2.669    3.404    2.599\n",
       "3  4.07  2.72    4.336    2.836    4.172    2.768\n",
       "4  1.58  2.47    1.702    2.534    1.621    2.455\n",
       "5  3.43  1.61    3.593    1.676    3.477    1.648\n",
       "6  1.22  0.74    1.302    0.763    1.227    0.751\n",
       "7  2.33  1.97    2.442    2.057    2.356    1.999\n",
       "8  0.33  3.56    0.359    3.796    0.304    3.654\n",
       "9  3.53  4.28    3.826    4.540    3.646    4.429"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_student = y_test[:20]\n",
    "pxy1 = [\n",
    "[0.241, 3.688],\n",
    "[1.227, 2.030],\n",
    "[3.537, 2.669],\n",
    "[4.336, 2.836],\n",
    "[1.702, 2.534],\n",
    "[3.593, 1.676],\n",
    "[1.302, 0.763],\n",
    "[2.442, 2.057],\n",
    "[0.359, 3.796],\n",
    "[3.826, 4.540],\n",
    "[4.767, 3.884],\n",
    "[3.932, 0.335], \n",
    "[2.717, 0.386], \n",
    "[3.319, 3.338], \n",
    "[5.035, 3.454], \n",
    "[1.840, 3.895], \n",
    "[3.716, 1.242],\n",
    "[0.768, 4.860], \n",
    "[1.192, 4.845], \n",
    "[0.286, 3.939] \n",
    "]\n",
    "pxy1 = np.array(pxy1)\n",
    "pxy2 = [\n",
    "[0.192, 3.548],\n",
    "[1.173, 1.972],\n",
    "[3.404, 2.599],\n",
    "[4.172, 2.768],\n",
    "[1.621, 2.455],\n",
    "[3.477, 1.648],\n",
    "[1.227, 0.751],\n",
    "[2.356, 1.999],\n",
    "[0.304, 3.654],\n",
    "[3.646, 4.429],\n",
    "[4.583, 3.804],\n",
    "[3.762, 0.336], \n",
    "[2.599, 0.389],\n",
    "[3.171, 3.239], \n",
    "[4.869, 3.397], \n",
    "[1.750, 3.755], \n",
    "[3.587, 1.226], \n",
    "[0.659, 4.707], \n",
    "[1.069, 4.689], \n",
    "[0.229, 3.794]]\n",
    "pxy2 = np.array(pxy2)\n",
    "\n",
    "coor1 = pd.DataFrame(y_student)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy1)\n",
    "coor2.columns = ['PX-MOEA', 'Py-MOEA']\n",
    "\n",
    "coor3 = pd.DataFrame(pxy2)\n",
    "coor3.columns = ['PX-NAAS', 'Py-NAAS']\n",
    "\n",
    "coor = pd.concat([coor1, coor2, coor3], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_student.csv')\n",
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_student[:, 0], y_student[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy1[:, 0], pxy1[:, 1], c='blue', marker='x', label = 'predict position with CTT-MOEA')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy2[:, 0], pxy2[:, 1], c='red', marker='x', label = 'predict position with CTT-MOEA(NAAS)')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_student.jpg', dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识蒸馏准备与设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 准备预训练好的教师模型\n",
    "teacher_model.eval()\n",
    "\n",
    "# 准备新的学生模型\n",
    "model = StudentTransformer().to(device)\n",
    "\n",
    "# 蒸馏温度\n",
    "T = 9\n",
    "\n",
    "# 蒸馏参数设置\n",
    "# hard_loss\n",
    "hard_loss = nn.MSELoss()\n",
    "# hard_loss权重\n",
    "alpha = 0.3\n",
    "# soft_loss kl散度\n",
    "soft_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识蒸馏训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frank/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([100, 2])) that is different to the input size (torch.Size([1, 100, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = -10411.670044\n",
      "Epoch: 0002 loss = -10418.210693\n",
      "Epoch: 0003 loss = -10421.324890\n",
      "Epoch: 0004 loss = -10423.941284\n",
      "Epoch: 0005 loss = -10426.218933\n",
      "Epoch: 0006 loss = -10428.354126\n",
      "Epoch: 0007 loss = -10430.313354\n",
      "Epoch: 0008 loss = -10431.782532\n",
      "Epoch: 0009 loss = -10432.940125\n",
      "Epoch: 0010 loss = -10433.869324\n",
      "Epoch: 0011 loss = -10434.597595\n",
      "Epoch: 0012 loss = -10435.117432\n",
      "Epoch: 0013 loss = -10435.506226\n",
      "Epoch: 0014 loss = -10435.813904\n",
      "Epoch: 0015 loss = -10436.074402\n",
      "Epoch: 0016 loss = -10436.317200\n",
      "Epoch: 0017 loss = -10436.344788\n",
      "Epoch: 0018 loss = -10436.564209\n",
      "Epoch: 0019 loss = -10436.755188\n",
      "Epoch: 0020 loss = -10436.831909\n",
      "Epoch: 0021 loss = -10436.896179\n",
      "Epoch: 0022 loss = -10437.046326\n",
      "Epoch: 0023 loss = -10436.998596\n",
      "Epoch: 0024 loss = -10437.144775\n",
      "Epoch: 0025 loss = -10437.139221\n",
      "Epoch: 0026 loss = -10437.155823\n",
      "Epoch: 0027 loss = -10437.171570\n",
      "Epoch: 0028 loss = -10437.223450\n",
      "Epoch: 0029 loss = -10437.242004\n",
      "Epoch: 0030 loss = -10437.252441\n",
      "Epoch: 0031 loss = -10437.253479\n",
      "Epoch: 0032 loss = -10437.311096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-8c8cefb44712>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformer_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[0m\u001b[1;32m    147\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                               memory_key_padding_mask=memory_key_padding_mask)\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[1;32m    292\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 教师模型预测\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(X, y)\n",
    "        # 学生模型预测\n",
    "        student_outputs = model(X, y)\n",
    "        student_loss = hard_loss(student_outputs, y)\n",
    "        # 计算蒸馏后的预测结果及soft_loss\n",
    "        distillation_loss = soft_loss(\n",
    "            F.softmax(student_outputs/T, dim=1),\n",
    "            F.softmax(teacher_outputs/T, dim=1)\n",
    "        )\n",
    "        # 将 hard_loss 和 soft_loss 加权求和\n",
    "        loss = alpha * student_loss + (1-alpha) * distillation_loss * T **2\n",
    "        # 反向传播,优化权重\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/distillation_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 蒸馏模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.1518006, 'mse': 0.03801897, 'rmse': 0.19498454216064115, 'evs': 0.9847988784313202, 'r2': 0.9816030012417469, 'mmax': 0.71145415, 'mmin': 0.016973555}\n"
     ]
    }
   ],
   "source": [
    "model = StudentTransformer().to(device)\n",
    "model.load_state_dict(torch.load('./result/distillation_weight.pth'))\n",
    "model.eval()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 蒸馏模型定位效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>PX</th>\n",
       "      <th>Py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.284969</td>\n",
       "      <td>3.602425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.164377</td>\n",
       "      <td>2.080438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.682233</td>\n",
       "      <td>2.803676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.07</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.393359</td>\n",
       "      <td>2.952392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.603147</td>\n",
       "      <td>2.571705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.43</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.892507</td>\n",
       "      <td>1.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.254863</td>\n",
       "      <td>0.782649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.426601</td>\n",
       "      <td>2.106437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.382243</td>\n",
       "      <td>3.688406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.531628</td>\n",
       "      <td>4.341705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.347397</td>\n",
       "      <td>3.730716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.67</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.900538</td>\n",
       "      <td>0.575031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.57</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.908475</td>\n",
       "      <td>0.409832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.340399</td>\n",
       "      <td>3.486715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.76</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4.560523</td>\n",
       "      <td>3.342371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.70</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.664338</td>\n",
       "      <td>3.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.975747</td>\n",
       "      <td>1.356169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.68</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>4.337845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.09</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.108630</td>\n",
       "      <td>4.413423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.25</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.346374</td>\n",
       "      <td>3.777927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X     y        PX        Py\n",
       "0   0.21  3.47  0.284969  3.602425\n",
       "1   1.13  1.96  1.164377  2.080438\n",
       "2   3.38  2.58  3.682233  2.803676\n",
       "3   4.07  2.72  4.393359  2.952392\n",
       "4   1.58  2.47  1.603147  2.571705\n",
       "5   3.43  1.61  3.892507  1.795763\n",
       "6   1.22  0.74  1.254863  0.782649\n",
       "7   2.33  1.97  2.426601  2.106437\n",
       "8   0.33  3.56  0.382243  3.688406\n",
       "9   3.53  4.28  3.531628  4.341705\n",
       "10  4.42  3.69  4.347397  3.730716\n",
       "11  3.67  0.34  3.900538  0.575031\n",
       "12  2.57  0.37  2.908475  0.409832\n",
       "13  3.14  3.22  3.340399  3.486715\n",
       "14  4.76  3.34  4.560523  3.342371\n",
       "15  1.70  3.71  1.664338  3.887244\n",
       "16  3.50  1.20  3.975747  1.356169\n",
       "17  0.68  4.65  0.806122  4.337845\n",
       "18  1.09  4.59  1.108630  4.413423\n",
       "19  0.25  3.70  0.346374  3.777927"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_distill = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_distill)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_distill.csv')\n",
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_distill[:, 0], y_distill[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with KD')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_distill.jpg', dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义问题类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MOEA(ea.Problem):\n",
    "    def __init__(self, train_data_loader, test_data_loader):\n",
    "        name = 'MOEA'\n",
    "        M = 1 # 初始化M（目标维数）\n",
    "        maxormins = [-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标）\n",
    "        Dim = 2 # 初始化Dim（决策变量维数）\n",
    "        varTypes = np.array([0] * Dim) # 初始化varTypes 0-连续\n",
    "        lb = [5, 0.1] # 决策变量下界\n",
    "        ub = [10, 0.9] # 决策变量上界\n",
    "        lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含）\n",
    "        ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含）\n",
    "        # 调用父类构造方法完成实例化\n",
    "        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)\n",
    "        # 数据设置\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.test_data_loader = test_data_loader\n",
    "\n",
    "\n",
    "    # 目标函数，采用多线程加速计算\n",
    "    def aimFunc(self, pop):\n",
    "        Vars = pop.Phen # 得到决策变量矩阵\n",
    "        # print(Vars)\n",
    "        pop.ObjV = np.zeros((pop.sizes, 1)) # 初始化种群个体目标函数值列向量\n",
    "        def subAimFunc(i):\n",
    "            epochs, alpha = int(Vars[i, 0]), float(Vars[i, 1])\n",
    "            print(epochs, alpha)\n",
    "            final_loss = 0\n",
    "            for epoch in range(epochs):\n",
    "                for data,targets in tqdm(train_data_loader):\n",
    "                    data, targets = data.to(device), targets.to(device)\n",
    "                    # 教师模型预测\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(data)\n",
    "                    # 学生模型预测\n",
    "                    student_outputs = model(data)\n",
    "                    student_loss = hard_loss(student_outputs, targets)\n",
    "                    # 计算蒸馏后的预测结果及soft_loss\n",
    "                    distillation_loss = soft_loss(\n",
    "                        F.softmax(student_outputs/T, dim=1),\n",
    "                        F.softmax(teacher_outputs/T, dim=1)\n",
    "                    )\n",
    "                    # 将 hard_loss 和 soft_loss 加权求和\n",
    "                    loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                    final_loss = loss.item()\n",
    "                    # 反向传播,优化权重\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            pop.ObjV[i] = final_loss # 最小化最终的损失作为目标函数\n",
    "        pool = ThreadPool(processes=2) # 设置池的大小\n",
    "        pool.map(subAimFunc, list(range(pop.sizes))) # 散列种群每个个体进行加速计算\n",
    "\n",
    "\n",
    "    # 代入优化后的参数先训练再对测试集进行检验，计算指标\n",
    "    def test(self, epochs, alpha):\n",
    "        for epoch in range(epochs):\n",
    "            for data,targets in tqdm(train_data_loader):\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                # 教师模型预测\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(data)\n",
    "                # 学生模型预测\n",
    "                student_outputs = model(data)\n",
    "                student_loss = hard_loss(student_outputs, targets)\n",
    "                # 计算蒸馏后的预测结果及soft_loss\n",
    "                distillation_loss = soft_loss(\n",
    "                    F.softmax(student_outputs/T, dim=1),\n",
    "                    F.softmax(teacher_outputs/T, dim=1)\n",
    "                )\n",
    "                # 将 hard_loss 和 soft_loss 加权求和\n",
    "                loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                # 反向传播,优化权重\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 测试集上评估性能\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x,y in test_data_loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    outputs = model(x)\n",
    "                    pred = outputs.max(1).indices\n",
    "                    num_correct += (pred == y).sum()\n",
    "                    num_samples += pred.size(0)\n",
    "                acc = (num_correct/num_samples).item()\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n",
    "\n",
    "        torch.save(model.state_dict(), \"./models/moea_distillation.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.3189171239733696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2855765145272017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 2/938 [00:00<00:54, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8424268286675215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 3/938 [00:00<00:39, 23.75it/s]\u001b[A\u001b[A\n",
      "  0%|          | 2/938 [00:00<00:52, 17.78it/s]\u001b[A\n",
      "\n",
      "  1%|          | 6/938 [00:00<00:44, 20.86it/s]\u001b[A\u001b[A\n",
      "  0%|          | 4/938 [00:00<00:51, 18.15it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▎| 878/938 [00:08<00:01, 36.62it/s]A\u001b[A\n",
      " 94%|█████████▎| 878/938 [00:08<00:00, 102.62it/s]\n",
      "\n",
      "\n",
      "  1%|          | 9/938 [00:00<00:48, 19.11it/s]]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8656420316547155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 1/938 [00:00<01:05, 14.39it/s]]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.6277091335505247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 4/938 [00:00<00:25, 37.06it/s]]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 10/938 [00:00<00:26, 34.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 31/938 [00:00<00:23, 38.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 38/938 [00:01<00:19, 45.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 46/938 [00:01<00:16, 54.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 54/938 [00:01<00:14, 61.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 65/938 [00:01<00:11, 74.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 76/938 [00:01<00:10, 83.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 86/938 [00:01<00:09, 88.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 96/938 [00:01<00:09, 89.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 106/938 [00:01<00:09, 85.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 116/938 [00:01<00:09, 87.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 125/938 [00:02<00:09, 87.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 134/938 [00:02<00:09, 86.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 143/938 [00:02<00:09, 87.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 152/938 [00:02<00:09, 86.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 163/938 [00:02<00:08, 92.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 174/938 [00:02<00:08, 95.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 184/938 [00:02<00:08, 92.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 194/938 [00:02<00:08, 92.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 205/938 [00:02<00:07, 96.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 216/938 [00:03<00:07, 99.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 226/938 [00:03<00:07, 97.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 237/938 [00:03<00:07, 100.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 248/938 [00:03<00:06, 101.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 260/938 [00:03<00:06, 104.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 272/938 [00:03<00:06, 106.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 283/938 [00:03<00:06, 105.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 295/938 [00:03<00:05, 107.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 306/938 [00:03<00:05, 107.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 317/938 [00:03<00:05, 106.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 328/938 [00:04<00:05, 105.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 339/938 [00:04<00:05, 107.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 351/938 [00:04<00:05, 108.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 362/938 [00:04<00:05, 106.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 374/938 [00:04<00:05, 107.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 385/938 [00:04<00:05, 106.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 397/938 [00:04<00:04, 108.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 409/938 [00:04<00:04, 109.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 421/938 [00:04<00:04, 111.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 433/938 [00:05<00:04, 112.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 445/938 [00:05<00:04, 111.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 457/938 [00:05<00:04, 112.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 469/938 [00:05<00:04, 108.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 481/938 [00:05<00:04, 110.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 493/938 [00:05<00:03, 111.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 505/938 [00:05<00:03, 111.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 517/938 [00:05<00:03, 112.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 529/938 [00:05<00:03, 113.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 541/938 [00:05<00:03, 113.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 553/938 [00:06<00:03, 112.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 565/938 [00:06<00:03, 113.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 577/938 [00:06<00:03, 113.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 589/938 [00:06<00:03, 114.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 601/938 [00:06<00:02, 115.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 613/938 [00:06<00:02, 112.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 625/938 [00:06<00:02, 113.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 637/938 [00:06<00:02, 114.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 649/938 [00:06<00:02, 114.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 661/938 [00:07<00:02, 115.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 673/938 [00:07<00:02, 115.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 685/938 [00:07<00:02, 106.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 696/938 [00:07<00:02, 105.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 708/938 [00:07<00:02, 109.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 719/938 [00:07<00:02, 106.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 731/938 [00:07<00:01, 109.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 743/938 [00:07<00:01, 112.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 755/938 [00:07<00:01, 113.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 767/938 [00:08<00:01, 110.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 779/938 [00:08<00:01, 109.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 791/938 [00:08<00:01, 112.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 803/938 [00:08<00:01, 105.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 814/938 [00:08<00:01, 103.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 825/938 [00:08<00:01, 103.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 836/938 [00:08<00:00, 104.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 848/938 [00:08<00:00, 106.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 859/938 [00:08<00:00, 106.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 871/938 [00:09<00:00, 108.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 882/938 [00:09<00:00, 104.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 893/938 [00:09<00:00, 104.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 904/938 [00:09<00:00, 99.99it/s] \u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 915/938 [00:09<00:00, 100.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 926/938 [00:09<00:00, 101.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 938/938 [00:09<00:00, 96.68it/s] \u001b[A\u001b[A\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.38it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 105.10it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 112.47it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.13it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.2740337282419205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 109.97it/s]\n",
      "100%|██████████| 938/938 [00:07<00:00, 118.57it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.56it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.24it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 104.54it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.32it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 106.33it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 116.82it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e006b3843ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mBestIndi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyAlgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 执行算法模板，得到最优个体以及最后一代种群\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mBestIndi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 把最优个体的信息保存到文件中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/templates/soeas/DE/DE_rand_1_bin/soea_DE_rand_1_bin_templet.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, prophetPop)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# ===========================准备进化============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitChrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNIND\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 初始化种群染色体矩阵\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_aimFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 计算种群的目标函数值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m# 插入先验知识（注意：这里不会对先知种群prophetPop的合法性进行检查，故应确保prophetPop是一个种群类且拥有合法的Chrom、ObjV、Phen等属性）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprophetPop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/Algorithm.py\u001b[0m in \u001b[0;36mcall_aimFunc\u001b[0;34m(self, pop)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error: problem has not been initialized. (算法模板中的问题对象未被初始化。)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maimFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 调用问题类的aimFunc()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalsNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalsNum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalsNum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m  \u001b[0;31m# 更新评价次数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# 格式检查\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-29ea1f645391>\u001b[0m in \u001b[0;36maimFunc\u001b[0;34m(self, pop)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_loss\u001b[0m \u001b[0;31m# 最小化最终的损失作为目标函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 设置池的大小\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubAimFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 散列种群每个个体进行加速计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-29ea1f645391>\u001b[0m in \u001b[0;36msubAimFunc\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;31m# 反向传播,优化权重\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "\"\"\"===============================实例化问题对象===========================\"\"\"\n",
    "\n",
    "problem = MOEA(train_data_loader, test_data_loader) # 生成问题对象\n",
    "\n",
    "\"\"\"=================================种群设置===============================\"\"\"\n",
    "\n",
    "Encoding = 'RI'       # 编码方式\n",
    "NIND = 10             # 种群规模\n",
    "Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器\n",
    "population = ea.Population(Encoding, Field, NIND) # 实例化种群对象（此时种群还没被初始化，仅仅是完成种群对象的实例化）\n",
    "\n",
    "\"\"\"===============================算法参数设置=============================\"\"\"\n",
    "\n",
    "myAlgorithm = ea.soea_DE_rand_1_bin_templet(problem, population) # 实例化一个算法模板对象\n",
    "myAlgorithm.MAXGEN = 10 # 最大进化代数\n",
    "myAlgorithm.trappedValue = 1e-6 # “进化停滞”判断阈值\n",
    "myAlgorithm.maxTrappedCount = 10 # 进化停滞计数器最大上限值，如果连续maxTrappedCount代被判定进化陷入停滞，则终止进化\n",
    "myAlgorithm.logTras = 1  # 设置每隔多少代记录日志，若设置成0则表示不记录日志\n",
    "myAlgorithm.verbose = True  # 设置是否打印输出日志信息\n",
    "myAlgorithm.drawing = 1  # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画）\n",
    "\n",
    "\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\n",
    "\n",
    "[BestIndi, population] = myAlgorithm.run()  # 执行算法模板，得到最优个体以及最后一代种群\n",
    "BestIndi.save()  # 把最优个体的信息保存到文件中\n",
    "\n",
    "\"\"\"==================================输出结果=============================\"\"\"\n",
    "\n",
    "print('用时：%f 秒' % myAlgorithm.passTime)\n",
    "print('评价次数：%d 次' % myAlgorithm.evalsNum)\n",
    "if BestIndi.sizes != 0:\n",
    "    print('最优的目标函数值为：%s' % BestIndi.ObjV[0][0])\n",
    "    print('最优的控制变量值为：')\n",
    "    for i in range(BestIndi.Phen.shape[1]):\n",
    "        print(BestIndi.Phen[0, i])\n",
    "else:\n",
    "    print('没找到可行解。')\n",
    "\n",
    "\"\"\"=================================检验结果===============================\"\"\"\n",
    "\n",
    "problem.test(epochs= int(BestIndi.Phen[0][0]), alpha= float(BestIndi.Phen[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
