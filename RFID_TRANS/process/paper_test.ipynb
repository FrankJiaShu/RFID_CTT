{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识蒸馏-RFID Transformer teacher->GRU student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geatpy as ea\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.calculate_param as cp\n",
    "from dataset import data_read\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 硬件设备准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 50)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = data_read.load_data('train')\n",
    "X_test, y_test = data_read.load_data('test')\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2000, 50])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device) # [len * feature]\n",
    "y_train = torch.from_numpy(y_train).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device) # [len * feature]\n",
    "y_test = torch.from_numpy(y_test).float().to(device)\n",
    "\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=100, shuffle=False)\n",
    "test_data_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义教师模型-transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 位置编码类\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.pe[:x.size(0), :]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TeacherTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherTransformer, self).__init__()\n",
    "        self.d_model = 128  # 词向量维度\n",
    "        self.embedding_enc = nn.Linear(50, self.d_model)\n",
    "        self.embedding_dec = nn.Linear(2, self.d_model)\n",
    "        self.pos_encoding = PositionalEncoding(self.d_model)\n",
    "        self.Transformer_layer = nn.Transformer(d_model=128, num_encoder_layers=3, num_decoder_layers=3, batch_first=True)\n",
    "        self.FC_layer = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 使用线性层代替embedding\n",
    "        src = self.embedding_enc(src).unsqueeze(0)\n",
    "        tgt = self.embedding_dec(tgt).unsqueeze(0)\n",
    "        src = self.pos_encoding(src)\n",
    "        out = self.Transformer_layer(src, tgt)\n",
    "        out = self.FC_layer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = TeacherTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "TeacherTransformer                                                     --\n",
      "├─Linear: 1-1                                                          6,528\n",
      "├─Linear: 1-2                                                          384\n",
      "├─PositionalEncoding: 1-3                                              --\n",
      "├─Transformer: 1-4                                                     --\n",
      "│    └─TransformerEncoder: 2-1                                         --\n",
      "│    │    └─ModuleList: 3-1                                            1,779,072\n",
      "│    │    └─LayerNorm: 3-2                                             256\n",
      "│    └─TransformerDecoder: 2-2                                         --\n",
      "│    │    └─ModuleList: 3-3                                            1,977,984\n",
      "│    │    └─LayerNorm: 3-4                                             256\n",
      "├─Linear: 1-5                                                          258\n",
      "===============================================================================================\n",
      "Total params: 3,764,738\n",
      "Trainable params: 3,764,738\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出教师模型的参数信息-300w参数\n",
    "cp.get_summary(model, input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 146.021196\n",
      "Epoch: 0002 loss = 48.642279\n",
      "Epoch: 0003 loss = 48.374830\n",
      "Epoch: 0004 loss = 40.773885\n",
      "Epoch: 0005 loss = 38.780626\n",
      "Epoch: 0006 loss = 31.814842\n",
      "Epoch: 0007 loss = 22.182482\n",
      "Epoch: 0008 loss = 15.505138\n",
      "Epoch: 0009 loss = 13.970082\n",
      "Epoch: 0010 loss = 9.494105\n",
      "Epoch: 0011 loss = 5.759591\n",
      "Epoch: 0012 loss = 5.455363\n",
      "Epoch: 0013 loss = 4.145405\n",
      "Epoch: 0014 loss = 4.251118\n",
      "Epoch: 0015 loss = 3.749619\n",
      "Epoch: 0016 loss = 2.698970\n",
      "Epoch: 0017 loss = 2.341664\n",
      "Epoch: 0018 loss = 2.750972\n",
      "Epoch: 0019 loss = 2.069706\n",
      "Epoch: 0020 loss = 2.142641\n",
      "Epoch: 0021 loss = 1.876754\n",
      "Epoch: 0022 loss = 1.554499\n",
      "Epoch: 0023 loss = 1.750292\n",
      "Epoch: 0024 loss = 1.905683\n",
      "Epoch: 0025 loss = 1.418602\n",
      "Epoch: 0026 loss = 1.549186\n",
      "Epoch: 0027 loss = 1.689632\n",
      "Epoch: 0028 loss = 1.545023\n",
      "Epoch: 0029 loss = 1.254578\n",
      "Epoch: 0030 loss = 1.295816\n",
      "Epoch: 0031 loss = 1.113830\n",
      "Epoch: 0032 loss = 1.197965\n",
      "Epoch: 0033 loss = 1.369943\n",
      "Epoch: 0034 loss = 1.013569\n",
      "Epoch: 0035 loss = 1.231339\n",
      "Epoch: 0036 loss = 1.386474\n",
      "Epoch: 0037 loss = 0.975088\n",
      "Epoch: 0038 loss = 1.162244\n",
      "Epoch: 0039 loss = 1.086151\n",
      "Epoch: 0040 loss = 0.970686\n",
      "Epoch: 0041 loss = 1.069518\n",
      "Epoch: 0042 loss = 0.718160\n",
      "Epoch: 0043 loss = 0.693110\n",
      "Epoch: 0044 loss = 0.703323\n",
      "Epoch: 0045 loss = 0.699173\n",
      "Epoch: 0046 loss = 0.809498\n",
      "Epoch: 0047 loss = 0.623248\n",
      "Epoch: 0048 loss = 0.748733\n",
      "Epoch: 0049 loss = 0.909876\n",
      "Epoch: 0050 loss = 0.733224\n",
      "Epoch: 0051 loss = 0.675324\n",
      "Epoch: 0052 loss = 0.659211\n",
      "Epoch: 0053 loss = 0.509601\n",
      "Epoch: 0054 loss = 0.505444\n",
      "Epoch: 0055 loss = 0.525242\n",
      "Epoch: 0056 loss = 0.607783\n",
      "Epoch: 0057 loss = 0.716973\n",
      "Epoch: 0058 loss = 0.638316\n",
      "Epoch: 0059 loss = 0.567311\n",
      "Epoch: 0060 loss = 0.571196\n",
      "Epoch: 0061 loss = 0.517468\n",
      "Epoch: 0062 loss = 0.468084\n",
      "Epoch: 0063 loss = 0.518527\n",
      "Epoch: 0064 loss = 0.532766\n",
      "Epoch: 0065 loss = 0.633589\n",
      "Epoch: 0066 loss = 0.542620\n",
      "Epoch: 0067 loss = 0.513787\n",
      "Epoch: 0068 loss = 0.506317\n",
      "Epoch: 0069 loss = 0.483628\n",
      "Epoch: 0070 loss = 0.507854\n",
      "Epoch: 0071 loss = 0.500861\n",
      "Epoch: 0072 loss = 0.445483\n",
      "Epoch: 0073 loss = 0.376043\n",
      "Epoch: 0074 loss = 0.395517\n",
      "Epoch: 0075 loss = 0.370844\n",
      "Epoch: 0076 loss = 0.374642\n",
      "Epoch: 0077 loss = 0.398057\n",
      "Epoch: 0078 loss = 0.416179\n",
      "Epoch: 0079 loss = 0.468224\n",
      "Epoch: 0080 loss = 0.448743\n",
      "Epoch: 0081 loss = 0.461111\n",
      "Epoch: 0082 loss = 0.446102\n",
      "Epoch: 0083 loss = 0.470443\n",
      "Epoch: 0084 loss = 0.392187\n",
      "Epoch: 0085 loss = 0.345276\n",
      "Epoch: 0086 loss = 0.331676\n",
      "Epoch: 0087 loss = 0.334069\n",
      "Epoch: 0088 loss = 0.326836\n",
      "Epoch: 0089 loss = 0.350567\n",
      "Epoch: 0090 loss = 0.377730\n",
      "Epoch: 0091 loss = 0.423912\n",
      "Epoch: 0092 loss = 0.411489\n",
      "Epoch: 0093 loss = 0.314159\n",
      "Epoch: 0094 loss = 0.325789\n",
      "Epoch: 0095 loss = 0.307691\n",
      "Epoch: 0096 loss = 0.311124\n",
      "Epoch: 0097 loss = 0.425064\n",
      "Epoch: 0098 loss = 0.371573\n",
      "Epoch: 0099 loss = 0.351531\n",
      "Epoch: 0100 loss = 0.422515\n",
      "best_loss::| 0.3076905161142349 ---best_epoch::| 94\n",
      "CPU times: user 4min 11s, sys: 47.1 s, total: 4min 58s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:  # enc_inputs : [len * feature]->[2000 * 50]\n",
    "        # print(X.shape)  # [100 * 50]\n",
    "        # print(y.shape)  # [100 * 50]\n",
    "        outputs = model(X, y)\n",
    "        outputs = outputs.squeeze()  # [100 * 2]\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss_num = loss.item()\n",
    "        epoch_loss += loss_num\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/teacher_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.084892, 'mse': 0.011776982, 'rmse': 0.10852180368617363, 'evs': 0.9972739815711975, 'r2': 0.9943189869485213, 'mmax': 0.21287823, 'mmin': 0.0052908137}\n"
     ]
    }
   ],
   "source": [
    "model = TeacherTransformer().to(device)\n",
    "# 暂存教师模型为teacher_model\n",
    "teacher_model = model\n",
    "model.load_state_dict(torch.load('./result/teacher_weight.pth'))\n",
    "model.eval()\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教师模型定位效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>PX</th>\n",
       "      <th>Py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.179203</td>\n",
       "      <td>3.613626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.182119</td>\n",
       "      <td>2.018872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.475395</td>\n",
       "      <td>2.628522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.07</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.254373</td>\n",
       "      <td>2.789131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.662742</td>\n",
       "      <td>2.512204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.43</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.558935</td>\n",
       "      <td>1.657329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.247052</td>\n",
       "      <td>0.733851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.385608</td>\n",
       "      <td>2.029962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.297978</td>\n",
       "      <td>3.725786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.700464</td>\n",
       "      <td>4.499172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.646064</td>\n",
       "      <td>3.832847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.67</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.877194</td>\n",
       "      <td>0.297701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.57</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.662488</td>\n",
       "      <td>0.357804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.255364</td>\n",
       "      <td>3.308111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.76</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4.927291</td>\n",
       "      <td>3.414310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.70</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.767315</td>\n",
       "      <td>3.836316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.674821</td>\n",
       "      <td>1.218679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.68</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.687669</td>\n",
       "      <td>4.779669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.09</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.104179</td>\n",
       "      <td>4.770106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.25</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.215453</td>\n",
       "      <td>3.864165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X     y        PX        Py\n",
       "0   0.21  3.47  0.179203  3.613626\n",
       "1   1.13  1.96  1.182119  2.018872\n",
       "2   3.38  2.58  3.475395  2.628522\n",
       "3   4.07  2.72  4.254373  2.789131\n",
       "4   1.58  2.47  1.662742  2.512204\n",
       "5   3.43  1.61  3.558935  1.657329\n",
       "6   1.22  0.74  1.247052  0.733851\n",
       "7   2.33  1.97  2.385608  2.029962\n",
       "8   0.33  3.56  0.297978  3.725786\n",
       "9   3.53  4.28  3.700464  4.499172\n",
       "10  4.42  3.69  4.646064  3.832847\n",
       "11  3.67  0.34  3.877194  0.297701\n",
       "12  2.57  0.37  2.662488  0.357804\n",
       "13  3.14  3.22  3.255364  3.308111\n",
       "14  4.76  3.34  4.927291  3.414310\n",
       "15  1.70  3.71  1.767315  3.836316\n",
       "16  3.50  1.20  3.674821  1.218679\n",
       "17  0.68  4.65  0.687669  4.779669\n",
       "18  1.09  4.59  1.104179  4.770106\n",
       "19  0.25  3.70  0.215453  3.864165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teacher = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_teacher)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_teacher.csv')\n",
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_teacher[:, 0], y_teacher[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with Transformer')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_teacher.jpg', dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义学生模型-小变压器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class StudentTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentTransformer, self).__init__()\n",
    "        self.d_model = 8  # 词向量维度\n",
    "        self.embedding_enc = nn.Linear(50, self.d_model)\n",
    "        self.embedding_dec = nn.Linear(2, self.d_model)\n",
    "        self.Transformer_layer = nn.Transformer(d_model=8, num_encoder_layers=1, num_decoder_layers=1, batch_first=True)\n",
    "        self.FC_layer = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 使用线性层代替embedding\n",
    "        src = self.embedding_enc(src).unsqueeze(0)\n",
    "        tgt = self.embedding_dec(tgt).unsqueeze(0)\n",
    "        out = self.Transformer_layer(src, tgt)\n",
    "        out = self.FC_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 从头先训练一下学生模型\n",
    "model = StudentTransformer().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchinfo信息如下：\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "StudentTransformer                                                     --\n",
      "├─Linear: 1-1                                                          408\n",
      "├─Linear: 1-2                                                          24\n",
      "├─Transformer: 1-3                                                     --\n",
      "│    └─TransformerEncoder: 2-1                                         --\n",
      "│    │    └─ModuleList: 3-1                                            35,144\n",
      "│    │    └─LayerNorm: 3-2                                             16\n",
      "│    └─TransformerDecoder: 2-2                                         --\n",
      "│    │    └─ModuleList: 3-3                                            35,448\n",
      "│    │    └─LayerNorm: 3-4                                             16\n",
      "├─Linear: 1-4                                                          18\n",
      "===============================================================================================\n",
      "Total params: 71,074\n",
      "Trainable params: 71,074\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 输出学生模型的参数信息-1w参数\n",
    "cp.get_summary(model, input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 139.130597\n",
      "Epoch: 0002 loss = 97.224904\n",
      "Epoch: 0003 loss = 61.542907\n",
      "Epoch: 0004 loss = 43.566233\n",
      "Epoch: 0005 loss = 46.203680\n",
      "Epoch: 0006 loss = 46.952348\n",
      "Epoch: 0007 loss = 41.023726\n",
      "Epoch: 0008 loss = 45.715397\n",
      "Epoch: 0009 loss = 40.270610\n",
      "Epoch: 0010 loss = 39.936496\n",
      "Epoch: 0011 loss = 37.431767\n",
      "Epoch: 0012 loss = 33.447421\n",
      "Epoch: 0013 loss = 29.424758\n",
      "Epoch: 0014 loss = 23.759452\n",
      "Epoch: 0015 loss = 25.533319\n",
      "Epoch: 0016 loss = 24.320489\n",
      "Epoch: 0017 loss = 21.061591\n",
      "Epoch: 0018 loss = 19.128983\n",
      "Epoch: 0019 loss = 14.962416\n",
      "Epoch: 0020 loss = 9.974117\n",
      "Epoch: 0021 loss = 7.762563\n",
      "Epoch: 0022 loss = 7.252261\n",
      "Epoch: 0023 loss = 6.549025\n",
      "Epoch: 0024 loss = 5.996923\n",
      "Epoch: 0025 loss = 5.540876\n",
      "Epoch: 0026 loss = 5.039779\n",
      "Epoch: 0027 loss = 4.265544\n",
      "Epoch: 0028 loss = 4.093740\n",
      "Epoch: 0029 loss = 3.506531\n",
      "Epoch: 0030 loss = 3.136931\n",
      "Epoch: 0031 loss = 2.851424\n",
      "Epoch: 0032 loss = 2.618742\n",
      "Epoch: 0033 loss = 2.439405\n",
      "Epoch: 0034 loss = 2.309009\n",
      "Epoch: 0035 loss = 2.148235\n",
      "Epoch: 0036 loss = 2.352889\n",
      "Epoch: 0037 loss = 1.867808\n",
      "Epoch: 0038 loss = 2.062507\n",
      "Epoch: 0039 loss = 1.719774\n",
      "Epoch: 0040 loss = 1.869026\n",
      "Epoch: 0041 loss = 1.590761\n",
      "Epoch: 0042 loss = 1.520358\n",
      "Epoch: 0043 loss = 1.471584\n",
      "Epoch: 0044 loss = 1.519939\n",
      "Epoch: 0045 loss = 1.352115\n",
      "Epoch: 0046 loss = 1.384212\n",
      "Epoch: 0047 loss = 1.252323\n",
      "Epoch: 0048 loss = 1.338291\n",
      "Epoch: 0049 loss = 1.230689\n",
      "Epoch: 0050 loss = 1.255565\n",
      "Epoch: 0051 loss = 1.166977\n",
      "Epoch: 0052 loss = 1.178662\n",
      "Epoch: 0053 loss = 1.096643\n",
      "Epoch: 0054 loss = 0.966547\n",
      "Epoch: 0055 loss = 0.836914\n",
      "Epoch: 0056 loss = 0.945276\n",
      "Epoch: 0057 loss = 0.827973\n",
      "Epoch: 0058 loss = 0.921610\n",
      "Epoch: 0059 loss = 0.782994\n",
      "Epoch: 0060 loss = 0.839072\n",
      "Epoch: 0061 loss = 0.719440\n",
      "Epoch: 0062 loss = 0.803847\n",
      "Epoch: 0063 loss = 0.649825\n",
      "Epoch: 0064 loss = 0.693687\n",
      "Epoch: 0065 loss = 0.626244\n",
      "Epoch: 0066 loss = 0.617384\n",
      "Epoch: 0067 loss = 0.552085\n",
      "Epoch: 0068 loss = 0.555797\n",
      "Epoch: 0069 loss = 0.524649\n",
      "Epoch: 0070 loss = 0.593270\n",
      "Epoch: 0071 loss = 0.543580\n",
      "Epoch: 0072 loss = 0.578153\n",
      "Epoch: 0073 loss = 0.506772\n",
      "Epoch: 0074 loss = 0.531487\n",
      "Epoch: 0075 loss = 0.530793\n",
      "Epoch: 0076 loss = 0.506764\n",
      "Epoch: 0077 loss = 0.518900\n",
      "Epoch: 0078 loss = 0.421687\n",
      "Epoch: 0079 loss = 0.431945\n",
      "Epoch: 0080 loss = 0.417714\n",
      "Epoch: 0081 loss = 0.417617\n",
      "Epoch: 0082 loss = 0.470894\n",
      "Epoch: 0083 loss = 0.398913\n",
      "Epoch: 0084 loss = 0.412360\n",
      "Epoch: 0085 loss = 0.434758\n",
      "Epoch: 0086 loss = 0.342018\n",
      "Epoch: 0087 loss = 0.355662\n",
      "Epoch: 0088 loss = 0.318917\n",
      "Epoch: 0089 loss = 0.322305\n",
      "Epoch: 0090 loss = 0.324324\n",
      "Epoch: 0091 loss = 0.361366\n",
      "Epoch: 0092 loss = 0.331830\n",
      "Epoch: 0093 loss = 0.287865\n",
      "Epoch: 0094 loss = 0.269841\n",
      "Epoch: 0095 loss = 0.296328\n",
      "Epoch: 0096 loss = 0.340956\n",
      "Epoch: 0097 loss = 0.256051\n",
      "Epoch: 0098 loss = 0.242094\n",
      "Epoch: 0099 loss = 0.308351\n",
      "Epoch: 0100 loss = 0.347302\n",
      "best_loss::| 0.2420944324694574 ---best_epoch::| 97\n",
      "CPU times: user 39.6 s, sys: 2.54 s, total: 42.1 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:  # enc_inputs : [len * feature]->[2000 * 50]\n",
    "        outputs = model(X, y)\n",
    "        outputs = outputs.squeeze()  # [100 * 2]\n",
    "        loss = criterion(outputs, y)\n",
    "        loss_num = loss.item()\n",
    "        epoch_loss += loss_num\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/student_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|', best_loss, '---best_epoch::|', best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.06455692, 'mse': 0.007047292, 'rmse': 0.08394814974186886, 'evs': 0.9978922605514526, 'r2': 0.9966219557245699, 'mmax': 0.15922213, 'mmin': 0.0050887465}\n"
     ]
    }
   ],
   "source": [
    "model = StudentTransformer().to(device)\n",
    "# 暂存教师模型为teacher_model\n",
    "student_model = model\n",
    "model.load_state_dict(torch.load('./result/student_weight.pth'))\n",
    "model.eval()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学生模型定位效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 X               y  PX-MOEA  Py-MOEA  PX-NAAS  Py-NAAS\n0   tensor(0.2100)  tensor(3.4700)    0.241    3.488    0.192    3.548\n1   tensor(1.1300)  tensor(1.9600)    1.227    2.030    1.173    1.972\n2   tensor(3.3800)  tensor(2.5800)    3.537    2.669    3.404    2.599\n3   tensor(4.0700)  tensor(2.7200)    4.336    2.836    4.172    2.768\n4   tensor(1.5800)  tensor(2.4700)    1.702    2.534    1.621    2.455\n5   tensor(3.4300)  tensor(1.6100)    3.593    1.676    3.477    1.648\n6   tensor(1.2200)  tensor(0.7400)    1.302    0.763    1.227    0.751\n7   tensor(2.3300)  tensor(1.9700)    2.442    2.057    2.356    1.999\n8   tensor(0.3300)  tensor(3.5600)    0.359    3.796    0.304    3.654\n9   tensor(3.5300)  tensor(4.2800)    3.826    4.540    3.646    4.429\n10  tensor(4.4200)  tensor(3.6900)    4.767    3.884    4.583    3.804\n11  tensor(3.6700)  tensor(0.3400)    3.932    0.335    3.762    0.336\n12  tensor(2.5700)  tensor(0.3700)    2.717    0.386    2.599    0.389\n13  tensor(3.1400)  tensor(3.2200)    3.319    3.338    3.171    3.239\n14  tensor(4.7600)  tensor(3.3400)    4.935    3.454    4.869    3.397\n15  tensor(1.7000)  tensor(3.7100)    1.840    3.895    1.750    3.755\n16  tensor(3.5000)  tensor(1.2000)    3.716    1.242    3.587    1.226\n17  tensor(0.6800)  tensor(4.6500)    0.768    4.860    0.659    4.707\n18  tensor(1.0900)  tensor(4.5900)    1.192    4.845    1.069    4.689\n19  tensor(0.2500)  tensor(3.7000)    0.286    3.939    0.229    3.794",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n      <th>PX-MOEA</th>\n      <th>Py-MOEA</th>\n      <th>PX-NAAS</th>\n      <th>Py-NAAS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tensor(0.2100)</td>\n      <td>tensor(3.4700)</td>\n      <td>0.241</td>\n      <td>3.488</td>\n      <td>0.192</td>\n      <td>3.548</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tensor(1.1300)</td>\n      <td>tensor(1.9600)</td>\n      <td>1.227</td>\n      <td>2.030</td>\n      <td>1.173</td>\n      <td>1.972</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tensor(3.3800)</td>\n      <td>tensor(2.5800)</td>\n      <td>3.537</td>\n      <td>2.669</td>\n      <td>3.404</td>\n      <td>2.599</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tensor(4.0700)</td>\n      <td>tensor(2.7200)</td>\n      <td>4.336</td>\n      <td>2.836</td>\n      <td>4.172</td>\n      <td>2.768</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tensor(1.5800)</td>\n      <td>tensor(2.4700)</td>\n      <td>1.702</td>\n      <td>2.534</td>\n      <td>1.621</td>\n      <td>2.455</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>tensor(3.4300)</td>\n      <td>tensor(1.6100)</td>\n      <td>3.593</td>\n      <td>1.676</td>\n      <td>3.477</td>\n      <td>1.648</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>tensor(1.2200)</td>\n      <td>tensor(0.7400)</td>\n      <td>1.302</td>\n      <td>0.763</td>\n      <td>1.227</td>\n      <td>0.751</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>tensor(2.3300)</td>\n      <td>tensor(1.9700)</td>\n      <td>2.442</td>\n      <td>2.057</td>\n      <td>2.356</td>\n      <td>1.999</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>tensor(0.3300)</td>\n      <td>tensor(3.5600)</td>\n      <td>0.359</td>\n      <td>3.796</td>\n      <td>0.304</td>\n      <td>3.654</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>tensor(3.5300)</td>\n      <td>tensor(4.2800)</td>\n      <td>3.826</td>\n      <td>4.540</td>\n      <td>3.646</td>\n      <td>4.429</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>tensor(4.4200)</td>\n      <td>tensor(3.6900)</td>\n      <td>4.767</td>\n      <td>3.884</td>\n      <td>4.583</td>\n      <td>3.804</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>tensor(3.6700)</td>\n      <td>tensor(0.3400)</td>\n      <td>3.932</td>\n      <td>0.335</td>\n      <td>3.762</td>\n      <td>0.336</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>tensor(2.5700)</td>\n      <td>tensor(0.3700)</td>\n      <td>2.717</td>\n      <td>0.386</td>\n      <td>2.599</td>\n      <td>0.389</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>tensor(3.1400)</td>\n      <td>tensor(3.2200)</td>\n      <td>3.319</td>\n      <td>3.338</td>\n      <td>3.171</td>\n      <td>3.239</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>tensor(4.7600)</td>\n      <td>tensor(3.3400)</td>\n      <td>4.935</td>\n      <td>3.454</td>\n      <td>4.869</td>\n      <td>3.397</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>tensor(1.7000)</td>\n      <td>tensor(3.7100)</td>\n      <td>1.840</td>\n      <td>3.895</td>\n      <td>1.750</td>\n      <td>3.755</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>tensor(3.5000)</td>\n      <td>tensor(1.2000)</td>\n      <td>3.716</td>\n      <td>1.242</td>\n      <td>3.587</td>\n      <td>1.226</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>tensor(0.6800)</td>\n      <td>tensor(4.6500)</td>\n      <td>0.768</td>\n      <td>4.860</td>\n      <td>0.659</td>\n      <td>4.707</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>tensor(1.0900)</td>\n      <td>tensor(4.5900)</td>\n      <td>1.192</td>\n      <td>4.845</td>\n      <td>1.069</td>\n      <td>4.689</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>tensor(0.2500)</td>\n      <td>tensor(3.7000)</td>\n      <td>0.286</td>\n      <td>3.939</td>\n      <td>0.229</td>\n      <td>3.794</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_student = y_test[:20]\n",
    "pxy1 = [\n",
    "[0.241, 3.488],\n",
    "[1.227, 2.030],\n",
    "[3.537, 2.669],\n",
    "[4.336, 2.836],\n",
    "[1.702, 2.534],\n",
    "[3.593, 1.676],\n",
    "[1.302, 0.763],\n",
    "[2.442, 2.057],\n",
    "[0.359, 3.796],\n",
    "[3.826, 4.540],\n",
    "[4.767, 3.884],\n",
    "[3.932, 0.335], \n",
    "[2.717, 0.386], \n",
    "[3.319, 3.338], \n",
    "[4.935, 3.454],\n",
    "[1.840, 3.895], \n",
    "[3.716, 1.242],\n",
    "[0.768, 4.860], \n",
    "[1.192, 4.845], \n",
    "[0.286, 3.939] \n",
    "]\n",
    "pxy1 = np.array(pxy1)\n",
    "pxy2 = [\n",
    "[0.192, 3.548],\n",
    "[1.173, 1.972],\n",
    "[3.404, 2.599],\n",
    "[4.172, 2.768],\n",
    "[1.621, 2.455],\n",
    "[3.477, 1.648],\n",
    "[1.227, 0.751],\n",
    "[2.356, 1.999],\n",
    "[0.304, 3.654],\n",
    "[3.646, 4.429],\n",
    "[4.583, 3.804],\n",
    "[3.762, 0.336], \n",
    "[2.599, 0.389],\n",
    "[3.171, 3.239], \n",
    "[4.869, 3.397], \n",
    "[1.750, 3.755], \n",
    "[3.587, 1.226], \n",
    "[0.659, 4.707], \n",
    "[1.069, 4.689], \n",
    "[0.229, 3.794]]\n",
    "pxy2 = np.array(pxy2)\n",
    "\n",
    "coor1 = pd.DataFrame(y_student)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy1)\n",
    "coor2.columns = ['PX-MOEA', 'Py-MOEA']\n",
    "\n",
    "coor3 = pd.DataFrame(pxy2)\n",
    "coor3.columns = ['PX-NAAS', 'Py-NAAS']\n",
    "\n",
    "coor = pd.concat([coor1, coor2, coor3], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_student.csv')\n",
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_student[:, 0], y_student[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy1[:, 0], pxy1[:, 1], c='blue', marker='x', label = 'predict position with CTT-MOEA')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy2[:, 0], pxy2[:, 1], c='red', marker='x', label = 'predict position with CTT-MOEA(NAAS)')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_student.jpg', dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识蒸馏准备与设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 准备预训练好的教师模型\n",
    "teacher_model.eval()\n",
    "\n",
    "# 准备新的学生模型\n",
    "model = StudentTransformer().to(device)\n",
    "\n",
    "# 蒸馏温度\n",
    "T = 9\n",
    "\n",
    "# 蒸馏参数设置\n",
    "# hard_loss\n",
    "hard_loss = nn.MSELoss()\n",
    "# hard_loss权重\n",
    "alpha = 0.3\n",
    "# soft_loss kl散度\n",
    "soft_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识蒸馏训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frank/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([100, 2])) that is different to the input size (torch.Size([1, 100, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = -10411.670044\n",
      "Epoch: 0002 loss = -10418.210693\n",
      "Epoch: 0003 loss = -10421.324890\n",
      "Epoch: 0004 loss = -10423.941284\n",
      "Epoch: 0005 loss = -10426.218933\n",
      "Epoch: 0006 loss = -10428.354126\n",
      "Epoch: 0007 loss = -10430.313354\n",
      "Epoch: 0008 loss = -10431.782532\n",
      "Epoch: 0009 loss = -10432.940125\n",
      "Epoch: 0010 loss = -10433.869324\n",
      "Epoch: 0011 loss = -10434.597595\n",
      "Epoch: 0012 loss = -10435.117432\n",
      "Epoch: 0013 loss = -10435.506226\n",
      "Epoch: 0014 loss = -10435.813904\n",
      "Epoch: 0015 loss = -10436.074402\n",
      "Epoch: 0016 loss = -10436.317200\n",
      "Epoch: 0017 loss = -10436.344788\n",
      "Epoch: 0018 loss = -10436.564209\n",
      "Epoch: 0019 loss = -10436.755188\n",
      "Epoch: 0020 loss = -10436.831909\n",
      "Epoch: 0021 loss = -10436.896179\n",
      "Epoch: 0022 loss = -10437.046326\n",
      "Epoch: 0023 loss = -10436.998596\n",
      "Epoch: 0024 loss = -10437.144775\n",
      "Epoch: 0025 loss = -10437.139221\n",
      "Epoch: 0026 loss = -10437.155823\n",
      "Epoch: 0027 loss = -10437.171570\n",
      "Epoch: 0028 loss = -10437.223450\n",
      "Epoch: 0029 loss = -10437.242004\n",
      "Epoch: 0030 loss = -10437.252441\n",
      "Epoch: 0031 loss = -10437.253479\n",
      "Epoch: 0032 loss = -10437.311096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-17-8c8cefb44712>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src, tgt)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0msrc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_enc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mtgt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_dec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtgt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTransformer_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFC_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m         \u001B[0mmemory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001B[0m\u001B[1;32m    147\u001B[0m                               \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m                               memory_key_padding_mask=memory_key_padding_mask)\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmod\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 291\u001B[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001B[0m\u001B[1;32m    292\u001B[0m                          \u001B[0mmemory_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmemory_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m                          \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    576\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sa_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mha_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_key_padding_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 578\u001B[0;31m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ff_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    579\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001B[0m in \u001B[0;36m_ff_block\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[0;31m# feed forward block\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    601\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_ff_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 602\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactivation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    603\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_loss = 100000\n",
    "best_epoch = 0\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    for X, y in train_data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 教师模型预测\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(X, y)\n",
    "        # 学生模型预测\n",
    "        student_outputs = model(X, y)\n",
    "        student_loss = hard_loss(student_outputs, y)\n",
    "        # 计算蒸馏后的预测结果及soft_loss\n",
    "        distillation_loss = soft_loss(\n",
    "            F.softmax(student_outputs/T, dim=1),\n",
    "            F.softmax(teacher_outputs/T, dim=1)\n",
    "        )\n",
    "        # 将 hard_loss 和 soft_loss 加权求和\n",
    "        loss = alpha * student_loss + (1-alpha) * distillation_loss * T **2\n",
    "        # 反向传播,优化权重\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, './result/distillation_weight.pth')\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "# 打印最佳的结果\n",
    "print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 蒸馏模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.1518006, 'mse': 0.03801897, 'rmse': 0.19498454216064115, 'evs': 0.9847988784313202, 'r2': 0.9816030012417469, 'mmax': 0.71145415, 'mmin': 0.016973555}\n"
     ]
    }
   ],
   "source": [
    "model = StudentTransformer().to(device)\n",
    "model.load_state_dict(torch.load('./result/distillation_weight.pth'))\n",
    "model.eval()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "pxy = model(X_test, y_test)\n",
    "pxy = pxy.cpu().detach().numpy().squeeze(0)\n",
    "y_test = y_test.cpu().detach().numpy()\n",
    "\n",
    "# 计算指标\n",
    "mae = mean_absolute_error(y_test, pxy)\n",
    "mse = mean_squared_error(y_test, pxy)\n",
    "rmse = mse ** 0.5\n",
    "evs = explained_variance_score(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "\n",
    "mmax = 0\n",
    "mmin = 10000\n",
    "for i in range(len(pxy)):\n",
    "    mmax = max(mean_absolute_error(y_test[i], pxy[i]), mmax)\n",
    "    mmin = min(mean_absolute_error(y_test[i], pxy[i]), mmin)\n",
    "\n",
    "print({'mae': mae, 'mse': mse, 'rmse': rmse, 'evs': evs, 'r2': r2, 'mmax': mmax, 'mmin': mmin})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 蒸馏模型定位效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>PX</th>\n",
       "      <th>Py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.284969</td>\n",
       "      <td>3.602425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.164377</td>\n",
       "      <td>2.080438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.682233</td>\n",
       "      <td>2.803676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.07</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.393359</td>\n",
       "      <td>2.952392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.603147</td>\n",
       "      <td>2.571705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.43</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.892507</td>\n",
       "      <td>1.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.254863</td>\n",
       "      <td>0.782649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.426601</td>\n",
       "      <td>2.106437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.382243</td>\n",
       "      <td>3.688406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.531628</td>\n",
       "      <td>4.341705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.347397</td>\n",
       "      <td>3.730716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.67</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.900538</td>\n",
       "      <td>0.575031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.57</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.908475</td>\n",
       "      <td>0.409832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.340399</td>\n",
       "      <td>3.486715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.76</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4.560523</td>\n",
       "      <td>3.342371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.70</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.664338</td>\n",
       "      <td>3.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.975747</td>\n",
       "      <td>1.356169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.68</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>4.337845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.09</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.108630</td>\n",
       "      <td>4.413423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.25</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.346374</td>\n",
       "      <td>3.777927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X     y        PX        Py\n",
       "0   0.21  3.47  0.284969  3.602425\n",
       "1   1.13  1.96  1.164377  2.080438\n",
       "2   3.38  2.58  3.682233  2.803676\n",
       "3   4.07  2.72  4.393359  2.952392\n",
       "4   1.58  2.47  1.603147  2.571705\n",
       "5   3.43  1.61  3.892507  1.795763\n",
       "6   1.22  0.74  1.254863  0.782649\n",
       "7   2.33  1.97  2.426601  2.106437\n",
       "8   0.33  3.56  0.382243  3.688406\n",
       "9   3.53  4.28  3.531628  4.341705\n",
       "10  4.42  3.69  4.347397  3.730716\n",
       "11  3.67  0.34  3.900538  0.575031\n",
       "12  2.57  0.37  2.908475  0.409832\n",
       "13  3.14  3.22  3.340399  3.486715\n",
       "14  4.76  3.34  4.560523  3.342371\n",
       "15  1.70  3.71  1.664338  3.887244\n",
       "16  3.50  1.20  3.975747  1.356169\n",
       "17  0.68  4.65  0.806122  4.337845\n",
       "18  1.09  4.59  1.108630  4.413423\n",
       "19  0.25  3.70  0.346374  3.777927"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_distill = y_test[:20]\n",
    "pxy = pxy[:20]\n",
    "coor1 = pd.DataFrame(y_distill)\n",
    "coor1.columns = ['X', 'y']\n",
    "\n",
    "coor2 = pd.DataFrame(pxy)\n",
    "coor2.columns = ['PX', 'Py']\n",
    "\n",
    "coor = pd.concat([coor1, coor2], axis=1)\n",
    "coor.to_csv('./result/coordinate_all_distill.csv')\n",
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.xlim((0, 5))\n",
    "plt.ylim((0, 5))\n",
    "plt.ylabel('RFID reader')\n",
    "plt.title('Coordinate Comparison')\n",
    "# 画图-标准坐标\n",
    "plt.scatter(y_distill[:, 0], y_distill[:, 1], c='black', marker='^', label='real position of RFID tag')\n",
    "\n",
    "# 画图-预测EA坐标\n",
    "plt.scatter(pxy[:, 0], pxy[:, 1], c='red', marker='x', label = 'predict position with KD')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('True')\n",
    "plt.savefig('./result/compare_coordinate_distill.jpg', dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义问题类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MOEA(ea.Problem):\n",
    "    def __init__(self, train_data_loader, test_data_loader):\n",
    "        name = 'MOEA'\n",
    "        M = 1 # 初始化M（目标维数）\n",
    "        maxormins = [-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标）\n",
    "        Dim = 2 # 初始化Dim（决策变量维数）\n",
    "        varTypes = np.array([0] * Dim) # 初始化varTypes 0-连续\n",
    "        lb = [5, 0.1] # 决策变量下界\n",
    "        ub = [10, 0.9] # 决策变量上界\n",
    "        lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含）\n",
    "        ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含）\n",
    "        # 调用父类构造方法完成实例化\n",
    "        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)\n",
    "        # 数据设置\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.test_data_loader = test_data_loader\n",
    "\n",
    "\n",
    "    # 目标函数，采用多线程加速计算\n",
    "    def aimFunc(self, pop):\n",
    "        Vars = pop.Phen # 得到决策变量矩阵\n",
    "        # print(Vars)\n",
    "        pop.ObjV = np.zeros((pop.sizes, 1)) # 初始化种群个体目标函数值列向量\n",
    "        def subAimFunc(i):\n",
    "            epochs, alpha = int(Vars[i, 0]), float(Vars[i, 1])\n",
    "            print(epochs, alpha)\n",
    "            final_loss = 0\n",
    "            for epoch in range(epochs):\n",
    "                for data,targets in tqdm(train_data_loader):\n",
    "                    data, targets = data.to(device), targets.to(device)\n",
    "                    # 教师模型预测\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(data)\n",
    "                    # 学生模型预测\n",
    "                    student_outputs = model(data)\n",
    "                    student_loss = hard_loss(student_outputs, targets)\n",
    "                    # 计算蒸馏后的预测结果及soft_loss\n",
    "                    distillation_loss = soft_loss(\n",
    "                        F.softmax(student_outputs/T, dim=1),\n",
    "                        F.softmax(teacher_outputs/T, dim=1)\n",
    "                    )\n",
    "                    # 将 hard_loss 和 soft_loss 加权求和\n",
    "                    loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                    final_loss = loss.item()\n",
    "                    # 反向传播,优化权重\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            pop.ObjV[i] = final_loss # 最小化最终的损失作为目标函数\n",
    "        pool = ThreadPool(processes=2) # 设置池的大小\n",
    "        pool.map(subAimFunc, list(range(pop.sizes))) # 散列种群每个个体进行加速计算\n",
    "\n",
    "\n",
    "    # 代入优化后的参数先训练再对测试集进行检验，计算指标\n",
    "    def test(self, epochs, alpha):\n",
    "        for epoch in range(epochs):\n",
    "            for data,targets in tqdm(train_data_loader):\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                # 教师模型预测\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(data)\n",
    "                # 学生模型预测\n",
    "                student_outputs = model(data)\n",
    "                student_loss = hard_loss(student_outputs, targets)\n",
    "                # 计算蒸馏后的预测结果及soft_loss\n",
    "                distillation_loss = soft_loss(\n",
    "                    F.softmax(student_outputs/T, dim=1),\n",
    "                    F.softmax(teacher_outputs/T, dim=1)\n",
    "                )\n",
    "                # 将 hard_loss 和 soft_loss 加权求和\n",
    "                loss = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "                # 反向传播,优化权重\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 测试集上评估性能\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x,y in test_data_loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    outputs = model(x)\n",
    "                    pred = outputs.max(1).indices\n",
    "                    num_correct += (pred == y).sum()\n",
    "                    num_samples += pred.size(0)\n",
    "                acc = (num_correct/num_samples).item()\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch:{}\\t Accuracy:{:4f}\".format(epoch + 1, acc))\n",
    "\n",
    "        torch.save(model.state_dict(), \"./models/moea_distillation.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.3189171239733696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2855765145272017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 2/938 [00:00<00:54, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8424268286675215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 3/938 [00:00<00:39, 23.75it/s]\u001B[A\u001B[A\n",
      "  0%|          | 2/938 [00:00<00:52, 17.78it/s]\u001B[A\n",
      "\n",
      "  1%|          | 6/938 [00:00<00:44, 20.86it/s]\u001B[A\u001B[A\n",
      "  0%|          | 4/938 [00:00<00:51, 18.15it/s]\u001B[A\n",
      "\n",
      " 94%|█████████▎| 878/938 [00:08<00:01, 36.62it/s]A\u001B[A\n",
      " 94%|█████████▎| 878/938 [00:08<00:00, 102.62it/s]\n",
      "\n",
      "\n",
      "  1%|          | 9/938 [00:00<00:48, 19.11it/s]]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.8656420316547155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 1/938 [00:00<01:05, 14.39it/s]]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.6277091335505247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 4/938 [00:00<00:25, 37.06it/s]]\u001B[A\u001B[A\n",
      "\n",
      "  1%|          | 10/938 [00:00<00:26, 34.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  3%|▎         | 31/938 [00:00<00:23, 38.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "  4%|▍         | 38/938 [00:01<00:19, 45.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "  5%|▍         | 46/938 [00:01<00:16, 54.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "  6%|▌         | 54/938 [00:01<00:14, 61.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "  7%|▋         | 65/938 [00:01<00:11, 74.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "  8%|▊         | 76/938 [00:01<00:10, 83.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "  9%|▉         | 86/938 [00:01<00:09, 88.29it/s]\u001B[A\u001B[A\n",
      "\n",
      " 10%|█         | 96/938 [00:01<00:09, 89.71it/s]\u001B[A\u001B[A\n",
      "\n",
      " 11%|█▏        | 106/938 [00:01<00:09, 85.26it/s]\u001B[A\u001B[A\n",
      "\n",
      " 12%|█▏        | 116/938 [00:01<00:09, 87.53it/s]\u001B[A\u001B[A\n",
      "\n",
      " 13%|█▎        | 125/938 [00:02<00:09, 87.56it/s]\u001B[A\u001B[A\n",
      "\n",
      " 14%|█▍        | 134/938 [00:02<00:09, 86.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 15%|█▌        | 143/938 [00:02<00:09, 87.52it/s]\u001B[A\u001B[A\n",
      "\n",
      " 16%|█▌        | 152/938 [00:02<00:09, 86.56it/s]\u001B[A\u001B[A\n",
      "\n",
      " 17%|█▋        | 163/938 [00:02<00:08, 92.49it/s]\u001B[A\u001B[A\n",
      "\n",
      " 19%|█▊        | 174/938 [00:02<00:08, 95.28it/s]\u001B[A\u001B[A\n",
      "\n",
      " 20%|█▉        | 184/938 [00:02<00:08, 92.35it/s]\u001B[A\u001B[A\n",
      "\n",
      " 21%|██        | 194/938 [00:02<00:08, 92.09it/s]\u001B[A\u001B[A\n",
      "\n",
      " 22%|██▏       | 205/938 [00:02<00:07, 96.28it/s]\u001B[A\u001B[A\n",
      "\n",
      " 23%|██▎       | 216/938 [00:03<00:07, 99.24it/s]\u001B[A\u001B[A\n",
      "\n",
      " 24%|██▍       | 226/938 [00:03<00:07, 97.81it/s]\u001B[A\u001B[A\n",
      "\n",
      " 25%|██▌       | 237/938 [00:03<00:07, 100.07it/s]\u001B[A\u001B[A\n",
      "\n",
      " 26%|██▋       | 248/938 [00:03<00:06, 101.80it/s]\u001B[A\u001B[A\n",
      "\n",
      " 28%|██▊       | 260/938 [00:03<00:06, 104.55it/s]\u001B[A\u001B[A\n",
      "\n",
      " 29%|██▉       | 272/938 [00:03<00:06, 106.73it/s]\u001B[A\u001B[A\n",
      "\n",
      " 30%|███       | 283/938 [00:03<00:06, 105.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 31%|███▏      | 295/938 [00:03<00:05, 107.48it/s]\u001B[A\u001B[A\n",
      "\n",
      " 33%|███▎      | 306/938 [00:03<00:05, 107.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 34%|███▍      | 317/938 [00:03<00:05, 106.38it/s]\u001B[A\u001B[A\n",
      "\n",
      " 35%|███▍      | 328/938 [00:04<00:05, 105.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 36%|███▌      | 339/938 [00:04<00:05, 107.02it/s]\u001B[A\u001B[A\n",
      "\n",
      " 37%|███▋      | 351/938 [00:04<00:05, 108.31it/s]\u001B[A\u001B[A\n",
      "\n",
      " 39%|███▊      | 362/938 [00:04<00:05, 106.19it/s]\u001B[A\u001B[A\n",
      "\n",
      " 40%|███▉      | 374/938 [00:04<00:05, 107.98it/s]\u001B[A\u001B[A\n",
      "\n",
      " 41%|████      | 385/938 [00:04<00:05, 106.42it/s]\u001B[A\u001B[A\n",
      "\n",
      " 42%|████▏     | 397/938 [00:04<00:04, 108.32it/s]\u001B[A\u001B[A\n",
      "\n",
      " 44%|████▎     | 409/938 [00:04<00:04, 109.17it/s]\u001B[A\u001B[A\n",
      "\n",
      " 45%|████▍     | 421/938 [00:04<00:04, 111.22it/s]\u001B[A\u001B[A\n",
      "\n",
      " 46%|████▌     | 433/938 [00:05<00:04, 112.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 47%|████▋     | 445/938 [00:05<00:04, 111.32it/s]\u001B[A\u001B[A\n",
      "\n",
      " 49%|████▊     | 457/938 [00:05<00:04, 112.26it/s]\u001B[A\u001B[A\n",
      "\n",
      " 50%|█████     | 469/938 [00:05<00:04, 108.13it/s]\u001B[A\u001B[A\n",
      "\n",
      " 51%|█████▏    | 481/938 [00:05<00:04, 110.86it/s]\u001B[A\u001B[A\n",
      "\n",
      " 53%|█████▎    | 493/938 [00:05<00:03, 111.45it/s]\u001B[A\u001B[A\n",
      "\n",
      " 54%|█████▍    | 505/938 [00:05<00:03, 111.51it/s]\u001B[A\u001B[A\n",
      "\n",
      " 55%|█████▌    | 517/938 [00:05<00:03, 112.92it/s]\u001B[A\u001B[A\n",
      "\n",
      " 56%|█████▋    | 529/938 [00:05<00:03, 113.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 58%|█████▊    | 541/938 [00:05<00:03, 113.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 59%|█████▉    | 553/938 [00:06<00:03, 112.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 60%|██████    | 565/938 [00:06<00:03, 113.01it/s]\u001B[A\u001B[A\n",
      "\n",
      " 62%|██████▏   | 577/938 [00:06<00:03, 113.99it/s]\u001B[A\u001B[A\n",
      "\n",
      " 63%|██████▎   | 589/938 [00:06<00:03, 114.94it/s]\u001B[A\u001B[A\n",
      "\n",
      " 64%|██████▍   | 601/938 [00:06<00:02, 115.34it/s]\u001B[A\u001B[A\n",
      "\n",
      " 65%|██████▌   | 613/938 [00:06<00:02, 112.19it/s]\u001B[A\u001B[A\n",
      "\n",
      " 67%|██████▋   | 625/938 [00:06<00:02, 113.47it/s]\u001B[A\u001B[A\n",
      "\n",
      " 68%|██████▊   | 637/938 [00:06<00:02, 114.37it/s]\u001B[A\u001B[A\n",
      "\n",
      " 69%|██████▉   | 649/938 [00:06<00:02, 114.63it/s]\u001B[A\u001B[A\n",
      "\n",
      " 70%|███████   | 661/938 [00:07<00:02, 115.88it/s]\u001B[A\u001B[A\n",
      "\n",
      " 72%|███████▏  | 673/938 [00:07<00:02, 115.04it/s]\u001B[A\u001B[A\n",
      "\n",
      " 73%|███████▎  | 685/938 [00:07<00:02, 106.64it/s]\u001B[A\u001B[A\n",
      "\n",
      " 74%|███████▍  | 696/938 [00:07<00:02, 105.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 75%|███████▌  | 708/938 [00:07<00:02, 109.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 77%|███████▋  | 719/938 [00:07<00:02, 106.84it/s]\u001B[A\u001B[A\n",
      "\n",
      " 78%|███████▊  | 731/938 [00:07<00:01, 109.64it/s]\u001B[A\u001B[A\n",
      "\n",
      " 79%|███████▉  | 743/938 [00:07<00:01, 112.57it/s]\u001B[A\u001B[A\n",
      "\n",
      " 80%|████████  | 755/938 [00:07<00:01, 113.94it/s]\u001B[A\u001B[A\n",
      "\n",
      " 82%|████████▏ | 767/938 [00:08<00:01, 110.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 83%|████████▎ | 779/938 [00:08<00:01, 109.68it/s]\u001B[A\u001B[A\n",
      "\n",
      " 84%|████████▍ | 791/938 [00:08<00:01, 112.01it/s]\u001B[A\u001B[A\n",
      "\n",
      " 86%|████████▌ | 803/938 [00:08<00:01, 105.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 87%|████████▋ | 814/938 [00:08<00:01, 103.05it/s]\u001B[A\u001B[A\n",
      "\n",
      " 88%|████████▊ | 825/938 [00:08<00:01, 103.50it/s]\u001B[A\u001B[A\n",
      "\n",
      " 89%|████████▉ | 836/938 [00:08<00:00, 104.69it/s]\u001B[A\u001B[A\n",
      "\n",
      " 90%|█████████ | 848/938 [00:08<00:00, 106.85it/s]\u001B[A\u001B[A\n",
      "\n",
      " 92%|█████████▏| 859/938 [00:08<00:00, 106.82it/s]\u001B[A\u001B[A\n",
      "\n",
      " 93%|█████████▎| 871/938 [00:09<00:00, 108.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 94%|█████████▍| 882/938 [00:09<00:00, 104.92it/s]\u001B[A\u001B[A\n",
      "\n",
      " 95%|█████████▌| 893/938 [00:09<00:00, 104.17it/s]\u001B[A\u001B[A\n",
      "\n",
      " 96%|█████████▋| 904/938 [00:09<00:00, 99.99it/s] \u001B[A\u001B[A\n",
      "\n",
      " 98%|█████████▊| 915/938 [00:09<00:00, 100.10it/s]\u001B[A\u001B[A\n",
      "\n",
      " 99%|█████████▊| 926/938 [00:09<00:00, 101.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "100%|██████████| 938/938 [00:09<00:00, 96.68it/s] \u001B[A\u001B[A\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.38it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 105.10it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 112.47it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.13it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.2740337282419205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 109.97it/s]\n",
      "100%|██████████| 938/938 [00:07<00:00, 118.57it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.56it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.24it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 104.54it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 114.32it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 106.33it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 116.82it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-e006b3843ce3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m \u001B[0;34m[\u001B[0m\u001B[0mBestIndi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpopulation\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmyAlgorithm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 执行算法模板，得到最优个体以及最后一代种群\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m \u001B[0mBestIndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 把最优个体的信息保存到文件中\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/templates/soeas/DE/DE_rand_1_bin/soea_DE_rand_1_bin_templet.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, prophetPop)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;31m# ===========================准备进化============================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0mpopulation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minitChrom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNIND\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 初始化种群染色体矩阵\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_aimFunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpopulation\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 计算种群的目标函数值\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;31m# 插入先验知识（注意：这里不会对先知种群prophetPop的合法性进行检查，故应确保prophetPop是一个种群类且拥有合法的Chrom、ObjV、Phen等属性）\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mprophetPop\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/geatpy/Algorithm.py\u001B[0m in \u001B[0;36mcall_aimFunc\u001B[0;34m(self, pop)\u001B[0m\n\u001B[1;32m    172\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproblem\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'error: problem has not been initialized. (算法模板中的问题对象未被初始化。)'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproblem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maimFunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 调用问题类的aimFunc()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevalsNum\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m  \u001B[0;31m# 更新评价次数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0;31m# 格式检查\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-29ea1f645391>\u001B[0m in \u001B[0;36maimFunc\u001B[0;34m(self, pop)\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mObjV\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfinal_loss\u001B[0m \u001B[0;31m# 最小化最终的损失作为目标函数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mpool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mThreadPool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocesses\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 设置池的大小\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubAimFunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 散列种群每个个体进行加速计算\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m         \u001B[0;32min\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mthat\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mreturned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         '''\n\u001B[0;32m--> 364\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstarmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    769\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    770\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 771\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    772\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    773\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mworker\u001B[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0mjob\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mwrap_exception\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mfunc\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_helper_reraises_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmapstar\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mstarmapstar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-29ea1f645391>\u001B[0m in \u001B[0;36msubAimFunc\u001B[0;34m(i)\u001B[0m\n\u001B[1;32m     45\u001B[0m                     \u001B[0;31m# 反向传播,优化权重\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m                     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    394\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    395\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 396\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    397\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    398\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    171\u001B[0m     \u001B[0;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[0;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 173\u001B[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[0;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 10]], which is output 0 of AsStridedBackward0, is at version 23416; expected version 23415 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "\"\"\"===============================实例化问题对象===========================\"\"\"\n",
    "\n",
    "problem = MOEA(train_data_loader, test_data_loader) # 生成问题对象\n",
    "\n",
    "\"\"\"=================================种群设置===============================\"\"\"\n",
    "\n",
    "Encoding = 'RI'       # 编码方式\n",
    "NIND = 10             # 种群规模\n",
    "Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器\n",
    "population = ea.Population(Encoding, Field, NIND) # 实例化种群对象（此时种群还没被初始化，仅仅是完成种群对象的实例化）\n",
    "\n",
    "\"\"\"===============================算法参数设置=============================\"\"\"\n",
    "\n",
    "myAlgorithm = ea.soea_DE_rand_1_bin_templet(problem, population) # 实例化一个算法模板对象\n",
    "myAlgorithm.MAXGEN = 10 # 最大进化代数\n",
    "myAlgorithm.trappedValue = 1e-6 # “进化停滞”判断阈值\n",
    "myAlgorithm.maxTrappedCount = 10 # 进化停滞计数器最大上限值，如果连续maxTrappedCount代被判定进化陷入停滞，则终止进化\n",
    "myAlgorithm.logTras = 1  # 设置每隔多少代记录日志，若设置成0则表示不记录日志\n",
    "myAlgorithm.verbose = True  # 设置是否打印输出日志信息\n",
    "myAlgorithm.drawing = 1  # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画）\n",
    "\n",
    "\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\n",
    "\n",
    "[BestIndi, population] = myAlgorithm.run()  # 执行算法模板，得到最优个体以及最后一代种群\n",
    "BestIndi.save()  # 把最优个体的信息保存到文件中\n",
    "\n",
    "\"\"\"==================================输出结果=============================\"\"\"\n",
    "\n",
    "print('用时：%f 秒' % myAlgorithm.passTime)\n",
    "print('评价次数：%d 次' % myAlgorithm.evalsNum)\n",
    "if BestIndi.sizes != 0:\n",
    "    print('最优的目标函数值为：%s' % BestIndi.ObjV[0][0])\n",
    "    print('最优的控制变量值为：')\n",
    "    for i in range(BestIndi.Phen.shape[1]):\n",
    "        print(BestIndi.Phen[0, i])\n",
    "else:\n",
    "    print('没找到可行解。')\n",
    "\n",
    "\"\"\"=================================检验结果===============================\"\"\"\n",
    "\n",
    "problem.test(epochs= int(BestIndi.Phen[0][0]), alpha= float(BestIndi.Phen[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
