{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 测试使用transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import utils.calculate_param as cp\n",
    "import dataset.data_read as data\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载Transformer模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = nn.Transformer(d_model=128, num_encoder_layers=3, num_decoder_layers=3, batch_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的参数信息如下：\n",
      "encoder.layers.0.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "encoder.layers.0.self_attn.in_proj_bias : torch.Size([384])\n",
      "encoder.layers.0.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "encoder.layers.0.self_attn.out_proj.bias : torch.Size([128])\n",
      "encoder.layers.0.linear1.weight : torch.Size([2048, 128])\n",
      "encoder.layers.0.linear1.bias : torch.Size([2048])\n",
      "encoder.layers.0.linear2.weight : torch.Size([128, 2048])\n",
      "encoder.layers.0.linear2.bias : torch.Size([128])\n",
      "encoder.layers.0.norm1.weight : torch.Size([128])\n",
      "encoder.layers.0.norm1.bias : torch.Size([128])\n",
      "encoder.layers.0.norm2.weight : torch.Size([128])\n",
      "encoder.layers.0.norm2.bias : torch.Size([128])\n",
      "encoder.layers.1.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "encoder.layers.1.self_attn.in_proj_bias : torch.Size([384])\n",
      "encoder.layers.1.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "encoder.layers.1.self_attn.out_proj.bias : torch.Size([128])\n",
      "encoder.layers.1.linear1.weight : torch.Size([2048, 128])\n",
      "encoder.layers.1.linear1.bias : torch.Size([2048])\n",
      "encoder.layers.1.linear2.weight : torch.Size([128, 2048])\n",
      "encoder.layers.1.linear2.bias : torch.Size([128])\n",
      "encoder.layers.1.norm1.weight : torch.Size([128])\n",
      "encoder.layers.1.norm1.bias : torch.Size([128])\n",
      "encoder.layers.1.norm2.weight : torch.Size([128])\n",
      "encoder.layers.1.norm2.bias : torch.Size([128])\n",
      "encoder.layers.2.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "encoder.layers.2.self_attn.in_proj_bias : torch.Size([384])\n",
      "encoder.layers.2.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "encoder.layers.2.self_attn.out_proj.bias : torch.Size([128])\n",
      "encoder.layers.2.linear1.weight : torch.Size([2048, 128])\n",
      "encoder.layers.2.linear1.bias : torch.Size([2048])\n",
      "encoder.layers.2.linear2.weight : torch.Size([128, 2048])\n",
      "encoder.layers.2.linear2.bias : torch.Size([128])\n",
      "encoder.layers.2.norm1.weight : torch.Size([128])\n",
      "encoder.layers.2.norm1.bias : torch.Size([128])\n",
      "encoder.layers.2.norm2.weight : torch.Size([128])\n",
      "encoder.layers.2.norm2.bias : torch.Size([128])\n",
      "encoder.norm.weight : torch.Size([128])\n",
      "encoder.norm.bias : torch.Size([128])\n",
      "decoder.layers.0.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "decoder.layers.0.self_attn.in_proj_bias : torch.Size([384])\n",
      "decoder.layers.0.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "decoder.layers.0.self_attn.out_proj.bias : torch.Size([128])\n",
      "decoder.layers.0.multihead_attn.in_proj_weight : torch.Size([384, 128])\n",
      "decoder.layers.0.multihead_attn.in_proj_bias : torch.Size([384])\n",
      "decoder.layers.0.multihead_attn.out_proj.weight : torch.Size([128, 128])\n",
      "decoder.layers.0.multihead_attn.out_proj.bias : torch.Size([128])\n",
      "decoder.layers.0.linear1.weight : torch.Size([2048, 128])\n",
      "decoder.layers.0.linear1.bias : torch.Size([2048])\n",
      "decoder.layers.0.linear2.weight : torch.Size([128, 2048])\n",
      "decoder.layers.0.linear2.bias : torch.Size([128])\n",
      "decoder.layers.0.norm1.weight : torch.Size([128])\n",
      "decoder.layers.0.norm1.bias : torch.Size([128])\n",
      "decoder.layers.0.norm2.weight : torch.Size([128])\n",
      "decoder.layers.0.norm2.bias : torch.Size([128])\n",
      "decoder.layers.0.norm3.weight : torch.Size([128])\n",
      "decoder.layers.0.norm3.bias : torch.Size([128])\n",
      "decoder.layers.1.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "decoder.layers.1.self_attn.in_proj_bias : torch.Size([384])\n",
      "decoder.layers.1.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "decoder.layers.1.self_attn.out_proj.bias : torch.Size([128])\n",
      "decoder.layers.1.multihead_attn.in_proj_weight : torch.Size([384, 128])\n",
      "decoder.layers.1.multihead_attn.in_proj_bias : torch.Size([384])\n",
      "decoder.layers.1.multihead_attn.out_proj.weight : torch.Size([128, 128])\n",
      "decoder.layers.1.multihead_attn.out_proj.bias : torch.Size([128])\n",
      "decoder.layers.1.linear1.weight : torch.Size([2048, 128])\n",
      "decoder.layers.1.linear1.bias : torch.Size([2048])\n",
      "decoder.layers.1.linear2.weight : torch.Size([128, 2048])\n",
      "decoder.layers.1.linear2.bias : torch.Size([128])\n",
      "decoder.layers.1.norm1.weight : torch.Size([128])\n",
      "decoder.layers.1.norm1.bias : torch.Size([128])\n",
      "decoder.layers.1.norm2.weight : torch.Size([128])\n",
      "decoder.layers.1.norm2.bias : torch.Size([128])\n",
      "decoder.layers.1.norm3.weight : torch.Size([128])\n",
      "decoder.layers.1.norm3.bias : torch.Size([128])\n",
      "decoder.layers.2.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "decoder.layers.2.self_attn.in_proj_bias : torch.Size([384])\n",
      "decoder.layers.2.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "decoder.layers.2.self_attn.out_proj.bias : torch.Size([128])\n",
      "decoder.layers.2.multihead_attn.in_proj_weight : torch.Size([384, 128])\n",
      "decoder.layers.2.multihead_attn.in_proj_bias : torch.Size([384])\n",
      "decoder.layers.2.multihead_attn.out_proj.weight : torch.Size([128, 128])\n",
      "decoder.layers.2.multihead_attn.out_proj.bias : torch.Size([128])\n",
      "decoder.layers.2.linear1.weight : torch.Size([2048, 128])\n",
      "decoder.layers.2.linear1.bias : torch.Size([2048])\n",
      "decoder.layers.2.linear2.weight : torch.Size([128, 2048])\n",
      "decoder.layers.2.linear2.bias : torch.Size([128])\n",
      "decoder.layers.2.norm1.weight : torch.Size([128])\n",
      "decoder.layers.2.norm1.bias : torch.Size([128])\n",
      "decoder.layers.2.norm2.weight : torch.Size([128])\n",
      "decoder.layers.2.norm2.bias : torch.Size([128])\n",
      "decoder.layers.2.norm3.weight : torch.Size([128])\n",
      "decoder.layers.2.norm3.bias : torch.Size([128])\n",
      "decoder.norm.weight : torch.Size([128])\n",
      "decoder.norm.bias : torch.Size([128])\n",
      "{'总数': 3757568, '可训练数': 3757568}\n"
     ]
    }
   ],
   "source": [
    "cp.get_info(model)\n",
    "cp.get_parameter_number(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Transformer(\n  (encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (1): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (2): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n  )\n  (decoder): TransformerDecoder(\n    (layers): ModuleList(\n      (0): TransformerDecoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (multihead_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n      (1): TransformerDecoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (multihead_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n      (2): TransformerDecoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (multihead_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载数据并embedding转为需要的tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 50)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = data.load_data_prefix('train')\n",
    "X_test, y_test = data.load_data_prefix('test')\n",
    "\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 调整batch_size 默认为1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([200, 10, 50])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train.reshape(200, 10, 50)).float() # batch * len * feature batch设置为1\n",
    "y_train = torch.from_numpy(y_train.reshape(200, 10, 2)).float()\n",
    "\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义嵌入的规则 使用线性层代替词向量的嵌入"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "embedding_enc = nn.Linear(50, 128)\n",
    "embedding_dec = nn.Linear(2, 128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([200, 10, 128])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 嵌入并且batch保持一致 batch * len * d_model\n",
    "X_train = embedding_enc(X_train).to(device)\n",
    "y_train = embedding_dec(y_train).to(device)\n",
    "\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 调用Transformer模型处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "out = model(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 2000, 128])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 输出过线性层变为坐标"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "projection = nn.Linear(128, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "out = projection(out.squeeze())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2386, -0.2895],\n        [-0.2758, -0.0868],\n        [-0.6989, -0.5534],\n        ...,\n        [ 0.3809, -0.2974],\n        [-0.0609, -0.1500],\n        [-0.2479, -0.1022]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义Transformer的时序模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class RFID_TRANS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RFID_TRANS, self).__init__()\n",
    "        # self.time_step = 50\n",
    "        # self.x_dim = 1\n",
    "        # self.h_dim = 60\n",
    "        # self.gru_layers = 1\n",
    "\n",
    "        self.Transformer_layer = nn.Transformer(d_model=128, num_encoder_layers=3, num_decoder_layers=3, batch_first=True)\n",
    "        self.FC = nn.Linear(128, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.Transformer_layer(x)\n",
    "        out = self.FC(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 开始训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # 忽略 占位符 索引为0.\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "best_loss = 100000\n",
    "best_epoch = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "torch.Size([200, 10, 128])\n",
      "1\n",
      "ok!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    dataset = TensorDataset(X_train, y_train)\n",
    "    data_loader = DataLoader(dataset, batch_size=200, shuffle=False)\n",
    "    cnt = 0\n",
    "    for X, y in data_loader:  # enc_inputs : [batch * len * d_model] 1 * 2000 * 128\n",
    "        print(X.shape)\n",
    "        cnt = cnt + 1\n",
    "        # enc_inputs=X.unsqueeze(0)   #(1*64*5)\n",
    "        # # enc_inputs=enc_inputs.squeeze(2)\n",
    "        # # dec_inputs : [batch_size, ]\n",
    "        # # dec_outputs: [batch_size, 1]\n",
    "        # outputs = model(enc_inputs)\n",
    "        # # print(outputs.shape)\n",
    "        # outputs = outputs.squeeze(1)\n",
    "        # outputs = outputs.unsqueeze(0)\n",
    "        # y = y.unsqueeze(0)\n",
    "        # # outputs: [batch_size * tgt_len, tgt_vocab_size]\n",
    "        # loss = criterion(outputs, y.view(1, -1))\n",
    "        # loss_num = loss.item()\n",
    "        # epoch_loss += loss_num\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        # optimizer.step()\n",
    "        # y_pre.append(outputs.detach().numpy())\n",
    "        # y_true.append(y.detach().numpy())\n",
    "\n",
    "#     if epoch_loss < best_loss:\n",
    "#         best_loss = epoch_loss\n",
    "#         best_epoch = epoch\n",
    "#         best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#         torch.save(best_model_wts, './result/weight.pth')\n",
    "#\n",
    "#     print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(epoch_loss))\n",
    "\n",
    "    print(cnt)\n",
    "# # 打印最佳的结果\n",
    "# print('best_loss::|',best_loss,'---best_epoch::|',best_epoch)\n",
    "\n",
    "print('ok!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}